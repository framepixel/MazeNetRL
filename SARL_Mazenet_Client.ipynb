{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81afe7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SARL_Env_v3 import MazeEnv\n",
    "\n",
    "from stable_baselines3 import A2C, PPO\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875af410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from JavalessClient import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4245b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = Client(\"manager\", \"127.0.0.1\", 9888, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcaf207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.login_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a149af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces import Discrete, Box, Tuple, MultiBinary, MultiDiscrete, Dict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75569102",
   "metadata": {},
   "outputs": [],
   "source": [
    "menv = MazeEnv()#.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae612ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9ce8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5da17a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "path = 'Training/Logs'\n",
    "model = A2C('MultiInputPolicy',\n",
    "            menv,\n",
    "            verbose=1,\n",
    "            tensorboard_log=path,\n",
    "            device=\"cuda\",\n",
    "#             learning_rate=0.007,\n",
    "#             n_steps=10,\n",
    "#             gamma=0.7,\n",
    "            \n",
    "           )\n",
    "checkpoint_callback = CheckpointCallback( save_freq=2048,\n",
    "                                          save_path=\"./saved_a2c_v4/\",\n",
    "                                          name_prefix=\"a2c_v4_model_\",\n",
    "                                          save_replay_buffer=True,\n",
    "                                          save_vecnormalize=True,)\n",
    "eval_callback = EvalCallback(menv, best_model_save_path=\"./best_a2c_v4/\",\n",
    "                             log_path=\"./logs/\", eval_freq=2000,\n",
    "                             deterministic=True, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aylam\\desktop\\Bachelorarbeit\\SARL_Env_v3.py\", line 242, in reset\n",
      "    print(receivedMazeCom.get_AcceptMessage().get_errortypeCode())\n",
      "AttributeError: 'NoneType' object has no attribute 'get_errortypeCode'\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aylam\\desktop\\Bachelorarbeit\\SARL_Env_v3.py\", line 242, in reset\n",
      "    print(receivedMazeCom.get_AcceptMessage().get_errortypeCode())\n",
      "AttributeError: 'NoneType' object has no attribute 'get_errortypeCode'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aylam\\desktop\\Bachelorarbeit\\SARL_Env_v3.py\", line 242, in reset\n",
      "    print(receivedMazeCom.get_AcceptMessage().get_errortypeCode())\n",
      "AttributeError: 'NoneType' object has no attribute 'get_errortypeCode'\n",
      "\n",
      "Logging to Training/Logs\\A2C_29\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 12       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.86    |\n",
      "|    explained_variance | 0.000409 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -33.2    |\n",
      "|    value_loss         | 15.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.18e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 16        |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -33       |\n",
      "|    value_loss         | 14.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.18e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 20        |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.83     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -29.1     |\n",
      "|    value_loss         | 13.4      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aylam\\AppData\\Roaming\\Python\\Python39\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2000, episode_reward=-1273.60 +/- 50.82\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -1.27e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.61     |\n",
      "|    explained_variance | 0.000669  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -28.8     |\n",
      "|    value_loss         | 12.6      |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.15e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 8         |\n",
      "|    iterations      | 400       |\n",
      "|    time_elapsed    | 225       |\n",
      "|    total_timesteps | 2000      |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.15e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 236       |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.88     |\n",
      "|    explained_variance | 0.000126  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -27.7     |\n",
      "|    value_loss         | 11.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.13e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 258       |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.87     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -26.5     |\n",
      "|    value_loss         | 11.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.13e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 12        |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 269       |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.56     |\n",
      "|    explained_variance | -2.47e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -29       |\n",
      "|    value_loss         | 10.6      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=-1300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.3e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.1    |\n",
      "|    explained_variance | -26.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 92.6     |\n",
      "|    value_loss         | 173      |\n",
      "------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.14e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 9         |\n",
      "|    iterations      | 800       |\n",
      "|    time_elapsed    | 413       |\n",
      "|    total_timesteps | 4000      |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.14e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 427       |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.99     |\n",
      "|    explained_variance | -3.7e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -26.3     |\n",
      "|    value_loss         | 9.5       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.12e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 448       |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.86     |\n",
      "|    explained_variance | -5.22e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 5.84      |\n",
      "|    value_loss         | 0.611     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.12e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 463       |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.3      |\n",
      "|    explained_variance | -1.37e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 5.86      |\n",
      "|    value_loss         | 0.733     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=-1299.20 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -1.3e+03  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.12     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -19.7     |\n",
      "|    value_loss         | 8.1       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -1.1e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 9        |\n",
      "|    iterations      | 1200     |\n",
      "|    time_elapsed    | 609      |\n",
      "|    total_timesteps | 6000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 622      |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.56    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -21.3    |\n",
      "|    value_loss         | 7.65     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.11e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 642       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.9      |\n",
      "|    explained_variance | -2.62e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 7.5       |\n",
      "|    value_loss         | 1.24      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.11e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 658       |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.82     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -18.1     |\n",
      "|    value_loss         | 6.98      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=8000, episode_reward=-1299.20 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.3e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.76    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -18.2    |\n",
      "|    value_loss         | 6.61     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -1.1e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 9        |\n",
      "|    iterations      | 1600     |\n",
      "|    time_elapsed    | 803      |\n",
      "|    total_timesteps | 8000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 815      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.56    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -20.1    |\n",
      "|    value_loss         | 6.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 835      |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -16.8    |\n",
      "|    value_loss         | 5.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 845      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.97    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -12.7    |\n",
      "|    value_loss         | 5.63     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-312.00 +/- 11.87\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -312     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.54    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -17.2    |\n",
      "|    value_loss         | 5.39     |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.11e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 10        |\n",
      "|    iterations      | 2000      |\n",
      "|    time_elapsed    | 991       |\n",
      "|    total_timesteps | 10000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.11e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 1004      |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.9      |\n",
      "|    explained_variance | 4.35e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | -13.8     |\n",
      "|    value_loss         | 5.31      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.09e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 1026      |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.51     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 11.3      |\n",
      "|    value_loss         | 2.55      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.09e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 1039      |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.09     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -13.1     |\n",
      "|    value_loss         | 5.05      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=-1152.00 +/- 120.88\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -1.15e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.12     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 6.84      |\n",
      "|    value_loss         | 2.99      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -1.1e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 2400     |\n",
      "|    time_elapsed    | 1187     |\n",
      "|    total_timesteps | 12000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 1197     |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.79    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -11.9    |\n",
      "|    value_loss         | 4.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 1216     |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.69    |\n",
      "|    explained_variance | 2.98e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 11.9     |\n",
      "|    value_loss         | 3.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 1229     |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.79    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 8.26     |\n",
      "|    value_loss         | 3.35     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=14000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.17    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -9.59    |\n",
      "|    value_loss         | 4.49     |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.09e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 10        |\n",
      "|    iterations      | 2800      |\n",
      "|    time_elapsed    | 1375      |\n",
      "|    total_timesteps | 14000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.09e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 1388      |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -13.1     |\n",
      "|    value_loss         | 4.5       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.08e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 1409      |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.34     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -10       |\n",
      "|    value_loss         | 4.62      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.08e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 1423      |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.67     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -8.15     |\n",
      "|    value_loss         | 4.82      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=-1100.00 +/- 400.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.76    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 7.43     |\n",
      "|    value_loss         | 2.66     |\n",
      "------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.05e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 10        |\n",
      "|    iterations      | 3200      |\n",
      "|    time_elapsed    | 1566      |\n",
      "|    total_timesteps | 16000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.05e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 1576      |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.12     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 5.33      |\n",
      "|    value_loss         | 2.37      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.03e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 1593      |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.44     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 5.26      |\n",
      "|    value_loss         | 2.46      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -1.03e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 1602      |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.19     |\n",
      "|    explained_variance | 4.12e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -6.39     |\n",
      "|    value_loss         | 5.73      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=18000, episode_reward=-1100.00 +/- 400.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.33    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 4.22     |\n",
      "|    value_loss         | 1.77     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -999     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 3600     |\n",
      "|    time_elapsed    | 1744     |\n",
      "|    total_timesteps | 18000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -999      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 1754      |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.09     |\n",
      "|    explained_variance | -9.06e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 4.18      |\n",
      "|    value_loss         | 1.48      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -966     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 1770     |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.68    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 3.2      |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -966     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 1779     |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.52    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 3.49     |\n",
      "|    value_loss         | 1.01     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=20000, episode_reward=-1300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.3e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 2.05     |\n",
      "|    value_loss         | 0.751    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -941     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 4000     |\n",
      "|    time_elapsed    | 1921     |\n",
      "|    total_timesteps | 20000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -941     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 1930     |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.17    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 1.82     |\n",
      "|    value_loss         | 0.605    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -915     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 1946     |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 1.13     |\n",
      "|    value_loss         | 0.423    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -915     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 1956     |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 2.12     |\n",
      "|    value_loss         | 0.318    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=22000, episode_reward=-1100.00 +/- 400.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.81    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.64     |\n",
      "|    value_loss         | 0.226    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -889     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 4400     |\n",
      "|    time_elapsed    | 2098     |\n",
      "|    total_timesteps | 22000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -889     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 2106     |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.798    |\n",
      "|    value_loss         | 0.178    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -866     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 2123     |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.4     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.211    |\n",
      "|    value_loss         | 0.136    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -866     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 2131     |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.79    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 0.281    |\n",
      "|    value_loss         | 0.111    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=-309.60 +/- 7.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -310     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.154   |\n",
      "|    value_loss         | 0.0949   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -842     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 4800     |\n",
      "|    time_elapsed    | 2274     |\n",
      "|    total_timesteps | 24000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -842      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 2282      |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.854    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -3.53e-05 |\n",
      "|    value_loss         | 0.0896    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -821     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 2299     |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0.552   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -821     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 2308     |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.958   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -0.0102  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=26000, episode_reward=-304.80 +/- 2.99\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -305     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -0.0159  |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -801     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 5200     |\n",
      "|    time_elapsed    | 2450     |\n",
      "|    total_timesteps | 26000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -801     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 2459     |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -0.149   |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -783     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 2475     |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -0.0359  |\n",
      "|    value_loss         | 0.0893   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -783     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 2484     |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -0.134   |\n",
      "|    value_loss         | 0.0893   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=28000, episode_reward=-304.80 +/- 4.66\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -305     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.84    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -0.281   |\n",
      "|    value_loss         | 0.0899   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -766     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 5600     |\n",
      "|    time_elapsed    | 2626     |\n",
      "|    total_timesteps | 28000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -766     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 2635     |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -0.104   |\n",
      "|    value_loss         | 0.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -751     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 2652     |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -0.122   |\n",
      "|    value_loss         | 0.0906   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -751     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 2660     |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.8     |\n",
      "|    explained_variance | 6.74e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -0.116   |\n",
      "|    value_loss         | 0.0906   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-312.80 +/- 9.93\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -313      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.99     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -0.616    |\n",
      "|    value_loss         | 0.0909    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -736     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 6000     |\n",
      "|    time_elapsed    | 2802     |\n",
      "|    total_timesteps | 30000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -736     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 2811     |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.75    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -0.548   |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -723     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 2827     |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -0.11    |\n",
      "|    value_loss         | 0.0904   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -723     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 2836     |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.67    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -0.179   |\n",
      "|    value_loss         | 0.0899   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=32000, episode_reward=-309.60 +/- 13.53\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -310      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.42     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -0.312    |\n",
      "|    value_loss         | 0.0905    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -710     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 6400     |\n",
      "|    time_elapsed    | 2978     |\n",
      "|    total_timesteps | 32000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -710      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 2987      |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.67     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -0.368    |\n",
      "|    value_loss         | 0.0913    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -697      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 3004      |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.08     |\n",
      "|    explained_variance | -1.81e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | -0.292    |\n",
      "|    value_loss         | 0.0915    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -697     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 3013     |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0.207   |\n",
      "|    value_loss         | 0.0897   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=34000, episode_reward=-309.60 +/- 13.29\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -310     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.76    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -0.0748  |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -688     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 6800     |\n",
      "|    time_elapsed    | 3156     |\n",
      "|    total_timesteps | 34000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -688     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 3165     |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -0.0545  |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -679     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 3182     |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.74    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -0.0347  |\n",
      "|    value_loss         | 0.0898   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -679     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 3190     |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.265   |\n",
      "|    value_loss         | 0.0896   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=36000, episode_reward=-298.60 +/- 11.38\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -299     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.7     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -0.068   |\n",
      "|    value_loss         | 0.0895   |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -670     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 7200     |\n",
      "|    time_elapsed    | 3332     |\n",
      "|    total_timesteps | 36000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -670     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 3341     |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.91    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -0.029   |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -662     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 3358     |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.57    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -0.658   |\n",
      "|    value_loss         | 0.0893   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -662     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 3367     |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.92    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 0.0593   |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=38000, episode_reward=-308.00 +/- 7.59\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -308     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.74    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 0.413    |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -659     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 7600     |\n",
      "|    time_elapsed    | 3511     |\n",
      "|    total_timesteps | 38000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -659     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 3522     |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 0.0047   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -651     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 3539     |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.56    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 0.0099   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -651      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 3548      |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.96     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -3.77     |\n",
      "|    value_loss         | 13.2      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-302.60 +/- 13.91\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -303     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.91    |\n",
      "|    explained_variance | -1.5e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -0.163   |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -649     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 8000     |\n",
      "|    time_elapsed    | 3696     |\n",
      "|    total_timesteps | 40000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -649      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 3707      |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.39     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 0.0883    |\n",
      "|    value_loss         | 0.0954    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -649     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 3724     |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.18    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -7.47    |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -649     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 3735     |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.56    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 0.117    |\n",
      "|    value_loss         | 0.101    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=42000, episode_reward=-318.40 +/- 9.33\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -318      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.22     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -0.0417   |\n",
      "|    value_loss         | 0.125     |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -653     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 8400     |\n",
      "|    time_elapsed    | 3878     |\n",
      "|    total_timesteps | 42000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -653     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 3889     |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.55    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 0.00639  |\n",
      "|    value_loss         | 0.123    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -657     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 3906     |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.56    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -2.96    |\n",
      "|    value_loss         | 11.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -657     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 3916     |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.19    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -22.6    |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=44000, episode_reward=-901.60 +/- 487.94\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -902     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 2.49     |\n",
      "|    value_loss         | 0.276    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -667     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 8800     |\n",
      "|    time_elapsed    | 4059     |\n",
      "|    total_timesteps | 44000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -667     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 4072     |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 1.26     |\n",
      "|    value_loss         | 0.322    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -666     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 4090     |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.27    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 0.235    |\n",
      "|    value_loss         | 0.263    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -666     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 4101     |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -17.8    |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=46000, episode_reward=-508.00 +/- 396.01\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -508     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -19.4    |\n",
      "|    value_loss         | 9.9      |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -672     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 9200     |\n",
      "|    time_elapsed    | 4247     |\n",
      "|    total_timesteps | 46000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -672      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 4256      |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.26     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 0.659     |\n",
      "|    value_loss         | 0.325     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -670      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 4274      |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.68     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 0.321     |\n",
      "|    value_loss         | 0.274     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -670     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 4284     |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.58    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 2.4      |\n",
      "|    value_loss         | 0.343    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=-301.60 +/- 3.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -302      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.93     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | 0.994     |\n",
      "|    value_loss         | 0.257     |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -671     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 9600     |\n",
      "|    time_elapsed    | 4427     |\n",
      "|    total_timesteps | 48000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -671      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 4437      |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.53     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | -20.2     |\n",
      "|    value_loss         | 10        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -681     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 4455     |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.81    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -17.4    |\n",
      "|    value_loss         | 9.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -681     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 4465     |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 0.432    |\n",
      "|    value_loss         | 0.323    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=50000, episode_reward=-304.80 +/- 9.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -305     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.75    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 0.0498   |\n",
      "|    value_loss         | 0.271    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -676     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 10000    |\n",
      "|    time_elapsed    | 4607     |\n",
      "|    total_timesteps | 50000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -676     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 4616     |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.836   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 0.048    |\n",
      "|    value_loss         | 0.209    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -669     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 4633     |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1       |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 0.151    |\n",
      "|    value_loss         | 0.162    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -669     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 4643     |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.881   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 0.141    |\n",
      "|    value_loss         | 0.133    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=52000, episode_reward=-508.00 +/- 396.13\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -508     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 0.0434   |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -663     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 10400    |\n",
      "|    time_elapsed    | 4784     |\n",
      "|    total_timesteps | 52000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -663     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 4793     |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.708   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -0.0939  |\n",
      "|    value_loss         | 0.0946   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -656      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 4809      |\n",
      "|    total_timesteps    | 53000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.986    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | 0.132     |\n",
      "|    value_loss         | 0.0891    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -656     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 4818     |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 0.156    |\n",
      "|    value_loss         | 0.099    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=54000, episode_reward=-305.60 +/- 6.97\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -306     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.14    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 0.00156  |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -656     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 10800    |\n",
      "|    time_elapsed    | 4960     |\n",
      "|    total_timesteps | 54000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -656     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 4969     |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 0.0385   |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -650     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 4986     |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -0.15    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -650     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 4995     |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -0.392   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aylam\\desktop\\Bachelorarbeit\\SARL_Env_v3.py\", line 174, in step\n",
      "    receivedMazeCom = self.agent.client.in_.read_maze_com()\n",
      "  File \"C:\\Users\\aylam\\desktop\\Bachelorarbeit\\XmlInputStream.py\", line 231, in read_maze_com\n",
      "    data += self.input_stream.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "Eval num_timesteps=56000, episode_reward=-263.40 +/- 99.50\n",
      "Episode length: 823.20 +/- 353.60\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 823      |\n",
      "|    mean_reward        | -263     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.66    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -0.326   |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -644     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 11200    |\n",
      "|    time_elapsed    | 5124     |\n",
      "|    total_timesteps | 56000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -644     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 5134     |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 0.106    |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -638      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 5151      |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.53     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -0.125    |\n",
      "|    value_loss         | 0.0895    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -638     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 5160     |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.53    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 0.186    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=58000, episode_reward=-705.60 +/- 485.37\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -706     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.24    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -0.545   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -635     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 11600    |\n",
      "|    time_elapsed    | 5303     |\n",
      "|    total_timesteps | 58000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -635      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 5314      |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.58     |\n",
      "|    explained_variance | -1.37e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | 0.141     |\n",
      "|    value_loss         | 0.0914    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -635      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 5331      |\n",
      "|    total_timesteps    | 59000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.34     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | -0.266    |\n",
      "|    value_loss         | 0.0895    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -635     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 5341     |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.78    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -0.0943  |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-700.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -700      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.9      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -0.41     |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -630     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 12000    |\n",
      "|    time_elapsed    | 5482     |\n",
      "|    total_timesteps | 60000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -630     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 5493     |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 0.229    |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -625     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 5510     |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -27      |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -625     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 5519     |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.19    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -0.16    |\n",
      "|    value_loss         | 0.0893   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=62000, episode_reward=-306.40 +/- 5.99\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -306     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.34    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -0.221   |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -620     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 12400    |\n",
      "|    time_elapsed    | 5661     |\n",
      "|    total_timesteps | 62000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -620     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 5670     |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -0.0745  |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -617     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 5686     |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 0.0407   |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -617     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 5695     |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -0.143   |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=-507.20 +/- 396.44\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -507     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.81    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -0.094   |\n",
      "|    value_loss         | 0.0897   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -613     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 12800    |\n",
      "|    time_elapsed    | 5837     |\n",
      "|    total_timesteps | 64000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -613      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 5847      |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.14     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | -0.242    |\n",
      "|    value_loss         | 0.0901    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -609     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 5863     |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -0.013   |\n",
      "|    value_loss         | 0.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -609     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 5872     |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.83    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -0.411   |\n",
      "|    value_loss         | 0.0899   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=66000, episode_reward=-1300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.3e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -0.187   |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -604     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 13200    |\n",
      "|    time_elapsed    | 6014     |\n",
      "|    total_timesteps | 66000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -604     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 6023     |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.65    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -11.5    |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -607     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 6041     |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.25    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -0.197   |\n",
      "|    value_loss         | 0.0941   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -607     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 6051     |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -20      |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=68000, episode_reward=-901.60 +/- 487.94\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -902     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.68    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -0.217   |\n",
      "|    value_loss         | 0.0971   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -607     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 13600    |\n",
      "|    time_elapsed    | 6193     |\n",
      "|    total_timesteps | 68000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -607     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 6204     |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -0.353   |\n",
      "|    value_loss         | 0.091    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -606     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 6221     |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.82    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -0.15    |\n",
      "|    value_loss         | 0.0938   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -606      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 6232      |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.41     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | 0.0124    |\n",
      "|    value_loss         | 0.0989    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-421.80 +/- 253.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -422     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -8.45    |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -605     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 14000    |\n",
      "|    time_elapsed    | 6382     |\n",
      "|    total_timesteps | 70000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -605     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 6393     |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 0.0619   |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -604     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 6411     |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.54    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -13.4    |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -604     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 6423     |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.8     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 0.0406   |\n",
      "|    value_loss         | 0.0925   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=72000, episode_reward=-1105.60 +/- 388.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -1.11e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | -21.6     |\n",
      "|    value_loss         | 12.5      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -605     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 14400    |\n",
      "|    time_elapsed    | 6568     |\n",
      "|    total_timesteps | 72000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -605     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 6577     |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 0.521    |\n",
      "|    value_loss         | 0.107    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -609     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 6596     |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -15.2    |\n",
      "|    value_loss         | 11.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -609     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 6608     |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 0.814    |\n",
      "|    value_loss         | 0.157    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=74000, episode_reward=-507.20 +/- 396.43\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -507     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.17    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -13.6    |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -610     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 14800    |\n",
      "|    time_elapsed    | 6753     |\n",
      "|    total_timesteps | 74000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -610     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 6762     |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 0.0851   |\n",
      "|    value_loss         | 0.135    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -607     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 6778     |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.62    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -0.377   |\n",
      "|    value_loss         | 0.109    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -607     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 6788     |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 0.34     |\n",
      "|    value_loss         | 0.0965   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=76000, episode_reward=-512.80 +/- 393.74\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -513     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -0.196   |\n",
      "|    value_loss         | 0.0898   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -603     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 15200    |\n",
      "|    time_elapsed    | 6930     |\n",
      "|    total_timesteps | 76000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -603      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 6939      |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.74     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | -0.324    |\n",
      "|    value_loss         | 0.0883    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -599     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 6955     |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.74    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -0.0384  |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -599     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 6964     |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -0.316   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=78000, episode_reward=-506.60 +/- 377.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -507     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.57    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -0.0568  |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -596     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 15600    |\n",
      "|    time_elapsed    | 7107     |\n",
      "|    total_timesteps | 78000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -596     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 7117     |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.98    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -0.0918  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -599     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 7134     |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.09    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -8.61    |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -599     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 7144     |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.72    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -12.2    |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-1100.00 +/- 400.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.11    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 0.454    |\n",
      "|    value_loss         | 0.107    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -599     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 16000    |\n",
      "|    time_elapsed    | 7287     |\n",
      "|    total_timesteps | 80000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -599     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 7296     |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.6     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -0.0261  |\n",
      "|    value_loss         | 0.096    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -597     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 7313     |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 0.071    |\n",
      "|    value_loss         | 0.095    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -597     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 7326     |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 1.13     |\n",
      "|    value_loss         | 0.119    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=82000, episode_reward=-704.00 +/- 486.66\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -704     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.18    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -11.9    |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -602     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 16400    |\n",
      "|    time_elapsed    | 7472     |\n",
      "|    total_timesteps | 82000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -602      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 7482      |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.17     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | 0.946     |\n",
      "|    value_loss         | 0.142     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -602     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 7501     |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.05    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 0.348    |\n",
      "|    value_loss         | 0.135    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -602     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 7512     |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -0.0547  |\n",
      "|    value_loss         | 0.11     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=84000, episode_reward=-305.60 +/- 7.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -306     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2       |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 0.282    |\n",
      "|    value_loss         | 0.0963   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -599     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 16800    |\n",
      "|    time_elapsed    | 7656     |\n",
      "|    total_timesteps | 84000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -599     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 7665     |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.38    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 0.0558   |\n",
      "|    value_loss         | 0.0918   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -596     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 7682     |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.46    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -0.123   |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -596     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 7691     |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.7     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -0.184   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=86000, episode_reward=-501.60 +/- 399.21\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -502     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.84    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -0.044   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -593     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 17200    |\n",
      "|    time_elapsed    | 7845     |\n",
      "|    total_timesteps | 86000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -593      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 7856      |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.67     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | -0.0728   |\n",
      "|    value_loss         | 0.0884    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -592     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 7872     |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.36    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -7.61    |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -592     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 7883     |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.99    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -0.0245  |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=88000, episode_reward=-657.60 +/- 369.58\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -658     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.65    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 0.186    |\n",
      "|    value_loss         | 0.0954   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -593     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 17600    |\n",
      "|    time_elapsed    | 8027     |\n",
      "|    total_timesteps | 88000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -593     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 8038     |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -19.3    |\n",
      "|    value_loss         | 11.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -598     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 8055     |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -11.8    |\n",
      "|    value_loss         | 11.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -598      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 8064      |\n",
      "|    total_timesteps    | 89500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.83     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | 0.775     |\n",
      "|    value_loss         | 0.155     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-900.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -900     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.48    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 0.85     |\n",
      "|    value_loss         | 0.135    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -597     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 18000    |\n",
      "|    time_elapsed    | 8206     |\n",
      "|    total_timesteps | 90000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -597     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 8216     |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.11    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -14.8    |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -595     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 8233     |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.18    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 0.438    |\n",
      "|    value_loss         | 0.105    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -595     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 8242     |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 0.0662   |\n",
      "|    value_loss         | 0.0946   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=92000, episode_reward=-500.80 +/- 399.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -501     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 0.336    |\n",
      "|    value_loss         | 0.0898   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -593     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 18400    |\n",
      "|    time_elapsed    | 8384     |\n",
      "|    total_timesteps | 92000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -593     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 8394     |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.6     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -0.0966  |\n",
      "|    value_loss         | 0.0894   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -591      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 8411      |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.65     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | 0.491     |\n",
      "|    value_loss         | 0.0887    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -591     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 8420     |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.84    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 0.0293   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=94000, episode_reward=-508.00 +/- 396.08\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -508      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 94000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.19     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | 0.24      |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -589     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 18800    |\n",
      "|    time_elapsed    | 8562     |\n",
      "|    total_timesteps | 94000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -589     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 8571     |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -0.226   |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -586      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 8587      |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.07     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | -0.16     |\n",
      "|    value_loss         | 0.0893    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -586     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 8595     |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.04    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -0.286   |\n",
      "|    value_loss         | 0.0893   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=-306.40 +/- 8.24\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -306     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -0.801   |\n",
      "|    value_loss         | 0.0896   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -583     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 19200    |\n",
      "|    time_elapsed    | 8737     |\n",
      "|    total_timesteps | 96000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -583     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 8746     |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -0.337   |\n",
      "|    value_loss         | 0.0895   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -580     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 8762     |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.91    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -0.183   |\n",
      "|    value_loss         | 0.0899   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -580     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 8771     |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.47    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -0.0538  |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=98000, episode_reward=-1300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.3e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.44    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 0.0348   |\n",
      "|    value_loss         | 0.0906   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -578     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 19600    |\n",
      "|    time_elapsed    | 8913     |\n",
      "|    total_timesteps | 98000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -578     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 8922     |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -0.0703  |\n",
      "|    value_loss         | 0.0894   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -575      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 8939      |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.94     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | -0.178    |\n",
      "|    value_loss         | 0.09      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -575      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 8948      |\n",
      "|    total_timesteps    | 99500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.99     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | -0.138    |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-700.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -700      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 100000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.04     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | -0.0287   |\n",
      "|    value_loss         | 0.0885    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -575     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 20000    |\n",
      "|    time_elapsed    | 9091     |\n",
      "|    total_timesteps | 100000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -575     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 20100    |\n",
      "|    time_elapsed       | 9100     |\n",
      "|    total_timesteps    | 100500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.55    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20099    |\n",
      "|    policy_loss        | -0.0717  |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -566     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 20200    |\n",
      "|    time_elapsed       | 9117     |\n",
      "|    total_timesteps    | 101000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.67    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20199    |\n",
      "|    policy_loss        | -0.684   |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -566     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 20300    |\n",
      "|    time_elapsed       | 9126     |\n",
      "|    total_timesteps    | 101500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.24    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20299    |\n",
      "|    policy_loss        | -0.116   |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=102000, episode_reward=-700.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -700     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 102000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.52    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20399    |\n",
      "|    policy_loss        | 0.149    |\n",
      "|    value_loss         | 0.0895   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -559     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 20400    |\n",
      "|    time_elapsed    | 9268     |\n",
      "|    total_timesteps | 102000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -559     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 20500    |\n",
      "|    time_elapsed       | 9277     |\n",
      "|    total_timesteps    | 102500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20499    |\n",
      "|    policy_loss        | 0.247    |\n",
      "|    value_loss         | 0.0896   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -551     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 20600    |\n",
      "|    time_elapsed       | 9293     |\n",
      "|    total_timesteps    | 103000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.29    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20599    |\n",
      "|    policy_loss        | -0.0661  |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -551     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 20700    |\n",
      "|    time_elapsed       | 9302     |\n",
      "|    total_timesteps    | 103500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20699    |\n",
      "|    policy_loss        | -0.477   |\n",
      "|    value_loss         | 0.0894   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=104000, episode_reward=-1104.00 +/- 392.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -1.1e+03  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 104000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.22     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20799     |\n",
      "|    policy_loss        | -0.494    |\n",
      "|    value_loss         | 0.0901    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -543     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 20800    |\n",
      "|    time_elapsed    | 9444     |\n",
      "|    total_timesteps | 104000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -543     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 20900    |\n",
      "|    time_elapsed       | 9452     |\n",
      "|    total_timesteps    | 104500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20899    |\n",
      "|    policy_loss        | 0.241    |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -538     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 21000    |\n",
      "|    time_elapsed       | 9468     |\n",
      "|    total_timesteps    | 105000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.47    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20999    |\n",
      "|    policy_loss        | -0.202   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -538     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 21100    |\n",
      "|    time_elapsed       | 9477     |\n",
      "|    total_timesteps    | 105500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.17    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21099    |\n",
      "|    policy_loss        | -0.125   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=106000, episode_reward=-501.60 +/- 399.21\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -502      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 106000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.08     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21199     |\n",
      "|    policy_loss        | -0.417    |\n",
      "|    value_loss         | 0.0887    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -531     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 21200    |\n",
      "|    time_elapsed    | 9620     |\n",
      "|    total_timesteps | 106000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -531     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 21300    |\n",
      "|    time_elapsed       | 9629     |\n",
      "|    total_timesteps    | 106500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21299    |\n",
      "|    policy_loss        | 0.0676   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -524     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 21400    |\n",
      "|    time_elapsed       | 9646     |\n",
      "|    total_timesteps    | 107000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.75    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21399    |\n",
      "|    policy_loss        | -0.0826  |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -524     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 21500    |\n",
      "|    time_elapsed       | 9655     |\n",
      "|    total_timesteps    | 107500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.54    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21499    |\n",
      "|    policy_loss        | 0.0989   |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=108000, episode_reward=-909.60 +/- 478.15\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -910     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 108000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.29    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21599    |\n",
      "|    policy_loss        | -0.528   |\n",
      "|    value_loss         | 0.0894   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -517     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 21600    |\n",
      "|    time_elapsed    | 9796     |\n",
      "|    total_timesteps | 108000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -517      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 21700     |\n",
      "|    time_elapsed       | 9805      |\n",
      "|    total_timesteps    | 108500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.78     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21699     |\n",
      "|    policy_loss        | -0.12     |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -510      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 21800     |\n",
      "|    time_elapsed       | 9821      |\n",
      "|    total_timesteps    | 109000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.99     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21799     |\n",
      "|    policy_loss        | -0.204    |\n",
      "|    value_loss         | 0.0888    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -510      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 21900     |\n",
      "|    time_elapsed       | 9830      |\n",
      "|    total_timesteps    | 109500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2        |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21899     |\n",
      "|    policy_loss        | -0.545    |\n",
      "|    value_loss         | 0.0887    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-308.20 +/- 21.25\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -308     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 110000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.73    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21999    |\n",
      "|    policy_loss        | 0.414    |\n",
      "|    value_loss         | 0.0892   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -501     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 22000    |\n",
      "|    time_elapsed    | 9972     |\n",
      "|    total_timesteps | 110000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -501     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 22100    |\n",
      "|    time_elapsed       | 9981     |\n",
      "|    total_timesteps    | 110500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22099    |\n",
      "|    policy_loss        | -0.205   |\n",
      "|    value_loss         | 0.0898   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -495     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 22200    |\n",
      "|    time_elapsed       | 9997     |\n",
      "|    total_timesteps    | 111000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.19    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22199    |\n",
      "|    policy_loss        | -0.00366 |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -495     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 22300    |\n",
      "|    time_elapsed       | 10007    |\n",
      "|    total_timesteps    | 111500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.47    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22299    |\n",
      "|    policy_loss        | 0.0613   |\n",
      "|    value_loss         | 0.0897   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=-700.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -700     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 112000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.76    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22399    |\n",
      "|    policy_loss        | -0.277   |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -487     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 22400    |\n",
      "|    time_elapsed    | 10149    |\n",
      "|    total_timesteps | 112000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -487     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 22500    |\n",
      "|    time_elapsed       | 10158    |\n",
      "|    total_timesteps    | 112500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22499    |\n",
      "|    policy_loss        | -0.26    |\n",
      "|    value_loss         | 0.0906   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -478     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 22600    |\n",
      "|    time_elapsed       | 10175    |\n",
      "|    total_timesteps    | 113000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.44    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22599    |\n",
      "|    policy_loss        | -0.203   |\n",
      "|    value_loss         | 0.091    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -478     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 22700    |\n",
      "|    time_elapsed       | 10184    |\n",
      "|    total_timesteps    | 113500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22699    |\n",
      "|    policy_loss        | -0.325   |\n",
      "|    value_loss         | 0.0915   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=114000, episode_reward=-310.40 +/- 8.98\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -310      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 114000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.1      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22799     |\n",
      "|    policy_loss        | 0.11      |\n",
      "|    value_loss         | 0.0917    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -472     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 22800    |\n",
      "|    time_elapsed    | 10326    |\n",
      "|    total_timesteps | 114000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -472     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 22900    |\n",
      "|    time_elapsed       | 10335    |\n",
      "|    total_timesteps    | 114500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.688   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22899    |\n",
      "|    policy_loss        | 0.107    |\n",
      "|    value_loss         | 0.0912   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -466     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 23000    |\n",
      "|    time_elapsed       | 10352    |\n",
      "|    total_timesteps    | 115000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22999    |\n",
      "|    policy_loss        | -0.084   |\n",
      "|    value_loss         | 0.0913   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -466     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 23100    |\n",
      "|    time_elapsed       | 10360    |\n",
      "|    total_timesteps    | 115500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.474   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23099    |\n",
      "|    policy_loss        | -0.0083  |\n",
      "|    value_loss         | 0.0908   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=116000, episode_reward=-310.40 +/- 12.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -310     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 116000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.592   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23199    |\n",
      "|    policy_loss        | -0.0102  |\n",
      "|    value_loss         | 0.0904   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -463     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 23200    |\n",
      "|    time_elapsed    | 10503    |\n",
      "|    total_timesteps | 116000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -463     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 23300    |\n",
      "|    time_elapsed       | 10513    |\n",
      "|    total_timesteps    | 116500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23299    |\n",
      "|    policy_loss        | -0.0067  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -460     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 23400    |\n",
      "|    time_elapsed       | 10529    |\n",
      "|    total_timesteps    | 117000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.68    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23399    |\n",
      "|    policy_loss        | -0.00587 |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -460      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 23500     |\n",
      "|    time_elapsed       | 10538     |\n",
      "|    total_timesteps    | 117500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.08     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23499     |\n",
      "|    policy_loss        | -0.00456  |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=118000, episode_reward=-303.40 +/- 3.77\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -303      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 118000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.53     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23599     |\n",
      "|    policy_loss        | -0.317    |\n",
      "|    value_loss         | 0.0886    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -461     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 23600    |\n",
      "|    time_elapsed    | 10680    |\n",
      "|    total_timesteps | 118000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -461     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 23700    |\n",
      "|    time_elapsed       | 10689    |\n",
      "|    total_timesteps    | 118500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.31    |\n",
      "|    explained_variance | -1.7e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23699    |\n",
      "|    policy_loss        | -0.08    |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -461     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 23800    |\n",
      "|    time_elapsed       | 10706    |\n",
      "|    total_timesteps    | 119000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23799    |\n",
      "|    policy_loss        | -0.0571  |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -461      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 23900     |\n",
      "|    time_elapsed       | 10715     |\n",
      "|    total_timesteps    | 119500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.86     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23899     |\n",
      "|    policy_loss        | -0.425    |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-314.40 +/- 13.53\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -314     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 120000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.31    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23999    |\n",
      "|    policy_loss        | 0.183    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -461     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 24000    |\n",
      "|    time_elapsed    | 10858    |\n",
      "|    total_timesteps | 120000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -461     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 24100    |\n",
      "|    time_elapsed       | 10866    |\n",
      "|    total_timesteps    | 120500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24099    |\n",
      "|    policy_loss        | -13.3    |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -461     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 24200    |\n",
      "|    time_elapsed       | 10883    |\n",
      "|    total_timesteps    | 121000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.34    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24199    |\n",
      "|    policy_loss        | 0.0531   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -461     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 24300    |\n",
      "|    time_elapsed       | 10892    |\n",
      "|    total_timesteps    | 121500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.24    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24299    |\n",
      "|    policy_loss        | 0.195    |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=122000, episode_reward=-310.40 +/- 9.67\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -310     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 122000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.65    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24399    |\n",
      "|    policy_loss        | -0.116   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -462     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 24400    |\n",
      "|    time_elapsed    | 11035    |\n",
      "|    total_timesteps | 122000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -462     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 24500    |\n",
      "|    time_elapsed       | 11044    |\n",
      "|    total_timesteps    | 122500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24499    |\n",
      "|    policy_loss        | -0.13    |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -462     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 24600    |\n",
      "|    time_elapsed       | 11061    |\n",
      "|    total_timesteps    | 123000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.49    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24599    |\n",
      "|    policy_loss        | 0.0951   |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -462      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 24700     |\n",
      "|    time_elapsed       | 11070     |\n",
      "|    total_timesteps    | 123500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.87     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24699     |\n",
      "|    policy_loss        | -0.371    |\n",
      "|    value_loss         | 0.0886    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=124000, episode_reward=-507.20 +/- 396.44\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -507     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 124000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.24    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24799    |\n",
      "|    policy_loss        | 0.031    |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -463     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 24800    |\n",
      "|    time_elapsed    | 11213    |\n",
      "|    total_timesteps | 124000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -463     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 24900    |\n",
      "|    time_elapsed       | 11222    |\n",
      "|    total_timesteps    | 124500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24899    |\n",
      "|    policy_loss        | 0.304    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -465     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 25000    |\n",
      "|    time_elapsed       | 11239    |\n",
      "|    total_timesteps    | 125000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.71    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24999    |\n",
      "|    policy_loss        | 0.299    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -465      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 25100     |\n",
      "|    time_elapsed       | 11249     |\n",
      "|    total_timesteps    | 125500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.78     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25099     |\n",
      "|    policy_loss        | 0.0192    |\n",
      "|    value_loss         | 0.0884    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=126000, episode_reward=-307.20 +/- 3.92\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -307      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 126000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.7      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25199     |\n",
      "|    policy_loss        | -0.0894   |\n",
      "|    value_loss         | 0.0887    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -465     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 25200    |\n",
      "|    time_elapsed    | 11391    |\n",
      "|    total_timesteps | 126000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -465     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 25300    |\n",
      "|    time_elapsed       | 11400    |\n",
      "|    total_timesteps    | 126500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25299    |\n",
      "|    policy_loss        | 0.0288   |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -465     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 25400    |\n",
      "|    time_elapsed       | 11416    |\n",
      "|    total_timesteps    | 127000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.72    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25399    |\n",
      "|    policy_loss        | -0.103   |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -465     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 25500    |\n",
      "|    time_elapsed       | 11425    |\n",
      "|    total_timesteps    | 127500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25499    |\n",
      "|    policy_loss        | -0.116   |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 128000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25599    |\n",
      "|    policy_loss        | 0.129    |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -466     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 25600    |\n",
      "|    time_elapsed    | 11568    |\n",
      "|    total_timesteps | 128000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -466      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 25700     |\n",
      "|    time_elapsed       | 11577     |\n",
      "|    total_timesteps    | 128500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.69     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25699     |\n",
      "|    policy_loss        | 0.051     |\n",
      "|    value_loss         | 0.0891    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -466     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 25800    |\n",
      "|    time_elapsed       | 11594    |\n",
      "|    total_timesteps    | 129000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25799    |\n",
      "|    policy_loss        | -0.0597  |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -466     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 25900    |\n",
      "|    time_elapsed       | 11603    |\n",
      "|    total_timesteps    | 129500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25899    |\n",
      "|    policy_loss        | -0.0231  |\n",
      "|    value_loss         | 0.0893   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-302.60 +/- 5.64\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -303     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 130000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25999    |\n",
      "|    policy_loss        | -0.0705  |\n",
      "|    value_loss         | 0.0897   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -466     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 26000    |\n",
      "|    time_elapsed    | 11746    |\n",
      "|    total_timesteps | 130000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -466     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 26100    |\n",
      "|    time_elapsed       | 11755    |\n",
      "|    total_timesteps    | 130500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.985   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26099    |\n",
      "|    policy_loss        | -0.0577  |\n",
      "|    value_loss         | 0.0897   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -466     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 26200    |\n",
      "|    time_elapsed       | 11772    |\n",
      "|    total_timesteps    | 131000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.766   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26199    |\n",
      "|    policy_loss        | -0.157   |\n",
      "|    value_loss         | 0.0904   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -466     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 26300    |\n",
      "|    time_elapsed       | 11781    |\n",
      "|    total_timesteps    | 131500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.73    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26299    |\n",
      "|    policy_loss        | -0.0192  |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=132000, episode_reward=-300.20 +/- 16.59\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 132000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.692   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26399    |\n",
      "|    policy_loss        | -0.0153  |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -466     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 26400    |\n",
      "|    time_elapsed    | 11923    |\n",
      "|    total_timesteps | 132000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -466     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 26500    |\n",
      "|    time_elapsed       | 11932    |\n",
      "|    total_timesteps    | 132500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.947   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26499    |\n",
      "|    policy_loss        | 0.21     |\n",
      "|    value_loss         | 0.0899   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -467     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 26600    |\n",
      "|    time_elapsed       | 11949    |\n",
      "|    total_timesteps    | 133000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26599    |\n",
      "|    policy_loss        | -0.0752  |\n",
      "|    value_loss         | 0.0903   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -467     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 26700    |\n",
      "|    time_elapsed       | 11958    |\n",
      "|    total_timesteps    | 133500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26699    |\n",
      "|    policy_loss        | -0.0538  |\n",
      "|    value_loss         | 0.0899   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=134000, episode_reward=-305.60 +/- 4.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -306      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 134000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.33     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26799     |\n",
      "|    policy_loss        | -0.0349   |\n",
      "|    value_loss         | 0.0904    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -466     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 26800    |\n",
      "|    time_elapsed    | 12101    |\n",
      "|    total_timesteps | 134000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -466     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 26900    |\n",
      "|    time_elapsed       | 12111    |\n",
      "|    total_timesteps    | 134500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.46    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26899    |\n",
      "|    policy_loss        | -0.0934  |\n",
      "|    value_loss         | 0.0903   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -465     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 27000    |\n",
      "|    time_elapsed       | 12128    |\n",
      "|    total_timesteps    | 135000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26999    |\n",
      "|    policy_loss        | -0.106   |\n",
      "|    value_loss         | 0.0906   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -465     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 27100    |\n",
      "|    time_elapsed       | 12137    |\n",
      "|    total_timesteps    | 135500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27099    |\n",
      "|    policy_loss        | -0.166   |\n",
      "|    value_loss         | 0.0898   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=136000, episode_reward=-504.00 +/- 398.02\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -504     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 136000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27199    |\n",
      "|    policy_loss        | -0.339   |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -465     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 27200    |\n",
      "|    time_elapsed    | 12279    |\n",
      "|    total_timesteps | 136000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -465     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 27300    |\n",
      "|    time_elapsed       | 12288    |\n",
      "|    total_timesteps    | 136500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.16    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27299    |\n",
      "|    policy_loss        | -0.162   |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -465     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 27400    |\n",
      "|    time_elapsed       | 12305    |\n",
      "|    total_timesteps    | 137000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27399    |\n",
      "|    policy_loss        | -0.198   |\n",
      "|    value_loss         | 0.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -465     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 27500    |\n",
      "|    time_elapsed       | 12315    |\n",
      "|    total_timesteps    | 137500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27499    |\n",
      "|    policy_loss        | -0.0405  |\n",
      "|    value_loss         | 0.09     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=138000, episode_reward=-304.80 +/- 4.66\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -305     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 138000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.2     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27599    |\n",
      "|    policy_loss        | -0.047   |\n",
      "|    value_loss         | 0.0905   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -463     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 27600    |\n",
      "|    time_elapsed    | 12460    |\n",
      "|    total_timesteps | 138000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -463     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 27700    |\n",
      "|    time_elapsed       | 12469    |\n",
      "|    total_timesteps    | 138500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27699    |\n",
      "|    policy_loss        | 0.0363   |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -466     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 27800    |\n",
      "|    time_elapsed       | 12485    |\n",
      "|    total_timesteps    | 139000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27799    |\n",
      "|    policy_loss        | 0.288    |\n",
      "|    value_loss         | 0.0915   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -466     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 27900    |\n",
      "|    time_elapsed       | 12496    |\n",
      "|    total_timesteps    | 139500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27899    |\n",
      "|    policy_loss        | 0.228    |\n",
      "|    value_loss         | 0.0934   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-480.00 +/- 346.01\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -480     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 140000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27999    |\n",
      "|    policy_loss        | -0.0508  |\n",
      "|    value_loss         | 0.0967   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -466     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 28000    |\n",
      "|    time_elapsed    | 12643    |\n",
      "|    total_timesteps | 140000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -466     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 28100    |\n",
      "|    time_elapsed       | 12655    |\n",
      "|    total_timesteps    | 140500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28099    |\n",
      "|    policy_loss        | -0.00895 |\n",
      "|    value_loss         | 0.0906   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -467     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 28200    |\n",
      "|    time_elapsed       | 12674    |\n",
      "|    total_timesteps    | 141000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28199    |\n",
      "|    policy_loss        | 0.125    |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -467      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 28300     |\n",
      "|    time_elapsed       | 12686     |\n",
      "|    total_timesteps    | 141500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.25     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28299     |\n",
      "|    policy_loss        | 0.358     |\n",
      "|    value_loss         | 0.096     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=142000, episode_reward=-504.00 +/- 398.08\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -504     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 142000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.18    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28399    |\n",
      "|    policy_loss        | -0.0107  |\n",
      "|    value_loss         | 0.0904   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -462     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 28400    |\n",
      "|    time_elapsed    | 12832    |\n",
      "|    total_timesteps | 142000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -462      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 28500     |\n",
      "|    time_elapsed       | 12841     |\n",
      "|    total_timesteps    | 142500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.28     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28499     |\n",
      "|    policy_loss        | -6.29     |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -460     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 28600    |\n",
      "|    time_elapsed       | 12859    |\n",
      "|    total_timesteps    | 143000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28599    |\n",
      "|    policy_loss        | -13.5    |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -460      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 28700     |\n",
      "|    time_elapsed       | 12872     |\n",
      "|    total_timesteps    | 143500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.24     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28699     |\n",
      "|    policy_loss        | -14.3     |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=-1100.00 +/- 400.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -1.1e+03  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 144000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.23     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28799     |\n",
      "|    policy_loss        | -5.2      |\n",
      "|    value_loss         | 12.5      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -456     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 28800    |\n",
      "|    time_elapsed    | 13016    |\n",
      "|    total_timesteps | 144000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -456     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 28900    |\n",
      "|    time_elapsed       | 13028    |\n",
      "|    total_timesteps    | 144500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.98    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28899    |\n",
      "|    policy_loss        | 0.278    |\n",
      "|    value_loss         | 0.101    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -455     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 29000    |\n",
      "|    time_elapsed       | 13048    |\n",
      "|    total_timesteps    | 145000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.24    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28999    |\n",
      "|    policy_loss        | -22.4    |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -455     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 29100    |\n",
      "|    time_elapsed       | 13059    |\n",
      "|    total_timesteps    | 145500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29099    |\n",
      "|    policy_loss        | -3.27    |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=146000, episode_reward=-1101.60 +/- 396.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 146000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.53    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29199    |\n",
      "|    policy_loss        | -0.0531  |\n",
      "|    value_loss         | 0.137    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -455     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 29200    |\n",
      "|    time_elapsed    | 13202    |\n",
      "|    total_timesteps | 146000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -455     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 29300    |\n",
      "|    time_elapsed       | 13215    |\n",
      "|    total_timesteps    | 146500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.11    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29299    |\n",
      "|    policy_loss        | -7.38    |\n",
      "|    value_loss         | 11.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -455      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 29400     |\n",
      "|    time_elapsed       | 13235     |\n",
      "|    total_timesteps    | 147000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.73     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29399     |\n",
      "|    policy_loss        | 0.272     |\n",
      "|    value_loss         | 0.12      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -455     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 29500    |\n",
      "|    time_elapsed       | 13245    |\n",
      "|    total_timesteps    | 147500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29499    |\n",
      "|    policy_loss        | 0.986    |\n",
      "|    value_loss         | 0.127    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=148000, episode_reward=-312.00 +/- 8.76\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -312     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 148000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.67    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29599    |\n",
      "|    policy_loss        | -25.8    |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -455     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 29600    |\n",
      "|    time_elapsed    | 13389    |\n",
      "|    total_timesteps | 148000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -455     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 29700    |\n",
      "|    time_elapsed       | 13400    |\n",
      "|    total_timesteps    | 148500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.34    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29699    |\n",
      "|    policy_loss        | 0.929    |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -447     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 29800    |\n",
      "|    time_elapsed       | 13417    |\n",
      "|    total_timesteps    | 149000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.51    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29799    |\n",
      "|    policy_loss        | -0.118   |\n",
      "|    value_loss         | 0.101    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -447     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 29900    |\n",
      "|    time_elapsed       | 13426    |\n",
      "|    total_timesteps    | 149500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29899    |\n",
      "|    policy_loss        | 0.304    |\n",
      "|    value_loss         | 0.0937   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-514.40 +/- 392.97\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -514     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 150000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.57    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29999    |\n",
      "|    policy_loss        | -0.315   |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -446     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 30000    |\n",
      "|    time_elapsed    | 13568    |\n",
      "|    total_timesteps | 150000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -446     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 30100    |\n",
      "|    time_elapsed       | 13577    |\n",
      "|    total_timesteps    | 150500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30099    |\n",
      "|    policy_loss        | -0.191   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -446     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 30200    |\n",
      "|    time_elapsed       | 13594    |\n",
      "|    total_timesteps    | 151000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30199    |\n",
      "|    policy_loss        | -0.0131  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -446      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 30300     |\n",
      "|    time_elapsed       | 13603     |\n",
      "|    total_timesteps    | 151500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.06     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30299     |\n",
      "|    policy_loss        | -0.264    |\n",
      "|    value_loss         | 0.0884    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=152000, episode_reward=-305.00 +/- 14.67\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -305     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 152000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30399    |\n",
      "|    policy_loss        | -0.0759  |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -446     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 30400    |\n",
      "|    time_elapsed    | 13746    |\n",
      "|    total_timesteps | 152000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -446      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 30500     |\n",
      "|    time_elapsed       | 13755     |\n",
      "|    total_timesteps    | 152500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.25     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30499     |\n",
      "|    policy_loss        | 0.16      |\n",
      "|    value_loss         | 0.0888    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -446      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 30600     |\n",
      "|    time_elapsed       | 13772     |\n",
      "|    total_timesteps    | 153000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.55     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30599     |\n",
      "|    policy_loss        | -0.435    |\n",
      "|    value_loss         | 0.0888    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -446     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 30700    |\n",
      "|    time_elapsed       | 13781    |\n",
      "|    total_timesteps    | 153500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30699    |\n",
      "|    policy_loss        | -0.235   |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=154000, episode_reward=-510.40 +/- 394.92\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -510     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 154000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.61    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30799    |\n",
      "|    policy_loss        | -0.738   |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -443     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 30800    |\n",
      "|    time_elapsed    | 13924    |\n",
      "|    total_timesteps | 154000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -443     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 30900    |\n",
      "|    time_elapsed       | 13933    |\n",
      "|    total_timesteps    | 154500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30899    |\n",
      "|    policy_loss        | -0.0508  |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -444     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 31000    |\n",
      "|    time_elapsed       | 13951    |\n",
      "|    total_timesteps    | 155000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30999    |\n",
      "|    policy_loss        | -0.378   |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -444     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 31100    |\n",
      "|    time_elapsed       | 13960    |\n",
      "|    total_timesteps    | 155500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.78    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31099    |\n",
      "|    policy_loss        | -0.503   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=156000, episode_reward=-505.60 +/- 397.35\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -506     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 156000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.79    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31199    |\n",
      "|    policy_loss        | -0.0621  |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -444     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 31200    |\n",
      "|    time_elapsed    | 14103    |\n",
      "|    total_timesteps | 156000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -444     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 31300    |\n",
      "|    time_elapsed       | 14112    |\n",
      "|    total_timesteps    | 156500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31299    |\n",
      "|    policy_loss        | 0.0667   |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -447     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 31400    |\n",
      "|    time_elapsed       | 14129    |\n",
      "|    total_timesteps    | 157000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.04    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31399    |\n",
      "|    policy_loss        | -0.19    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -447     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 31500    |\n",
      "|    time_elapsed       | 14138    |\n",
      "|    total_timesteps    | 157500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.11    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31499    |\n",
      "|    policy_loss        | -0.141   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=158000, episode_reward=-900.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -900      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 158000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.89     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31599     |\n",
      "|    policy_loss        | -0.149    |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -446     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 31600    |\n",
      "|    time_elapsed    | 14282    |\n",
      "|    total_timesteps | 158000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -446     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 31700    |\n",
      "|    time_elapsed       | 14291    |\n",
      "|    total_timesteps    | 158500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31699    |\n",
      "|    policy_loss        | -0.074   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -445     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 31800    |\n",
      "|    time_elapsed       | 14310    |\n",
      "|    total_timesteps    | 159000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.54    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31799    |\n",
      "|    policy_loss        | -0.0572  |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -445     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 31900    |\n",
      "|    time_elapsed       | 14320    |\n",
      "|    total_timesteps    | 159500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31899    |\n",
      "|    policy_loss        | -13.1    |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-909.60 +/- 478.38\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -910     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 160000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.05    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31999    |\n",
      "|    policy_loss        | -11.4    |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -447     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 32000    |\n",
      "|    time_elapsed    | 14464    |\n",
      "|    total_timesteps | 160000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -447     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 32100    |\n",
      "|    time_elapsed       | 14474    |\n",
      "|    total_timesteps    | 160500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.26    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32099    |\n",
      "|    policy_loss        | -16.2    |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -451      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 32200     |\n",
      "|    time_elapsed       | 14491     |\n",
      "|    total_timesteps    | 161000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.37     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32199     |\n",
      "|    policy_loss        | -11.7     |\n",
      "|    value_loss         | 12.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -451     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 32300    |\n",
      "|    time_elapsed       | 14501    |\n",
      "|    total_timesteps    | 161500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32299    |\n",
      "|    policy_loss        | -21.8    |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=162000, episode_reward=-900.80 +/- 488.92\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -901     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 162000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.59    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32399    |\n",
      "|    policy_loss        | -15.9    |\n",
      "|    value_loss         | 11.3     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -459     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 32400    |\n",
      "|    time_elapsed    | 14647    |\n",
      "|    total_timesteps | 162000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -459     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 32500    |\n",
      "|    time_elapsed       | 14658    |\n",
      "|    total_timesteps    | 162500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32499    |\n",
      "|    policy_loss        | -8.69    |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -461     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 32600    |\n",
      "|    time_elapsed       | 14675    |\n",
      "|    total_timesteps    | 163000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.33    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32599    |\n",
      "|    policy_loss        | 1.2      |\n",
      "|    value_loss         | 0.172    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -461     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 32700    |\n",
      "|    time_elapsed       | 14684    |\n",
      "|    total_timesteps    | 163500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.73    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32699    |\n",
      "|    policy_loss        | 0.157    |\n",
      "|    value_loss         | 0.157    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=164000, episode_reward=-700.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -700     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 164000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.19    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32799    |\n",
      "|    policy_loss        | 0.456    |\n",
      "|    value_loss         | 0.124    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -462     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 32800    |\n",
      "|    time_elapsed    | 14826    |\n",
      "|    total_timesteps | 164000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -462      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 32900     |\n",
      "|    time_elapsed       | 14836     |\n",
      "|    total_timesteps    | 164500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.04     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32899     |\n",
      "|    policy_loss        | 0.0515    |\n",
      "|    value_loss         | 0.115     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -462     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 33000    |\n",
      "|    time_elapsed       | 14852    |\n",
      "|    total_timesteps    | 165000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.66    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32999    |\n",
      "|    policy_loss        | 0.0791   |\n",
      "|    value_loss         | 0.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -462     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 33100    |\n",
      "|    time_elapsed       | 14861    |\n",
      "|    total_timesteps    | 165500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33099    |\n",
      "|    policy_loss        | 0.488    |\n",
      "|    value_loss         | 0.0923   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=166000, episode_reward=-900.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -900      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 166000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.37     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33199     |\n",
      "|    policy_loss        | 0.27      |\n",
      "|    value_loss         | 0.0913    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -463     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 33200    |\n",
      "|    time_elapsed    | 15003    |\n",
      "|    total_timesteps | 166000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -463     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 33300    |\n",
      "|    time_elapsed       | 15012    |\n",
      "|    total_timesteps    | 166500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.54    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33299    |\n",
      "|    policy_loss        | 0.0474   |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -459      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 33400     |\n",
      "|    time_elapsed       | 15029     |\n",
      "|    total_timesteps    | 167000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.47     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33399     |\n",
      "|    policy_loss        | -0.349    |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -459     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 33500    |\n",
      "|    time_elapsed       | 15038    |\n",
      "|    total_timesteps    | 167500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.59    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33499    |\n",
      "|    policy_loss        | -0.0177  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=168000, episode_reward=-311.20 +/- 11.14\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -311     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 168000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33599    |\n",
      "|    policy_loss        | 0.101    |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -456     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 33600    |\n",
      "|    time_elapsed    | 15180    |\n",
      "|    total_timesteps | 168000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -456     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 33700    |\n",
      "|    time_elapsed       | 15190    |\n",
      "|    total_timesteps    | 168500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33699    |\n",
      "|    policy_loss        | -0.0592  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -455     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 33800    |\n",
      "|    time_elapsed       | 15206    |\n",
      "|    total_timesteps    | 169000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.33    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33799    |\n",
      "|    policy_loss        | -0.0545  |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -455     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 33900    |\n",
      "|    time_elapsed       | 15215    |\n",
      "|    total_timesteps    | 169500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.98    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33899    |\n",
      "|    policy_loss        | -0.175   |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-700.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -700     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 170000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33999    |\n",
      "|    policy_loss        | -0.0981  |\n",
      "|    value_loss         | 0.0892   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -453     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 34000    |\n",
      "|    time_elapsed    | 15358    |\n",
      "|    total_timesteps | 170000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -453     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 34100    |\n",
      "|    time_elapsed       | 15368    |\n",
      "|    total_timesteps    | 170500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.1     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34099    |\n",
      "|    policy_loss        | -0.315   |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -451     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 34200    |\n",
      "|    time_elapsed       | 15385    |\n",
      "|    total_timesteps    | 171000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.26    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34199    |\n",
      "|    policy_loss        | -1.21    |\n",
      "|    value_loss         | 0.0893   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -451     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 34300    |\n",
      "|    time_elapsed       | 15394    |\n",
      "|    total_timesteps    | 171500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.7     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34299    |\n",
      "|    policy_loss        | 0.54     |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=172000, episode_reward=-900.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -900      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 172000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.63     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34399     |\n",
      "|    policy_loss        | -26.5     |\n",
      "|    value_loss         | 12.9      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -452     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 34400    |\n",
      "|    time_elapsed    | 15540    |\n",
      "|    total_timesteps | 172000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -452     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 34500    |\n",
      "|    time_elapsed       | 15551    |\n",
      "|    total_timesteps    | 172500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.67    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34499    |\n",
      "|    policy_loss        | 0.185    |\n",
      "|    value_loss         | 0.0937   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -447     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 34600    |\n",
      "|    time_elapsed       | 15568    |\n",
      "|    total_timesteps    | 173000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.62    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34599    |\n",
      "|    policy_loss        | 0.134    |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -447     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 34700    |\n",
      "|    time_elapsed       | 15577    |\n",
      "|    total_timesteps    | 173500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34699    |\n",
      "|    policy_loss        | 0.0997   |\n",
      "|    value_loss         | 0.0894   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=174000, episode_reward=-500.00 +/- 400.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -500     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 174000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.64    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34799    |\n",
      "|    policy_loss        | -25.3    |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -447     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 34800    |\n",
      "|    time_elapsed    | 15725    |\n",
      "|    total_timesteps | 174000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -447     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 34900    |\n",
      "|    time_elapsed       | 15735    |\n",
      "|    total_timesteps    | 174500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34899    |\n",
      "|    policy_loss        | 0.618    |\n",
      "|    value_loss         | 0.0934   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -448      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 35000     |\n",
      "|    time_elapsed       | 15753     |\n",
      "|    total_timesteps    | 175000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.09     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34999     |\n",
      "|    policy_loss        | 0.232     |\n",
      "|    value_loss         | 0.0906    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -448     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 35100    |\n",
      "|    time_elapsed       | 15764    |\n",
      "|    total_timesteps    | 175500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.38    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35099    |\n",
      "|    policy_loss        | 0.121    |\n",
      "|    value_loss         | 0.0933   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=-1299.20 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.3e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 176000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35199    |\n",
      "|    policy_loss        | -7.57    |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -450     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 35200    |\n",
      "|    time_elapsed    | 15910    |\n",
      "|    total_timesteps | 176000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -450      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 35300     |\n",
      "|    time_elapsed       | 15920     |\n",
      "|    total_timesteps    | 176500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.45     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35299     |\n",
      "|    policy_loss        | 0.202     |\n",
      "|    value_loss         | 0.102     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -454     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 35400    |\n",
      "|    time_elapsed       | 15938    |\n",
      "|    total_timesteps    | 177000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35399    |\n",
      "|    policy_loss        | 0.428    |\n",
      "|    value_loss         | 0.0969   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -454     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 35500    |\n",
      "|    time_elapsed       | 15949    |\n",
      "|    total_timesteps    | 177500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.16    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35499    |\n",
      "|    policy_loss        | -0.141   |\n",
      "|    value_loss         | 0.0995   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=178000, episode_reward=-500.00 +/- 400.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -500     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 178000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.92    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35599    |\n",
      "|    policy_loss        | -9.21    |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -456     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 35600    |\n",
      "|    time_elapsed    | 16092    |\n",
      "|    total_timesteps | 178000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -456     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 35700    |\n",
      "|    time_elapsed       | 16101    |\n",
      "|    total_timesteps    | 178500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.74    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35699    |\n",
      "|    policy_loss        | 0.255    |\n",
      "|    value_loss         | 0.0931   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -452     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 35800    |\n",
      "|    time_elapsed       | 16118    |\n",
      "|    total_timesteps    | 179000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35799    |\n",
      "|    policy_loss        | 0.0333   |\n",
      "|    value_loss         | 0.0894   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -452     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 35900    |\n",
      "|    time_elapsed       | 16127    |\n",
      "|    total_timesteps    | 179500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.19    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35899    |\n",
      "|    policy_loss        | -0.14    |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-893.80 +/- 497.59\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -894      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 180000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.49     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35999     |\n",
      "|    policy_loss        | 0.123     |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -450     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 36000    |\n",
      "|    time_elapsed    | 16269    |\n",
      "|    total_timesteps | 180000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -450     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 36100    |\n",
      "|    time_elapsed       | 16278    |\n",
      "|    total_timesteps    | 180500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.64    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36099    |\n",
      "|    policy_loss        | -0.396   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -449     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 36200    |\n",
      "|    time_elapsed       | 16295    |\n",
      "|    total_timesteps    | 181000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.2     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36199    |\n",
      "|    policy_loss        | -0.0338  |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -449     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 36300    |\n",
      "|    time_elapsed       | 16304    |\n",
      "|    total_timesteps    | 181500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.16    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36299    |\n",
      "|    policy_loss        | 0.055    |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=182000, episode_reward=-516.00 +/- 392.24\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -516     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 182000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.22    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36399    |\n",
      "|    policy_loss        | -9.22    |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -445     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 36400    |\n",
      "|    time_elapsed    | 16447    |\n",
      "|    total_timesteps | 182000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -445     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 36500    |\n",
      "|    time_elapsed       | 16456    |\n",
      "|    total_timesteps    | 182500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.32    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36499    |\n",
      "|    policy_loss        | -0.631   |\n",
      "|    value_loss         | 0.0896   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -443      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 36600     |\n",
      "|    time_elapsed       | 16472     |\n",
      "|    total_timesteps    | 183000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.37     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36599     |\n",
      "|    policy_loss        | -0.0222   |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -443      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 36700     |\n",
      "|    time_elapsed       | 16481     |\n",
      "|    total_timesteps    | 183500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.15     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36699     |\n",
      "|    policy_loss        | 0.0879    |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=184000, episode_reward=-315.20 +/- 8.16\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -315     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 184000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36799    |\n",
      "|    policy_loss        | -0.0651  |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -443     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 36800    |\n",
      "|    time_elapsed    | 16624    |\n",
      "|    total_timesteps | 184000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -443     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 36900    |\n",
      "|    time_elapsed       | 16633    |\n",
      "|    total_timesteps    | 184500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36899    |\n",
      "|    policy_loss        | -0.0907  |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -442     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 37000    |\n",
      "|    time_elapsed       | 16649    |\n",
      "|    total_timesteps    | 185000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.52    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36999    |\n",
      "|    policy_loss        | 0.0215   |\n",
      "|    value_loss         | 0.0893   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -442     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 37100    |\n",
      "|    time_elapsed       | 16658    |\n",
      "|    total_timesteps    | 185500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37099    |\n",
      "|    policy_loss        | 0.109    |\n",
      "|    value_loss         | 0.0897   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=186000, episode_reward=-508.00 +/- 396.10\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -508     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 186000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37199    |\n",
      "|    policy_loss        | 0.00758  |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -442     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 37200    |\n",
      "|    time_elapsed    | 16801    |\n",
      "|    total_timesteps | 186000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -442     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 37300    |\n",
      "|    time_elapsed       | 16809    |\n",
      "|    total_timesteps    | 186500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.62    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37299    |\n",
      "|    policy_loss        | -0.305   |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -441     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 37400    |\n",
      "|    time_elapsed       | 16826    |\n",
      "|    total_timesteps    | 187000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37399    |\n",
      "|    policy_loss        | -0.206   |\n",
      "|    value_loss         | 0.0899   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -441     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 37500    |\n",
      "|    time_elapsed       | 16835    |\n",
      "|    total_timesteps    | 187500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.24    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37499    |\n",
      "|    policy_loss        | -0.0571  |\n",
      "|    value_loss         | 0.0895   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=188000, episode_reward=-303.20 +/- 3.92\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -303      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 188000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.35     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37599     |\n",
      "|    policy_loss        | -0.0338   |\n",
      "|    value_loss         | 0.0898    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -437     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 37600    |\n",
      "|    time_elapsed    | 16977    |\n",
      "|    total_timesteps | 188000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -437     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 37700    |\n",
      "|    time_elapsed       | 16986    |\n",
      "|    total_timesteps    | 188500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.62    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37699    |\n",
      "|    policy_loss        | -0.325   |\n",
      "|    value_loss         | 0.0897   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -430     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 37800    |\n",
      "|    time_elapsed       | 17003    |\n",
      "|    total_timesteps    | 189000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.09    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37799    |\n",
      "|    policy_loss        | -14.7    |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -430     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 37900    |\n",
      "|    time_elapsed       | 17013    |\n",
      "|    total_timesteps    | 189500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37899    |\n",
      "|    policy_loss        | 0.00101  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-507.20 +/- 396.48\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -507     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 190000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37999    |\n",
      "|    policy_loss        | -0.0305  |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -430     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 38000    |\n",
      "|    time_elapsed    | 17156    |\n",
      "|    total_timesteps | 190000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -430      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 38100     |\n",
      "|    time_elapsed       | 17165     |\n",
      "|    total_timesteps    | 190500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.27     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38099     |\n",
      "|    policy_loss        | 0.213     |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -429     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 38200    |\n",
      "|    time_elapsed       | 17181    |\n",
      "|    total_timesteps    | 191000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.67    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38199    |\n",
      "|    policy_loss        | 0.00655  |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -429      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 38300     |\n",
      "|    time_elapsed       | 17190     |\n",
      "|    total_timesteps    | 191500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.85     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38299     |\n",
      "|    policy_loss        | -0.00756  |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=-307.20 +/- 9.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -307     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 192000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38399    |\n",
      "|    policy_loss        | -0.203   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -430     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 38400    |\n",
      "|    time_elapsed    | 17333    |\n",
      "|    total_timesteps | 192000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -430      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 38500     |\n",
      "|    time_elapsed       | 17342     |\n",
      "|    total_timesteps    | 192500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.59     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38499     |\n",
      "|    policy_loss        | -0.56     |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -429     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 38600    |\n",
      "|    time_elapsed       | 17358    |\n",
      "|    total_timesteps    | 193000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38599    |\n",
      "|    policy_loss        | -0.166   |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -429      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 38700     |\n",
      "|    time_elapsed       | 17368     |\n",
      "|    total_timesteps    | 193500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.72     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38699     |\n",
      "|    policy_loss        | -0.0194   |\n",
      "|    value_loss         | 0.0885    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=194000, episode_reward=-504.00 +/- 398.08\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -504     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 194000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.37    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38799    |\n",
      "|    policy_loss        | -0.26    |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -429     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 38800    |\n",
      "|    time_elapsed    | 17511    |\n",
      "|    total_timesteps | 194000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -429     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 38900    |\n",
      "|    time_elapsed       | 17519    |\n",
      "|    total_timesteps    | 194500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.51    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38899    |\n",
      "|    policy_loss        | -0.179   |\n",
      "|    value_loss         | 0.0895   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -430     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 39000    |\n",
      "|    time_elapsed       | 17536    |\n",
      "|    total_timesteps    | 195000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.07    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38999    |\n",
      "|    policy_loss        | -0.934   |\n",
      "|    value_loss         | 0.0897   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -430     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 39100    |\n",
      "|    time_elapsed       | 17545    |\n",
      "|    total_timesteps    | 195500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.19    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39099    |\n",
      "|    policy_loss        | -0.299   |\n",
      "|    value_loss         | 0.0895   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=196000, episode_reward=-705.60 +/- 485.35\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -706     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 196000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39199    |\n",
      "|    policy_loss        | -0.115   |\n",
      "|    value_loss         | 0.0904   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -430     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 39200    |\n",
      "|    time_elapsed    | 17688    |\n",
      "|    total_timesteps | 196000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -430     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 39300    |\n",
      "|    time_elapsed       | 17697    |\n",
      "|    total_timesteps    | 196500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39299    |\n",
      "|    policy_loss        | -0.113   |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -430     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 39400    |\n",
      "|    time_elapsed       | 17713    |\n",
      "|    total_timesteps    | 197000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.68    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39399    |\n",
      "|    policy_loss        | -0.0985  |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -430     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 39500    |\n",
      "|    time_elapsed       | 17722    |\n",
      "|    total_timesteps    | 197500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39499    |\n",
      "|    policy_loss        | -0.165   |\n",
      "|    value_loss         | 0.0904   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=198000, episode_reward=-504.80 +/- 397.71\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -505     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 198000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.948   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39599    |\n",
      "|    policy_loss        | -1.12    |\n",
      "|    value_loss         | 0.0911   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -430     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 39600    |\n",
      "|    time_elapsed    | 17865    |\n",
      "|    total_timesteps | 198000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -430     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 39700    |\n",
      "|    time_elapsed       | 17874    |\n",
      "|    total_timesteps    | 198500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39699    |\n",
      "|    policy_loss        | -0.101   |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -430     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 39800    |\n",
      "|    time_elapsed       | 17890    |\n",
      "|    total_timesteps    | 199000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.955   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39799    |\n",
      "|    policy_loss        | -0.0243  |\n",
      "|    value_loss         | 0.0905   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -430      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 39900     |\n",
      "|    time_elapsed       | 17899     |\n",
      "|    total_timesteps    | 199500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.09     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39899     |\n",
      "|    policy_loss        | -0.329    |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-504.00 +/- 398.08\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -504     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 200000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.671   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39999    |\n",
      "|    policy_loss        | -0.00738 |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -430     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 40000    |\n",
      "|    time_elapsed    | 18041    |\n",
      "|    total_timesteps | 200000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -430     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 40100    |\n",
      "|    time_elapsed       | 18051    |\n",
      "|    total_timesteps    | 200500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.668   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40099    |\n",
      "|    policy_loss        | -0.299   |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -430     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 40200    |\n",
      "|    time_elapsed       | 18067    |\n",
      "|    total_timesteps    | 201000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.888   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40199    |\n",
      "|    policy_loss        | -0.013   |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -430      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 40300     |\n",
      "|    time_elapsed       | 18076     |\n",
      "|    total_timesteps    | 201500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.65     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40299     |\n",
      "|    policy_loss        | -0.0432   |\n",
      "|    value_loss         | 0.0884    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=202000, episode_reward=-902.40 +/- 486.97\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -902     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 202000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40399    |\n",
      "|    policy_loss        | -3.44    |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -432     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 40400    |\n",
      "|    time_elapsed    | 18219    |\n",
      "|    total_timesteps | 202000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -432     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 40500    |\n",
      "|    time_elapsed       | 18228    |\n",
      "|    total_timesteps    | 202500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40499    |\n",
      "|    policy_loss        | -0.075   |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -436     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 40600    |\n",
      "|    time_elapsed       | 18244    |\n",
      "|    total_timesteps    | 203000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.708   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40599    |\n",
      "|    policy_loss        | 0.00559  |\n",
      "|    value_loss         | 0.0948   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -436     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 40700    |\n",
      "|    time_elapsed       | 18253    |\n",
      "|    total_timesteps    | 203500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.676   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40699    |\n",
      "|    policy_loss        | -0.0811  |\n",
      "|    value_loss         | 0.09     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=204000, episode_reward=-900.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -900     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 204000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.667   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40799    |\n",
      "|    policy_loss        | -0.143   |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -436     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 40800    |\n",
      "|    time_elapsed    | 18396    |\n",
      "|    total_timesteps | 204000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -436     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 40900    |\n",
      "|    time_elapsed       | 18405    |\n",
      "|    total_timesteps    | 204500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.799   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40899    |\n",
      "|    policy_loss        | -7.49    |\n",
      "|    value_loss         | 13.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -433      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 41000     |\n",
      "|    time_elapsed       | 18421     |\n",
      "|    total_timesteps    | 205000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.861    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40999     |\n",
      "|    policy_loss        | 0.0284    |\n",
      "|    value_loss         | 0.0883    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -433      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 41100     |\n",
      "|    time_elapsed       | 18431     |\n",
      "|    total_timesteps    | 205500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.74     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41099     |\n",
      "|    policy_loss        | -0.0206   |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=206000, episode_reward=-700.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -700     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 206000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.714   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41199    |\n",
      "|    policy_loss        | -0.0243  |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -433     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 41200    |\n",
      "|    time_elapsed    | 18573    |\n",
      "|    total_timesteps | 206000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -433     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 41300    |\n",
      "|    time_elapsed       | 18582    |\n",
      "|    total_timesteps    | 206500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.16    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41299    |\n",
      "|    policy_loss        | -0.791   |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -433      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 41400     |\n",
      "|    time_elapsed       | 18599     |\n",
      "|    total_timesteps    | 207000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.06     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41399     |\n",
      "|    policy_loss        | -0.0329   |\n",
      "|    value_loss         | 0.0891    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -433     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 41500    |\n",
      "|    time_elapsed       | 18609    |\n",
      "|    total_timesteps    | 207500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.89    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41499    |\n",
      "|    policy_loss        | -9.7     |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=-1300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.3e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 208000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.73    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41599    |\n",
      "|    policy_loss        | 0.364    |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -435     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 41600    |\n",
      "|    time_elapsed    | 18750    |\n",
      "|    total_timesteps | 208000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -435     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 41700    |\n",
      "|    time_elapsed       | 18760    |\n",
      "|    total_timesteps    | 208500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.53    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41699    |\n",
      "|    policy_loss        | 0.357    |\n",
      "|    value_loss         | 0.0892   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -435     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 41800    |\n",
      "|    time_elapsed       | 18779    |\n",
      "|    total_timesteps    | 209000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.23    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41799    |\n",
      "|    policy_loss        | 0.059    |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -435     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 41900    |\n",
      "|    time_elapsed       | 18789    |\n",
      "|    total_timesteps    | 209500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.44    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41899    |\n",
      "|    policy_loss        | 0.0112   |\n",
      "|    value_loss         | 0.0977   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 210000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.43    |\n",
      "|    explained_variance | 4.77e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41999    |\n",
      "|    policy_loss        | -20      |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -441     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 42000    |\n",
      "|    time_elapsed    | 18933    |\n",
      "|    total_timesteps | 210000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -441      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 42100     |\n",
      "|    time_elapsed       | 18944     |\n",
      "|    total_timesteps    | 210500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3        |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42099     |\n",
      "|    policy_loss        | 0.489     |\n",
      "|    value_loss         | 0.116     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -443     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 42200    |\n",
      "|    time_elapsed       | 18961    |\n",
      "|    total_timesteps    | 211000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.77    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42199    |\n",
      "|    policy_loss        | 0.275    |\n",
      "|    value_loss         | 0.1      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -443     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 42300    |\n",
      "|    time_elapsed       | 18971    |\n",
      "|    total_timesteps    | 211500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42299    |\n",
      "|    policy_loss        | 0.58     |\n",
      "|    value_loss         | 0.0944   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=212000, episode_reward=-326.40 +/- 52.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -326      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 212000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.19     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42399     |\n",
      "|    policy_loss        | 0.0938    |\n",
      "|    value_loss         | 0.0896    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -443     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 42400    |\n",
      "|    time_elapsed    | 19115    |\n",
      "|    total_timesteps | 212000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -443     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 42500    |\n",
      "|    time_elapsed       | 19125    |\n",
      "|    total_timesteps    | 212500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.4     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42499    |\n",
      "|    policy_loss        | -0.0584  |\n",
      "|    value_loss         | 0.0945   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -446     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 42600    |\n",
      "|    time_elapsed       | 19143    |\n",
      "|    total_timesteps    | 213000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.36    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42599    |\n",
      "|    policy_loss        | -0.45    |\n",
      "|    value_loss         | 0.0904   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -446     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 42700    |\n",
      "|    time_elapsed       | 19154    |\n",
      "|    total_timesteps    | 213500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42699    |\n",
      "|    policy_loss        | -0.439   |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=214000, episode_reward=-304.00 +/- 6.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -304     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 214000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.55    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42799    |\n",
      "|    policy_loss        | 0.0256   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -446     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 42800    |\n",
      "|    time_elapsed    | 19297    |\n",
      "|    total_timesteps | 214000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -446      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 42900     |\n",
      "|    time_elapsed       | 19307     |\n",
      "|    total_timesteps    | 214500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.66     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42899     |\n",
      "|    policy_loss        | -17.8     |\n",
      "|    value_loss         | 13.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -447     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 43000    |\n",
      "|    time_elapsed       | 19323    |\n",
      "|    total_timesteps    | 215000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.91    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42999    |\n",
      "|    policy_loss        | 0.199    |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -447      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 43100     |\n",
      "|    time_elapsed       | 19332     |\n",
      "|    total_timesteps    | 215500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.98     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43099     |\n",
      "|    policy_loss        | -0.236    |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=216000, episode_reward=-599.20 +/- 373.96\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -599     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 216000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.28    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43199    |\n",
      "|    policy_loss        | -19.5    |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -448     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 43200    |\n",
      "|    time_elapsed    | 19476    |\n",
      "|    total_timesteps | 216000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -448     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 43300    |\n",
      "|    time_elapsed       | 19485    |\n",
      "|    total_timesteps    | 216500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.03    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43299    |\n",
      "|    policy_loss        | -0.181   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -447     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 43400    |\n",
      "|    time_elapsed       | 19501    |\n",
      "|    total_timesteps    | 217000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43399    |\n",
      "|    policy_loss        | 0.31     |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -447     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 43500    |\n",
      "|    time_elapsed       | 19511    |\n",
      "|    total_timesteps    | 217500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43499    |\n",
      "|    policy_loss        | 0.00591  |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=218000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 218000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43599    |\n",
      "|    policy_loss        | 0.0309   |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -445     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 43600    |\n",
      "|    time_elapsed    | 19653    |\n",
      "|    total_timesteps | 218000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -445     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 43700    |\n",
      "|    time_elapsed       | 19662    |\n",
      "|    total_timesteps    | 218500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43699    |\n",
      "|    policy_loss        | 0.297    |\n",
      "|    value_loss         | 0.0895   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -445     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 43800    |\n",
      "|    time_elapsed       | 19679    |\n",
      "|    total_timesteps    | 219000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43799    |\n",
      "|    policy_loss        | -0.0254  |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -445     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 43900    |\n",
      "|    time_elapsed       | 19689    |\n",
      "|    total_timesteps    | 219500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.8     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43899    |\n",
      "|    policy_loss        | -18.7    |\n",
      "|    value_loss         | 13.2     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-298.60 +/- 14.08\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -299     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 220000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43999    |\n",
      "|    policy_loss        | -0.0324  |\n",
      "|    value_loss         | 0.0926   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -448     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 44000    |\n",
      "|    time_elapsed    | 19839    |\n",
      "|    total_timesteps | 220000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -448     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 44100    |\n",
      "|    time_elapsed       | 19852    |\n",
      "|    total_timesteps    | 220500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.35    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44099    |\n",
      "|    policy_loss        | 0.304    |\n",
      "|    value_loss         | 0.105    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -451      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 44200     |\n",
      "|    time_elapsed       | 19870     |\n",
      "|    total_timesteps    | 221000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.31     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44199     |\n",
      "|    policy_loss        | 0.165     |\n",
      "|    value_loss         | 0.108     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -451     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 44300    |\n",
      "|    time_elapsed       | 19882    |\n",
      "|    total_timesteps    | 221500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.96    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44299    |\n",
      "|    policy_loss        | 0.609    |\n",
      "|    value_loss         | 0.0992   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=222000, episode_reward=-504.80 +/- 397.64\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -505     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 222000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.46    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44399    |\n",
      "|    policy_loss        | -15      |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -451     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 44400    |\n",
      "|    time_elapsed    | 20026    |\n",
      "|    total_timesteps | 222000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -451     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 44500    |\n",
      "|    time_elapsed       | 20038    |\n",
      "|    total_timesteps    | 222500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.33    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44499    |\n",
      "|    policy_loss        | -18.9    |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -456     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 44600    |\n",
      "|    time_elapsed       | 20060    |\n",
      "|    total_timesteps    | 223000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.99    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44599    |\n",
      "|    policy_loss        | 1.16     |\n",
      "|    value_loss         | 0.123    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -456     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 44700    |\n",
      "|    time_elapsed       | 20070    |\n",
      "|    total_timesteps    | 223500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44699    |\n",
      "|    policy_loss        | 0.273    |\n",
      "|    value_loss         | 0.146    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=-693.80 +/- 495.09\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -694     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 224000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.64    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44799    |\n",
      "|    policy_loss        | -12.5    |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -460     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 44800    |\n",
      "|    time_elapsed    | 20222    |\n",
      "|    total_timesteps | 224000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -460     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 44900    |\n",
      "|    time_elapsed       | 20237    |\n",
      "|    total_timesteps    | 224500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.26    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44899    |\n",
      "|    policy_loss        | 1.13     |\n",
      "|    value_loss         | 0.166    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -464     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 45000    |\n",
      "|    time_elapsed       | 20254    |\n",
      "|    total_timesteps    | 225000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.81    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44999    |\n",
      "|    policy_loss        | -20.1    |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -464     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 45100    |\n",
      "|    time_elapsed       | 20267    |\n",
      "|    total_timesteps    | 225500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45099    |\n",
      "|    policy_loss        | 1.46     |\n",
      "|    value_loss         | 0.208    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=226000, episode_reward=-704.80 +/- 486.02\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -705     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 226000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.47    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45199    |\n",
      "|    policy_loss        | 0.789    |\n",
      "|    value_loss         | 0.183    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -467     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 45200    |\n",
      "|    time_elapsed    | 20411    |\n",
      "|    total_timesteps | 226000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -467      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 45300     |\n",
      "|    time_elapsed       | 20422     |\n",
      "|    total_timesteps    | 226500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.22     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45299     |\n",
      "|    policy_loss        | 0.344     |\n",
      "|    value_loss         | 0.155     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -468     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 45400    |\n",
      "|    time_elapsed       | 20439    |\n",
      "|    total_timesteps    | 227000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.56    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45399    |\n",
      "|    policy_loss        | 0.313    |\n",
      "|    value_loss         | 0.122    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -468      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 45500     |\n",
      "|    time_elapsed       | 20448     |\n",
      "|    total_timesteps    | 227500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.78     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45499     |\n",
      "|    policy_loss        | -0.399    |\n",
      "|    value_loss         | 0.111     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=228000, episode_reward=-1100.00 +/- 400.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 228000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.07    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45599    |\n",
      "|    policy_loss        | 0.567    |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -469     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 45600    |\n",
      "|    time_elapsed    | 20591    |\n",
      "|    total_timesteps | 228000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -469     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 45700    |\n",
      "|    time_elapsed       | 20601    |\n",
      "|    total_timesteps    | 228500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45699    |\n",
      "|    policy_loss        | 0.171    |\n",
      "|    value_loss         | 0.093    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -469     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 45800    |\n",
      "|    time_elapsed       | 20619    |\n",
      "|    total_timesteps    | 229000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.72    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45799    |\n",
      "|    policy_loss        | 0.0972   |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -469     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 45900    |\n",
      "|    time_elapsed       | 20629    |\n",
      "|    total_timesteps    | 229500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45899    |\n",
      "|    policy_loss        | 0.287    |\n",
      "|    value_loss         | 0.0913   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-900.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -900     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 230000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.67    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45999    |\n",
      "|    policy_loss        | -9.31    |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -472     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 46000    |\n",
      "|    time_elapsed    | 20773    |\n",
      "|    total_timesteps | 230000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -472     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 46100    |\n",
      "|    time_elapsed       | 20785    |\n",
      "|    total_timesteps    | 230500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.4     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46099    |\n",
      "|    policy_loss        | -0.184   |\n",
      "|    value_loss         | 0.101    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -476     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 46200    |\n",
      "|    time_elapsed       | 20804    |\n",
      "|    total_timesteps    | 231000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.9     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46199    |\n",
      "|    policy_loss        | -20      |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -476     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 46300    |\n",
      "|    time_elapsed       | 20823    |\n",
      "|    total_timesteps    | 231500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.17    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46299    |\n",
      "|    policy_loss        | 0.521    |\n",
      "|    value_loss         | 0.116    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=232000, episode_reward=-897.00 +/- 493.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -897     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 232000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46399    |\n",
      "|    policy_loss        | 0.213    |\n",
      "|    value_loss         | 0.123    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -481     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 46400    |\n",
      "|    time_elapsed    | 20974    |\n",
      "|    total_timesteps | 232000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -481     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 46500    |\n",
      "|    time_elapsed       | 20984    |\n",
      "|    total_timesteps    | 232500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.89    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46499    |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    value_loss         | 0.154    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -485     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 46600    |\n",
      "|    time_elapsed       | 21002    |\n",
      "|    total_timesteps    | 233000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46599    |\n",
      "|    policy_loss        | 0.767    |\n",
      "|    value_loss         | 0.143    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -485     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 46700    |\n",
      "|    time_elapsed       | 21014    |\n",
      "|    total_timesteps    | 233500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.24    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46699    |\n",
      "|    policy_loss        | -14.5    |\n",
      "|    value_loss         | 11.5     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=234000, episode_reward=-1299.20 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.3e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 234000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46799    |\n",
      "|    policy_loss        | 0.88     |\n",
      "|    value_loss         | 0.141    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -489     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 46800    |\n",
      "|    time_elapsed    | 21156    |\n",
      "|    total_timesteps | 234000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -489     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 46900    |\n",
      "|    time_elapsed       | 21168    |\n",
      "|    total_timesteps    | 234500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.51    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46899    |\n",
      "|    policy_loss        | 0.318    |\n",
      "|    value_loss         | 0.163    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -492      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 47000     |\n",
      "|    time_elapsed       | 21189     |\n",
      "|    total_timesteps    | 235000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.38     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46999     |\n",
      "|    policy_loss        | -13.9     |\n",
      "|    value_loss         | 11.8      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -492     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 47100    |\n",
      "|    time_elapsed       | 21199    |\n",
      "|    total_timesteps    | 235500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.01    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47099    |\n",
      "|    policy_loss        | -0.251   |\n",
      "|    value_loss         | 0.107    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=236000, episode_reward=-1300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.3e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 236000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47199    |\n",
      "|    policy_loss        | 0.0791   |\n",
      "|    value_loss         | 0.0958   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -491     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 47200    |\n",
      "|    time_elapsed    | 21341    |\n",
      "|    total_timesteps | 236000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -491      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 47300     |\n",
      "|    time_elapsed       | 21351     |\n",
      "|    total_timesteps    | 236500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.66     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47299     |\n",
      "|    policy_loss        | -17.2     |\n",
      "|    value_loss         | 12        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -496     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 47400    |\n",
      "|    time_elapsed       | 21370    |\n",
      "|    total_timesteps    | 237000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47399    |\n",
      "|    policy_loss        | -0.0426  |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -496     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 47500    |\n",
      "|    time_elapsed       | 21382    |\n",
      "|    total_timesteps    | 237500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.5     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47499    |\n",
      "|    policy_loss        | -15      |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=238000, episode_reward=-1300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.3e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 238000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47599    |\n",
      "|    policy_loss        | 0.319    |\n",
      "|    value_loss         | 0.176    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -502     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 47600    |\n",
      "|    time_elapsed    | 21525    |\n",
      "|    total_timesteps | 238000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -502     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 47700    |\n",
      "|    time_elapsed       | 21535    |\n",
      "|    total_timesteps    | 238500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.33    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47699    |\n",
      "|    policy_loss        | 0.593    |\n",
      "|    value_loss         | 0.153    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -499     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 47800    |\n",
      "|    time_elapsed       | 21552    |\n",
      "|    total_timesteps    | 239000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.71    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47799    |\n",
      "|    policy_loss        | -0.184   |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -499     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 47900    |\n",
      "|    time_elapsed       | 21567    |\n",
      "|    total_timesteps    | 239500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47899    |\n",
      "|    policy_loss        | -9.26    |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-699.20 +/- 488.92\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -699     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 240000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47999    |\n",
      "|    policy_loss        | 0.387    |\n",
      "|    value_loss         | 0.111    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -498     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 48000    |\n",
      "|    time_elapsed    | 21709    |\n",
      "|    total_timesteps | 240000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -498     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 48100    |\n",
      "|    time_elapsed       | 21720    |\n",
      "|    total_timesteps    | 240500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48099    |\n",
      "|    policy_loss        | 0.0252   |\n",
      "|    value_loss         | 0.107    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -497     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 48200    |\n",
      "|    time_elapsed       | 21737    |\n",
      "|    total_timesteps    | 241000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48199    |\n",
      "|    policy_loss        | 0.216    |\n",
      "|    value_loss         | 0.0934   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -497     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 48300    |\n",
      "|    time_elapsed       | 21752    |\n",
      "|    total_timesteps    | 241500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.77    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48299    |\n",
      "|    policy_loss        | 0.692    |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=242000, episode_reward=-902.40 +/- 486.97\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -902      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 242000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.933    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48399     |\n",
      "|    policy_loss        | 0.0621    |\n",
      "|    value_loss         | 0.0975    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -499     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 48400    |\n",
      "|    time_elapsed    | 21895    |\n",
      "|    total_timesteps | 242000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -499     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 48500    |\n",
      "|    time_elapsed       | 21904    |\n",
      "|    total_timesteps    | 242500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48499    |\n",
      "|    policy_loss        | 0.0572   |\n",
      "|    value_loss         | 0.0903   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -496      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 48600     |\n",
      "|    time_elapsed       | 21920     |\n",
      "|    total_timesteps    | 243000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.26     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48599     |\n",
      "|    policy_loss        | -0.0205   |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -496     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 48700    |\n",
      "|    time_elapsed       | 21929    |\n",
      "|    total_timesteps    | 243500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.943   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48699    |\n",
      "|    policy_loss        | -0.0178  |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=244000, episode_reward=-700.00 +/- 489.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -700     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 244000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.22    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48799    |\n",
      "|    policy_loss        | -0.0702  |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -493     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 48800    |\n",
      "|    time_elapsed    | 22071    |\n",
      "|    total_timesteps | 244000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -493      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 48900     |\n",
      "|    time_elapsed       | 22082     |\n",
      "|    total_timesteps    | 244500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.17     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48899     |\n",
      "|    policy_loss        | -0.307    |\n",
      "|    value_loss         | 0.0904    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -497     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 49000    |\n",
      "|    time_elapsed       | 22100    |\n",
      "|    total_timesteps    | 245000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.59    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48999    |\n",
      "|    policy_loss        | -0.0787  |\n",
      "|    value_loss         | 0.111    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -497     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 49100    |\n",
      "|    time_elapsed       | 22112    |\n",
      "|    total_timesteps    | 245500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.51    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49099    |\n",
      "|    policy_loss        | -16.5    |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=246000, episode_reward=-310.40 +/- 12.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -310      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 246000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49199     |\n",
      "|    policy_loss        | 1.24      |\n",
      "|    value_loss         | 0.18      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -498     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 49200    |\n",
      "|    time_elapsed    | 22268    |\n",
      "|    total_timesteps | 246000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -498     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 49300    |\n",
      "|    time_elapsed       | 22278    |\n",
      "|    total_timesteps    | 246500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.48    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49299    |\n",
      "|    policy_loss        | 1.8      |\n",
      "|    value_loss         | 0.187    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -500     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 49400    |\n",
      "|    time_elapsed       | 22297    |\n",
      "|    total_timesteps    | 247000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49399    |\n",
      "|    policy_loss        | -18.2    |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -500     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 49500    |\n",
      "|    time_elapsed       | 22308    |\n",
      "|    total_timesteps    | 247500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49499    |\n",
      "|    policy_loss        | 0.308    |\n",
      "|    value_loss         | 0.186    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=248000, episode_reward=-516.00 +/- 390.77\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -516     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 248000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49599    |\n",
      "|    policy_loss        | -22.2    |\n",
      "|    value_loss         | 11.3     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -498     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 49600    |\n",
      "|    time_elapsed    | 22454    |\n",
      "|    total_timesteps | 248000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -498      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 49700     |\n",
      "|    time_elapsed       | 22464     |\n",
      "|    total_timesteps    | 248500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.89     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49699     |\n",
      "|    policy_loss        | 0.148     |\n",
      "|    value_loss         | 0.145     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -498     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 49800    |\n",
      "|    time_elapsed       | 22481    |\n",
      "|    total_timesteps    | 249000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.37    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49799    |\n",
      "|    policy_loss        | 0.166    |\n",
      "|    value_loss         | 0.115    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -498     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 49900    |\n",
      "|    time_elapsed       | 22491    |\n",
      "|    total_timesteps    | 249500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.37    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49899    |\n",
      "|    policy_loss        | 0.0564   |\n",
      "|    value_loss         | 0.107    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-700.80 +/- 487.62\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -701     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 250000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.656   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49999    |\n",
      "|    policy_loss        | 0.00577  |\n",
      "|    value_loss         | 0.0939   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -499     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 50000    |\n",
      "|    time_elapsed    | 22635    |\n",
      "|    total_timesteps | 250000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -499     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 50100    |\n",
      "|    time_elapsed       | 22645    |\n",
      "|    total_timesteps    | 250500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.2     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50099    |\n",
      "|    policy_loss        | 0.000933 |\n",
      "|    value_loss         | 0.0892   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -499     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 50200    |\n",
      "|    time_elapsed       | 22661    |\n",
      "|    total_timesteps    | 251000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50199    |\n",
      "|    policy_loss        | -0.459   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -499     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 50300    |\n",
      "|    time_elapsed       | 22670    |\n",
      "|    total_timesteps    | 251500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.551   |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50299    |\n",
      "|    policy_loss        | -0.409   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=252000, episode_reward=-481.40 +/- 407.46\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -481     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 252000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.524   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50399    |\n",
      "|    policy_loss        | -0.467   |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -498     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 50400    |\n",
      "|    time_elapsed    | 22814    |\n",
      "|    total_timesteps | 252000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -498     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 50500    |\n",
      "|    time_elapsed       | 22823    |\n",
      "|    total_timesteps    | 252500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.491   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50499    |\n",
      "|    policy_loss        | -0.00487 |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -498     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 50600    |\n",
      "|    time_elapsed       | 22840    |\n",
      "|    total_timesteps    | 253000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.548   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50599    |\n",
      "|    policy_loss        | -0.00887 |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -498     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 50700    |\n",
      "|    time_elapsed       | 22853    |\n",
      "|    total_timesteps    | 253500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50699    |\n",
      "|    policy_loss        | -13.9    |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=254000, episode_reward=-494.60 +/- 398.88\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -495     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 254000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.94    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50799    |\n",
      "|    policy_loss        | -14.4    |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -501     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 50800    |\n",
      "|    time_elapsed    | 22996    |\n",
      "|    total_timesteps | 254000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -501     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 50900    |\n",
      "|    time_elapsed       | 23006    |\n",
      "|    total_timesteps    | 254500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.46    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50899    |\n",
      "|    policy_loss        | -16.5    |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -506      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 51000     |\n",
      "|    time_elapsed       | 23025     |\n",
      "|    total_timesteps    | 255000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.54     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50999     |\n",
      "|    policy_loss        | 0.121     |\n",
      "|    value_loss         | 0.117     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -506     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 51100    |\n",
      "|    time_elapsed       | 23037    |\n",
      "|    total_timesteps    | 255500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51099    |\n",
      "|    policy_loss        | 0.106    |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=-304.00 +/- 5.06\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -304      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 256000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.945    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51199     |\n",
      "|    policy_loss        | -0.0608   |\n",
      "|    value_loss         | 0.116     |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -508     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 51200    |\n",
      "|    time_elapsed    | 23198    |\n",
      "|    total_timesteps | 256000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -508      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 51300     |\n",
      "|    time_elapsed       | 23208     |\n",
      "|    total_timesteps    | 256500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.878    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51299     |\n",
      "|    policy_loss        | 0.0453    |\n",
      "|    value_loss         | 0.1       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -506     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 51400    |\n",
      "|    time_elapsed       | 23225    |\n",
      "|    total_timesteps    | 257000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.32    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51399    |\n",
      "|    policy_loss        | 0.00046  |\n",
      "|    value_loss         | 0.0906   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -506      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 51500     |\n",
      "|    time_elapsed       | 23234     |\n",
      "|    total_timesteps    | 257500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.503    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51499     |\n",
      "|    policy_loss        | 0.121     |\n",
      "|    value_loss         | 0.0884    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=258000, episode_reward=-296.20 +/- 11.74\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -296     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 258000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.505   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51599    |\n",
      "|    policy_loss        | -0.00549 |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -506     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 51600    |\n",
      "|    time_elapsed    | 23376    |\n",
      "|    total_timesteps | 258000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -506     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 51700    |\n",
      "|    time_elapsed       | 23385    |\n",
      "|    total_timesteps    | 258500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.396   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51699    |\n",
      "|    policy_loss        | -0.172   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -503     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 51800    |\n",
      "|    time_elapsed       | 23402    |\n",
      "|    total_timesteps    | 259000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.571   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51799    |\n",
      "|    policy_loss        | -0.00778 |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -503     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 51900    |\n",
      "|    time_elapsed       | 23412    |\n",
      "|    total_timesteps    | 259500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.981   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51899    |\n",
      "|    policy_loss        | -0.132   |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=-297.80 +/- 8.59\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -298     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 260000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.12    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51999    |\n",
      "|    policy_loss        | -0.037   |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -501     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 52000    |\n",
      "|    time_elapsed    | 23554    |\n",
      "|    total_timesteps | 260000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -501     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 52100    |\n",
      "|    time_elapsed       | 23564    |\n",
      "|    total_timesteps    | 260500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.64    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52099    |\n",
      "|    policy_loss        | -11      |\n",
      "|    value_loss         | 13.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -497     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 52200    |\n",
      "|    time_elapsed       | 23583    |\n",
      "|    total_timesteps    | 261000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52199    |\n",
      "|    policy_loss        | -0.236   |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -497      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 52300     |\n",
      "|    time_elapsed       | 23596     |\n",
      "|    total_timesteps    | 261500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.09     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52299     |\n",
      "|    policy_loss        | 0.00247   |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=262000, episode_reward=-696.80 +/- 485.99\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -697     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 262000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.969   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52399    |\n",
      "|    policy_loss        | 0.234    |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -491     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 52400    |\n",
      "|    time_elapsed    | 23740    |\n",
      "|    total_timesteps | 262000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -491     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 52500    |\n",
      "|    time_elapsed       | 23751    |\n",
      "|    total_timesteps    | 262500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52499    |\n",
      "|    policy_loss        | -16.4    |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -494     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 52600    |\n",
      "|    time_elapsed       | 23776    |\n",
      "|    total_timesteps    | 263000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.31    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52599    |\n",
      "|    policy_loss        | -11      |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -494     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 52700    |\n",
      "|    time_elapsed       | 23788    |\n",
      "|    total_timesteps    | 263500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.78    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52699    |\n",
      "|    policy_loss        | 0.415    |\n",
      "|    value_loss         | 0.125    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=264000, episode_reward=-698.60 +/- 487.85\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -699     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 264000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52799    |\n",
      "|    policy_loss        | 0.561    |\n",
      "|    value_loss         | 0.114    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -496     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 52800    |\n",
      "|    time_elapsed    | 23941    |\n",
      "|    total_timesteps | 264000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -496     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 52900    |\n",
      "|    time_elapsed       | 23951    |\n",
      "|    total_timesteps    | 264500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.6     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52899    |\n",
      "|    policy_loss        | 0.233    |\n",
      "|    value_loss         | 0.127    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -499     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 53000    |\n",
      "|    time_elapsed       | 23968    |\n",
      "|    total_timesteps    | 265000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.684   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52999    |\n",
      "|    policy_loss        | -0.0412  |\n",
      "|    value_loss         | 0.116    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -499     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 53100    |\n",
      "|    time_elapsed       | 23978    |\n",
      "|    total_timesteps    | 265500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.1     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53099    |\n",
      "|    policy_loss        | -17.2    |\n",
      "|    value_loss         | 11.6     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=266000, episode_reward=-500.20 +/- 398.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -500     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 266000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.51    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53199    |\n",
      "|    policy_loss        | 0.248    |\n",
      "|    value_loss         | 0.179    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -504     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 53200    |\n",
      "|    time_elapsed    | 24142    |\n",
      "|    total_timesteps | 266000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -504     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 53300    |\n",
      "|    time_elapsed       | 24154    |\n",
      "|    total_timesteps    | 266500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53299    |\n",
      "|    policy_loss        | -8.46    |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 53400    |\n",
      "|    time_elapsed       | 24173    |\n",
      "|    total_timesteps    | 267000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53399    |\n",
      "|    policy_loss        | -0.00437 |\n",
      "|    value_loss         | 0.196    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 53500    |\n",
      "|    time_elapsed       | 24185    |\n",
      "|    total_timesteps    | 267500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.985   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53499    |\n",
      "|    policy_loss        | 0.0852   |\n",
      "|    value_loss         | 0.155    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=268000, episode_reward=-703.20 +/- 487.29\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -703     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 268000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.913   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53599    |\n",
      "|    policy_loss        | -4.73    |\n",
      "|    value_loss         | 11.5     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -510     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 53600    |\n",
      "|    time_elapsed    | 24330    |\n",
      "|    total_timesteps | 268000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -510     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 53700    |\n",
      "|    time_elapsed       | 24341    |\n",
      "|    total_timesteps    | 268500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.402   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53699    |\n",
      "|    policy_loss        | 0.011    |\n",
      "|    value_loss         | 0.122    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 53800    |\n",
      "|    time_elapsed       | 24360    |\n",
      "|    total_timesteps    | 269000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.22    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53799    |\n",
      "|    policy_loss        | -18.5    |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 53900    |\n",
      "|    time_elapsed       | 24370    |\n",
      "|    total_timesteps    | 269500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.51    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53899    |\n",
      "|    policy_loss        | -0.0988  |\n",
      "|    value_loss         | 0.0937   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=-1098.40 +/- 397.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 270000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.9     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53999    |\n",
      "|    policy_loss        | -14.6    |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -510     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 54000    |\n",
      "|    time_elapsed    | 24515    |\n",
      "|    total_timesteps | 270000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -510     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 54100    |\n",
      "|    time_elapsed       | 24527    |\n",
      "|    total_timesteps    | 270500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.46    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54099    |\n",
      "|    policy_loss        | 0.555    |\n",
      "|    value_loss         | 0.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 54200    |\n",
      "|    time_elapsed       | 24551    |\n",
      "|    total_timesteps    | 271000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.12    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54199    |\n",
      "|    policy_loss        | -8.36    |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 54300    |\n",
      "|    time_elapsed       | 24561    |\n",
      "|    total_timesteps    | 271500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.79    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54299    |\n",
      "|    policy_loss        | -14      |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=272000, episode_reward=-931.20 +/- 361.10\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -931     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 272000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.67    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54399    |\n",
      "|    policy_loss        | -9.67    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -513     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 54400    |\n",
      "|    time_elapsed    | 24710    |\n",
      "|    total_timesteps | 272000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -513      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 54500     |\n",
      "|    time_elapsed       | 24719     |\n",
      "|    total_timesteps    | 272500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.972    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54499     |\n",
      "|    policy_loss        | -0.0478   |\n",
      "|    value_loss         | 0.105     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -517     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 54600    |\n",
      "|    time_elapsed       | 24736    |\n",
      "|    total_timesteps    | 273000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.88    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54599    |\n",
      "|    policy_loss        | -7.61    |\n",
      "|    value_loss         | 11.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -517     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 54700    |\n",
      "|    time_elapsed       | 24745    |\n",
      "|    total_timesteps    | 273500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54699    |\n",
      "|    policy_loss        | 0.0814   |\n",
      "|    value_loss         | 0.139    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=274000, episode_reward=-494.60 +/- 391.10\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -495     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 274000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.74    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54799    |\n",
      "|    policy_loss        | -6.85    |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -516     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 54800    |\n",
      "|    time_elapsed    | 24889    |\n",
      "|    total_timesteps | 274000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -516     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 54900    |\n",
      "|    time_elapsed       | 24899    |\n",
      "|    total_timesteps    | 274500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.07    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54899    |\n",
      "|    policy_loss        | -8.35    |\n",
      "|    value_loss         | 11.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -518     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 55000    |\n",
      "|    time_elapsed       | 24917    |\n",
      "|    total_timesteps    | 275000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.73    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54999    |\n",
      "|    policy_loss        | 0.419    |\n",
      "|    value_loss         | 0.126    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -518     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 55100    |\n",
      "|    time_elapsed       | 24927    |\n",
      "|    total_timesteps    | 275500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.66    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55099    |\n",
      "|    policy_loss        | -3.3     |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=276000, episode_reward=-997.60 +/- 397.21\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -998     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 276000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55199    |\n",
      "|    policy_loss        | -0.35    |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -518     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 55200    |\n",
      "|    time_elapsed    | 25074    |\n",
      "|    total_timesteps | 276000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -518     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 55300    |\n",
      "|    time_elapsed       | 25086    |\n",
      "|    total_timesteps    | 276500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.3     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55299    |\n",
      "|    policy_loss        | 0.662    |\n",
      "|    value_loss         | 0.109    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -516      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 55400     |\n",
      "|    time_elapsed       | 25106     |\n",
      "|    total_timesteps    | 277000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.13     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55399     |\n",
      "|    policy_loss        | -10.5     |\n",
      "|    value_loss         | 12.4      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -516     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 55500    |\n",
      "|    time_elapsed       | 25115    |\n",
      "|    total_timesteps    | 277500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.8     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55499    |\n",
      "|    policy_loss        | 0.0356   |\n",
      "|    value_loss         | 0.0929   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=278000, episode_reward=-891.20 +/- 482.81\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -891     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 278000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.1     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55599    |\n",
      "|    policy_loss        | -11.8    |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -517     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 55600    |\n",
      "|    time_elapsed    | 25258    |\n",
      "|    total_timesteps | 278000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -517     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 55700    |\n",
      "|    time_elapsed       | 25268    |\n",
      "|    total_timesteps    | 278500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.12    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55699    |\n",
      "|    policy_loss        | -0.0951  |\n",
      "|    value_loss         | 0.105    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -517     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 55800    |\n",
      "|    time_elapsed       | 25283    |\n",
      "|    total_timesteps    | 279000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.499   |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55799    |\n",
      "|    policy_loss        | -0.00479 |\n",
      "|    value_loss         | 0.0921   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -517     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 55900    |\n",
      "|    time_elapsed       | 25293    |\n",
      "|    total_timesteps    | 279500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.342   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55899    |\n",
      "|    policy_loss        | -0.317   |\n",
      "|    value_loss         | 0.0899   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-1096.00 +/- 398.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 280000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.276   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55999    |\n",
      "|    policy_loss        | -0.00125 |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -517     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 56000    |\n",
      "|    time_elapsed    | 25436    |\n",
      "|    total_timesteps | 280000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -517      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 56100     |\n",
      "|    time_elapsed       | 25445     |\n",
      "|    total_timesteps    | 280500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.55     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56099     |\n",
      "|    policy_loss        | 0.101     |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -516     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 56200    |\n",
      "|    time_elapsed       | 25462    |\n",
      "|    total_timesteps    | 281000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56199    |\n",
      "|    policy_loss        | 0.0566   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -516     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 56300    |\n",
      "|    time_elapsed       | 25472    |\n",
      "|    total_timesteps    | 281500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.59    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56299    |\n",
      "|    policy_loss        | 0.207    |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=282000, episode_reward=-826.40 +/- 437.19\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -826     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 282000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.41    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56399    |\n",
      "|    policy_loss        | -0.662   |\n",
      "|    value_loss         | 0.0893   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -516     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 56400    |\n",
      "|    time_elapsed    | 25615    |\n",
      "|    total_timesteps | 282000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -516     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 56500    |\n",
      "|    time_elapsed       | 25626    |\n",
      "|    total_timesteps    | 282500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.73    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56499    |\n",
      "|    policy_loss        | -20.5    |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -521     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 56600    |\n",
      "|    time_elapsed       | 25644    |\n",
      "|    total_timesteps    | 283000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.79    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56599    |\n",
      "|    policy_loss        | -19.2    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -521      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 56700     |\n",
      "|    time_elapsed       | 25656     |\n",
      "|    total_timesteps    | 283500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.95     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56699     |\n",
      "|    policy_loss        | -6.19     |\n",
      "|    value_loss         | 11.9      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=284000, episode_reward=-1092.80 +/- 384.45\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -1.09e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 284000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56799     |\n",
      "|    policy_loss        | 0.783     |\n",
      "|    value_loss         | 0.135     |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -526     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 56800    |\n",
      "|    time_elapsed    | 25801    |\n",
      "|    total_timesteps | 284000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -526      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 56900     |\n",
      "|    time_elapsed       | 25812     |\n",
      "|    total_timesteps    | 284500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.71     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56899     |\n",
      "|    policy_loss        | 0.568     |\n",
      "|    value_loss         | 0.128     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -528     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 57000    |\n",
      "|    time_elapsed       | 25832    |\n",
      "|    total_timesteps    | 285000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.427   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56999    |\n",
      "|    policy_loss        | -0.269   |\n",
      "|    value_loss         | 0.128    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -528     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 57100    |\n",
      "|    time_elapsed       | 25841    |\n",
      "|    total_timesteps    | 285500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.176   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57099    |\n",
      "|    policy_loss        | 0.00176  |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=286000, episode_reward=-502.40 +/- 398.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -502     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 286000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.287   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57199    |\n",
      "|    policy_loss        | 0.00129  |\n",
      "|    value_loss         | 0.0925   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -529     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 57200    |\n",
      "|    time_elapsed    | 25984    |\n",
      "|    total_timesteps | 286000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -529     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 57300    |\n",
      "|    time_elapsed       | 25994    |\n",
      "|    total_timesteps    | 286500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.253   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57299    |\n",
      "|    policy_loss        | 0.00367  |\n",
      "|    value_loss         | 0.0995   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -532     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 57400    |\n",
      "|    time_elapsed       | 26013    |\n",
      "|    total_timesteps    | 287000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.78    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57399    |\n",
      "|    policy_loss        | 0.22     |\n",
      "|    value_loss         | 0.0946   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -532     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 57500    |\n",
      "|    time_elapsed       | 26023    |\n",
      "|    total_timesteps    | 287500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.426   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57499    |\n",
      "|    policy_loss        | -0.00157 |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=-1098.40 +/- 397.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -1.1e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 288000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.2     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57599    |\n",
      "|    policy_loss        | 0.275    |\n",
      "|    value_loss         | 0.0913   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -533     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 57600    |\n",
      "|    time_elapsed    | 26166    |\n",
      "|    total_timesteps | 288000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -533     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 57700    |\n",
      "|    time_elapsed       | 26176    |\n",
      "|    total_timesteps    | 288500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.626   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57699    |\n",
      "|    policy_loss        | 0.00164  |\n",
      "|    value_loss         | 0.0935   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -534     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 57800    |\n",
      "|    time_elapsed       | 26194    |\n",
      "|    total_timesteps    | 289000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57799    |\n",
      "|    policy_loss        | 0.229    |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -534      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 57900     |\n",
      "|    time_elapsed       | 26206     |\n",
      "|    total_timesteps    | 289500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.58     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 57899     |\n",
      "|    policy_loss        | -7.68     |\n",
      "|    value_loss         | 12.7      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=-697.60 +/- 485.33\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -698     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 290000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57999    |\n",
      "|    policy_loss        | -0.119   |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -537     |\n",
      "| time/              |          |\n",
      "|    fps             | 11       |\n",
      "|    iterations      | 58000    |\n",
      "|    time_elapsed    | 26352    |\n",
      "|    total_timesteps | 290000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -537     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 58100    |\n",
      "|    time_elapsed       | 26365    |\n",
      "|    total_timesteps    | 290500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.81    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58099    |\n",
      "|    policy_loss        | 0.759    |\n",
      "|    value_loss         | 0.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 58200    |\n",
      "|    time_elapsed       | 26387    |\n",
      "|    total_timesteps    | 291000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.92    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58199    |\n",
      "|    policy_loss        | -0.0645  |\n",
      "|    value_loss         | 0.0995   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 58300    |\n",
      "|    time_elapsed       | 26398    |\n",
      "|    total_timesteps    | 291500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58299    |\n",
      "|    policy_loss        | 0.563    |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=292000, episode_reward=-502.40 +/- 396.82\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -502      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 292000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.86     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 58399     |\n",
      "|    policy_loss        | 0.162     |\n",
      "|    value_loss         | 0.1       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -541     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 58400    |\n",
      "|    time_elapsed    | 26554    |\n",
      "|    total_timesteps | 292000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -541     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 58500    |\n",
      "|    time_elapsed       | 26563    |\n",
      "|    total_timesteps    | 292500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.53    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58499    |\n",
      "|    policy_loss        | -15.5    |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -546     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 58600    |\n",
      "|    time_elapsed       | 26581    |\n",
      "|    total_timesteps    | 293000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.73    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58599    |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    value_loss         | 0.128    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -546     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 58700    |\n",
      "|    time_elapsed       | 26592    |\n",
      "|    total_timesteps    | 293500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58699    |\n",
      "|    policy_loss        | -14.6    |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=294000, episode_reward=-908.00 +/- 477.08\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -908     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 294000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.37    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58799    |\n",
      "|    policy_loss        | -6.62    |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -548     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 58800    |\n",
      "|    time_elapsed    | 26739    |\n",
      "|    total_timesteps | 294000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -548      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 58900     |\n",
      "|    time_elapsed       | 26750     |\n",
      "|    total_timesteps    | 294500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.631    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 58899     |\n",
      "|    policy_loss        | 0.00925   |\n",
      "|    value_loss         | 0.101     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -547     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 59000    |\n",
      "|    time_elapsed       | 26769    |\n",
      "|    total_timesteps    | 295000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.676   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58999    |\n",
      "|    policy_loss        | -0.0173  |\n",
      "|    value_loss         | 0.0907   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -547     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 59100    |\n",
      "|    time_elapsed       | 26780    |\n",
      "|    total_timesteps    | 295500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.619   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59099    |\n",
      "|    policy_loss        | -0.131   |\n",
      "|    value_loss         | 0.0898   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=296000, episode_reward=-893.00 +/- 495.33\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -893     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 296000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.448   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59199    |\n",
      "|    policy_loss        | 0.797    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -548     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 59200    |\n",
      "|    time_elapsed    | 26925    |\n",
      "|    total_timesteps | 296000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -548     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 59300    |\n",
      "|    time_elapsed       | 26935    |\n",
      "|    total_timesteps    | 296500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.754   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59299    |\n",
      "|    policy_loss        | 0.251    |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -549     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 59400    |\n",
      "|    time_elapsed       | 26952    |\n",
      "|    total_timesteps    | 297000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59399    |\n",
      "|    policy_loss        | -0.381   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -549      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 59500     |\n",
      "|    time_elapsed       | 26966     |\n",
      "|    total_timesteps    | 297500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.97     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 59499     |\n",
      "|    policy_loss        | -9.44     |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=298000, episode_reward=-505.60 +/- 395.26\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -506      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 298000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.72     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 59599     |\n",
      "|    policy_loss        | 0.0469    |\n",
      "|    value_loss         | 0.0944    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -553     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 59600    |\n",
      "|    time_elapsed    | 27113    |\n",
      "|    total_timesteps | 298000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -553     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 59700    |\n",
      "|    time_elapsed       | 27126    |\n",
      "|    total_timesteps    | 298500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59699    |\n",
      "|    policy_loss        | -0.0968  |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -555     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 59800    |\n",
      "|    time_elapsed       | 27142    |\n",
      "|    total_timesteps    | 299000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59799    |\n",
      "|    policy_loss        | -11.6    |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -555     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 59900    |\n",
      "|    time_elapsed       | 27152    |\n",
      "|    total_timesteps    | 299500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.948   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59899    |\n",
      "|    policy_loss        | -0.0266  |\n",
      "|    value_loss         | 0.0928   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=-698.40 +/- 487.94\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -698      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 300000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.568    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 59999     |\n",
      "|    policy_loss        | -0.000967 |\n",
      "|    value_loss         | 0.0887    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -554     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 60000    |\n",
      "|    time_elapsed    | 27297    |\n",
      "|    total_timesteps | 300000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -554     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 60100    |\n",
      "|    time_elapsed       | 27310    |\n",
      "|    total_timesteps    | 300500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.51    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 60099    |\n",
      "|    policy_loss        | -11.8    |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -557      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 60200     |\n",
      "|    time_elapsed       | 27327     |\n",
      "|    total_timesteps    | 301000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.44     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 60199     |\n",
      "|    policy_loss        | 0.152     |\n",
      "|    value_loss         | 0.0903    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -557      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 60300     |\n",
      "|    time_elapsed       | 27338     |\n",
      "|    total_timesteps    | 301500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.644    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 60299     |\n",
      "|    policy_loss        | -0.000693 |\n",
      "|    value_loss         | 0.0897    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=302000, episode_reward=-723.20 +/- 469.88\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -723     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 302000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 60399    |\n",
      "|    policy_loss        | 0.292    |\n",
      "|    value_loss         | 0.0964   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -557     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 60400    |\n",
      "|    time_elapsed    | 27484    |\n",
      "|    total_timesteps | 302000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -557     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 60500    |\n",
      "|    time_elapsed       | 27496    |\n",
      "|    total_timesteps    | 302500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.09    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 60499    |\n",
      "|    policy_loss        | -0.152   |\n",
      "|    value_loss         | 0.0931   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -554     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 60600    |\n",
      "|    time_elapsed       | 27516    |\n",
      "|    total_timesteps    | 303000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.07    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 60599    |\n",
      "|    policy_loss        | 0.315    |\n",
      "|    value_loss         | 0.0911   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -554     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 60700    |\n",
      "|    time_elapsed       | 27526    |\n",
      "|    total_timesteps    | 303500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.725   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 60699    |\n",
      "|    policy_loss        | -7.69    |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=304000, episode_reward=-547.20 +/- 378.23\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -547     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 304000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.16    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 60799    |\n",
      "|    policy_loss        | 0.553    |\n",
      "|    value_loss         | 0.139    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -560     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 60800    |\n",
      "|    time_elapsed    | 27671    |\n",
      "|    total_timesteps | 304000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -560     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 60900    |\n",
      "|    time_elapsed       | 27688    |\n",
      "|    total_timesteps    | 304500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 60899    |\n",
      "|    policy_loss        | -19.1    |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -563     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 61000    |\n",
      "|    time_elapsed       | 27707    |\n",
      "|    total_timesteps    | 305000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.24    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 60999    |\n",
      "|    policy_loss        | -11.3    |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -563     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 61100    |\n",
      "|    time_elapsed       | 27718    |\n",
      "|    total_timesteps    | 305500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 61099    |\n",
      "|    policy_loss        | 0.17     |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=306000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 306000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.21    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 61199    |\n",
      "|    policy_loss        | 0.065    |\n",
      "|    value_loss         | 0.101    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -564     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 61200    |\n",
      "|    time_elapsed    | 27862    |\n",
      "|    total_timesteps | 306000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -564     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 61300    |\n",
      "|    time_elapsed       | 27871    |\n",
      "|    total_timesteps    | 306500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.513   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 61299    |\n",
      "|    policy_loss        | -0.218   |\n",
      "|    value_loss         | 0.0916   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -565     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 61400    |\n",
      "|    time_elapsed       | 27889    |\n",
      "|    total_timesteps    | 307000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.84    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 61399    |\n",
      "|    policy_loss        | 0.404    |\n",
      "|    value_loss         | 0.091    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -565     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 61500    |\n",
      "|    time_elapsed       | 27899    |\n",
      "|    total_timesteps    | 307500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.56    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 61499    |\n",
      "|    policy_loss        | -10.4    |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=308000, episode_reward=-623.20 +/- 407.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -623     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 308000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.57    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 61599    |\n",
      "|    policy_loss        | 0.0129   |\n",
      "|    value_loss         | 0.098    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -566     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 61600    |\n",
      "|    time_elapsed    | 28051    |\n",
      "|    total_timesteps | 308000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -566     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 61700    |\n",
      "|    time_elapsed       | 28065    |\n",
      "|    total_timesteps    | 308500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.46    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 61699    |\n",
      "|    policy_loss        | 0.335    |\n",
      "|    value_loss         | 0.105    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -569     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 61800    |\n",
      "|    time_elapsed       | 28088    |\n",
      "|    total_timesteps    | 309000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 61799    |\n",
      "|    policy_loss        | 0.508    |\n",
      "|    value_loss         | 0.117    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -569     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 61900    |\n",
      "|    time_elapsed       | 28100    |\n",
      "|    total_timesteps    | 309500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.8     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 61899    |\n",
      "|    policy_loss        | 0.308    |\n",
      "|    value_loss         | 0.119    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-740.80 +/- 446.16\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -741     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 310000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 61999    |\n",
      "|    policy_loss        | 0.265    |\n",
      "|    value_loss         | 0.112    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -565     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 62000    |\n",
      "|    time_elapsed    | 28244    |\n",
      "|    total_timesteps | 310000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -565      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 62100     |\n",
      "|    time_elapsed       | 28262     |\n",
      "|    total_timesteps    | 310500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.03     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 62099     |\n",
      "|    policy_loss        | 0.0146    |\n",
      "|    value_loss         | 0.115     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -567     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 62200    |\n",
      "|    time_elapsed       | 28280    |\n",
      "|    total_timesteps    | 311000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.7     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 62199    |\n",
      "|    policy_loss        | 0.564    |\n",
      "|    value_loss         | 0.115    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -567     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 62300    |\n",
      "|    time_elapsed       | 28291    |\n",
      "|    total_timesteps    | 311500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 62299    |\n",
      "|    policy_loss        | -0.085   |\n",
      "|    value_loss         | 0.128    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=312000, episode_reward=-506.40 +/- 394.83\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -506     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 312000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.603   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 62399    |\n",
      "|    policy_loss        | 0.0166   |\n",
      "|    value_loss         | 0.114    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -569     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 62400    |\n",
      "|    time_elapsed    | 28436    |\n",
      "|    total_timesteps | 312000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -569     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 62500    |\n",
      "|    time_elapsed       | 28447    |\n",
      "|    total_timesteps    | 312500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 62499    |\n",
      "|    policy_loss        | 0.312    |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -569     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 62600    |\n",
      "|    time_elapsed       | 28464    |\n",
      "|    total_timesteps    | 313000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.466   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 62599    |\n",
      "|    policy_loss        | 0.00734  |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -569     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 62700    |\n",
      "|    time_elapsed       | 28474    |\n",
      "|    total_timesteps    | 313500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.194   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 62699    |\n",
      "|    policy_loss        | 0.00085  |\n",
      "|    value_loss         | 0.0928   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=314000, episode_reward=-342.40 +/- 49.09\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -342      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 314000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.159    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 62799     |\n",
      "|    policy_loss        | -0.000129 |\n",
      "|    value_loss         | 0.0889    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -569     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 62800    |\n",
      "|    time_elapsed    | 28617    |\n",
      "|    total_timesteps | 314000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -569     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 62900    |\n",
      "|    time_elapsed       | 28628    |\n",
      "|    total_timesteps    | 314500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.372   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 62899    |\n",
      "|    policy_loss        | 0.00104  |\n",
      "|    value_loss         | 0.0921   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -571     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 63000    |\n",
      "|    time_elapsed       | 28650    |\n",
      "|    total_timesteps    | 315000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.505   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 62999    |\n",
      "|    policy_loss        | 0.000182 |\n",
      "|    value_loss         | 0.0903   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -571      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 63100     |\n",
      "|    time_elapsed       | 28659     |\n",
      "|    total_timesteps    | 315500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.61     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63099     |\n",
      "|    policy_loss        | -9.59     |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=316000, episode_reward=-305.60 +/- 4.08\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -306     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 316000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.267   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 63199    |\n",
      "|    policy_loss        | 0.00469  |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -576     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 63200    |\n",
      "|    time_elapsed    | 28804    |\n",
      "|    total_timesteps | 316000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -576     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 63300    |\n",
      "|    time_elapsed       | 28814    |\n",
      "|    total_timesteps    | 316500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.83    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 63299    |\n",
      "|    policy_loss        | -11.9    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -577     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 63400    |\n",
      "|    time_elapsed       | 28833    |\n",
      "|    total_timesteps    | 317000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 63399    |\n",
      "|    policy_loss        | -13.8    |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -577      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 63500     |\n",
      "|    time_elapsed       | 28842     |\n",
      "|    total_timesteps    | 317500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.482    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63499     |\n",
      "|    policy_loss        | 0.000969  |\n",
      "|    value_loss         | 0.0923    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=318000, episode_reward=-319.20 +/- 11.14\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -319      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 318000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.277    |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63599     |\n",
      "|    policy_loss        | -0.000603 |\n",
      "|    value_loss         | 0.0886    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -577     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 63600    |\n",
      "|    time_elapsed    | 28985    |\n",
      "|    total_timesteps | 318000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -577     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 63700    |\n",
      "|    time_elapsed       | 28994    |\n",
      "|    total_timesteps    | 318500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.683   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 63699    |\n",
      "|    policy_loss        | -0.00121 |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -578     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 63800    |\n",
      "|    time_elapsed       | 29012    |\n",
      "|    total_timesteps    | 319000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.699   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 63799    |\n",
      "|    policy_loss        | -0.00703 |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -578      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 63900     |\n",
      "|    time_elapsed       | 29023     |\n",
      "|    total_timesteps    | 319500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.494    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63899     |\n",
      "|    policy_loss        | 0.00489   |\n",
      "|    value_loss         | 0.0998    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 320000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.398   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 63999    |\n",
      "|    policy_loss        | -0.195   |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -582     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 64000    |\n",
      "|    time_elapsed    | 29170    |\n",
      "|    total_timesteps | 320000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -582     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 64100    |\n",
      "|    time_elapsed       | 29180    |\n",
      "|    total_timesteps    | 320500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.378   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 64099    |\n",
      "|    policy_loss        | -0.173   |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -585     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 64200    |\n",
      "|    time_elapsed       | 29199    |\n",
      "|    total_timesteps    | 321000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.19    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 64199    |\n",
      "|    policy_loss        | -2.15    |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -585      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 64300     |\n",
      "|    time_elapsed       | 29209     |\n",
      "|    total_timesteps    | 321500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.703    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 64299     |\n",
      "|    policy_loss        | 0.041     |\n",
      "|    value_loss         | 0.234     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=322000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 322000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 64399    |\n",
      "|    policy_loss        | 0.93     |\n",
      "|    value_loss         | 0.183    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -584     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 64400    |\n",
      "|    time_elapsed    | 29353    |\n",
      "|    total_timesteps | 322000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -584     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 64500    |\n",
      "|    time_elapsed       | 29363    |\n",
      "|    total_timesteps    | 322500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.19    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 64499    |\n",
      "|    policy_loss        | -6.05    |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -588     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 64600    |\n",
      "|    time_elapsed       | 29379    |\n",
      "|    total_timesteps    | 323000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.64    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 64599    |\n",
      "|    policy_loss        | 1.26     |\n",
      "|    value_loss         | 0.418    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -588      |\n",
      "| time/                 |           |\n",
      "|    fps                | 11        |\n",
      "|    iterations         | 64700     |\n",
      "|    time_elapsed       | 29389     |\n",
      "|    total_timesteps    | 323500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.35     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 64699     |\n",
      "|    policy_loss        | 0.451     |\n",
      "|    value_loss         | 0.312     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=324000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 324000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.22    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 64799    |\n",
      "|    policy_loss        | 0.087    |\n",
      "|    value_loss         | 0.26     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -584     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 64800    |\n",
      "|    time_elapsed    | 29536    |\n",
      "|    total_timesteps | 324000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -584      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 64900     |\n",
      "|    time_elapsed       | 29545     |\n",
      "|    total_timesteps    | 324500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.17     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 64899     |\n",
      "|    policy_loss        | 0.24      |\n",
      "|    value_loss         | 0.194     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -579     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 65000    |\n",
      "|    time_elapsed       | 29561    |\n",
      "|    total_timesteps    | 325000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.867   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 64999    |\n",
      "|    policy_loss        | 0.313    |\n",
      "|    value_loss         | 0.149    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -579     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 65100    |\n",
      "|    time_elapsed       | 29570    |\n",
      "|    total_timesteps    | 325500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.503   |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 65099    |\n",
      "|    policy_loss        | 0.015    |\n",
      "|    value_loss         | 0.117    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=326000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 326000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.774   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 65199    |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -575     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 65200    |\n",
      "|    time_elapsed    | 29713    |\n",
      "|    total_timesteps | 326000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -575     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 65300    |\n",
      "|    time_elapsed       | 29725    |\n",
      "|    total_timesteps    | 326500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.09    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 65299    |\n",
      "|    policy_loss        | 0.394    |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -577     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 65400    |\n",
      "|    time_elapsed       | 29748    |\n",
      "|    total_timesteps    | 327000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.17    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 65399    |\n",
      "|    policy_loss        | -0.00162 |\n",
      "|    value_loss         | 0.0956   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -577     |\n",
      "| time/                 |          |\n",
      "|    fps                | 11       |\n",
      "|    iterations         | 65500    |\n",
      "|    time_elapsed       | 29760    |\n",
      "|    total_timesteps    | 327500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.55    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 65499    |\n",
      "|    policy_loss        | -3.44    |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=328000, episode_reward=-349.60 +/- 99.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -350     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 328000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.908   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 65599    |\n",
      "|    policy_loss        | -0.00703 |\n",
      "|    value_loss         | 0.093    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -578     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 65600    |\n",
      "|    time_elapsed    | 29912    |\n",
      "|    total_timesteps | 328000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -578     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 65700    |\n",
      "|    time_elapsed       | 29924    |\n",
      "|    total_timesteps    | 328500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.8     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 65699    |\n",
      "|    policy_loss        | 0.0468   |\n",
      "|    value_loss         | 0.094    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -579     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 65800    |\n",
      "|    time_elapsed       | 29942    |\n",
      "|    total_timesteps    | 329000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.293   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 65799    |\n",
      "|    policy_loss        | 4.11e-05 |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -579     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 65900    |\n",
      "|    time_elapsed       | 29960    |\n",
      "|    total_timesteps    | 329500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 65899    |\n",
      "|    policy_loss        | -14.8    |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 330000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.94    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 65999    |\n",
      "|    policy_loss        | -4.66    |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -580     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 66000    |\n",
      "|    time_elapsed    | 30123    |\n",
      "|    total_timesteps | 330000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -580     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 66100    |\n",
      "|    time_elapsed       | 30133    |\n",
      "|    total_timesteps    | 330500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.335   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 66099    |\n",
      "|    policy_loss        | 0.000878 |\n",
      "|    value_loss         | 0.0919   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -576      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 66200     |\n",
      "|    time_elapsed       | 30150     |\n",
      "|    total_timesteps    | 331000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.359    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 66199     |\n",
      "|    policy_loss        | -0.00259  |\n",
      "|    value_loss         | 0.0884    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -576     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 66300    |\n",
      "|    time_elapsed       | 30160    |\n",
      "|    total_timesteps    | 331500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.549   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 66299    |\n",
      "|    policy_loss        | -0.00977 |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=332000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 332000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.367   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 66399    |\n",
      "|    policy_loss        | -0.00324 |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -571     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 66400    |\n",
      "|    time_elapsed    | 30308    |\n",
      "|    total_timesteps | 332000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -571     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 66500    |\n",
      "|    time_elapsed       | 30319    |\n",
      "|    total_timesteps    | 332500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.287   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 66499    |\n",
      "|    policy_loss        | -0.469   |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -567     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 66600    |\n",
      "|    time_elapsed       | 30337    |\n",
      "|    total_timesteps    | 333000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.285   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 66599    |\n",
      "|    policy_loss        | -0.00376 |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -567      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 66700     |\n",
      "|    time_elapsed       | 30348     |\n",
      "|    total_timesteps    | 333500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.339    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 66699     |\n",
      "|    policy_loss        | 0.174     |\n",
      "|    value_loss         | 0.0888    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=334000, episode_reward=-304.00 +/- 5.06\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -304     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 334000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.554   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 66799    |\n",
      "|    policy_loss        | -0.0072  |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -563     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 66800    |\n",
      "|    time_elapsed    | 30490    |\n",
      "|    total_timesteps | 334000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -563     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 66900    |\n",
      "|    time_elapsed       | 30500    |\n",
      "|    total_timesteps    | 334500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.643   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 66899    |\n",
      "|    policy_loss        | -0.00965 |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -559     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 67000    |\n",
      "|    time_elapsed       | 30519    |\n",
      "|    total_timesteps    | 335000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 66999    |\n",
      "|    policy_loss        | -0.275   |\n",
      "|    value_loss         | 0.0895   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -559     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 67100    |\n",
      "|    time_elapsed       | 30529    |\n",
      "|    total_timesteps    | 335500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.78    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 67099    |\n",
      "|    policy_loss        | 0.0319   |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=336000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 336000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 67199    |\n",
      "|    policy_loss        | -0.0273  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -561     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 67200    |\n",
      "|    time_elapsed    | 30672    |\n",
      "|    total_timesteps | 336000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -561     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 67300    |\n",
      "|    time_elapsed       | 30682    |\n",
      "|    total_timesteps    | 336500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.472   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 67299    |\n",
      "|    policy_loss        | -0.00548 |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -556     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 67400    |\n",
      "|    time_elapsed       | 30701    |\n",
      "|    total_timesteps    | 337000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.755   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 67399    |\n",
      "|    policy_loss        | -0.0052  |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -556     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 67500    |\n",
      "|    time_elapsed       | 30711    |\n",
      "|    total_timesteps    | 337500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.983   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 67499    |\n",
      "|    policy_loss        | 0.00469  |\n",
      "|    value_loss         | 0.0972   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=338000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 338000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.74    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 67599    |\n",
      "|    policy_loss        | -0.00324 |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -554     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 67600    |\n",
      "|    time_elapsed    | 30855    |\n",
      "|    total_timesteps | 338000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -554     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 67700    |\n",
      "|    time_elapsed       | 30865    |\n",
      "|    total_timesteps    | 338500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.434   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 67699    |\n",
      "|    policy_loss        | -0.00256 |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -553     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 67800    |\n",
      "|    time_elapsed       | 30882    |\n",
      "|    total_timesteps    | 339000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.77    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 67799    |\n",
      "|    policy_loss        | 0.111    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -553     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 67900    |\n",
      "|    time_elapsed       | 30892    |\n",
      "|    total_timesteps    | 339500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 67899    |\n",
      "|    policy_loss        | -0.109   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=-293.80 +/- 12.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -294     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 340000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.17    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 67999    |\n",
      "|    policy_loss        | -0.0248  |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -550     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 68000    |\n",
      "|    time_elapsed    | 31041    |\n",
      "|    total_timesteps | 340000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -550     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 68100    |\n",
      "|    time_elapsed       | 31052    |\n",
      "|    total_timesteps    | 340500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.41    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 68099    |\n",
      "|    policy_loss        | -0.408   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -552     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 68200    |\n",
      "|    time_elapsed       | 31071    |\n",
      "|    total_timesteps    | 341000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 68199    |\n",
      "|    policy_loss        | 0.105    |\n",
      "|    value_loss         | 0.0892   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -552     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 68300    |\n",
      "|    time_elapsed       | 31081    |\n",
      "|    total_timesteps    | 341500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.835   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 68299    |\n",
      "|    policy_loss        | -7.32    |\n",
      "|    value_loss         | 13.2     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=342000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 342000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.862   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 68399    |\n",
      "|    policy_loss        | -0.0131  |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -548     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 68400    |\n",
      "|    time_elapsed    | 31224    |\n",
      "|    total_timesteps | 342000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -548     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 68500    |\n",
      "|    time_elapsed       | 31234    |\n",
      "|    total_timesteps    | 342500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 68499    |\n",
      "|    policy_loss        | 0.0479   |\n",
      "|    value_loss         | 0.0932   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -552      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 68600     |\n",
      "|    time_elapsed       | 31253     |\n",
      "|    total_timesteps    | 343000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.646    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 68599     |\n",
      "|    policy_loss        | -0.0115   |\n",
      "|    value_loss         | 0.0909    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -552      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 68700     |\n",
      "|    time_elapsed       | 31265     |\n",
      "|    total_timesteps    | 343500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.07     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 68699     |\n",
      "|    policy_loss        | -0.0826   |\n",
      "|    value_loss         | 0.0884    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=344000, episode_reward=-301.60 +/- 1.96\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -302     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 344000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 68799    |\n",
      "|    policy_loss        | -0.09    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -552     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 68800    |\n",
      "|    time_elapsed    | 31411    |\n",
      "|    total_timesteps | 344000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -552      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 68900     |\n",
      "|    time_elapsed       | 31423     |\n",
      "|    total_timesteps    | 344500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.71     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 68899     |\n",
      "|    policy_loss        | -0.175    |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -545      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 69000     |\n",
      "|    time_elapsed       | 31443     |\n",
      "|    total_timesteps    | 345000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.11     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 68999     |\n",
      "|    policy_loss        | 0.106     |\n",
      "|    value_loss         | 0.0887    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -545     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 69100    |\n",
      "|    time_elapsed       | 31453    |\n",
      "|    total_timesteps    | 345500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 69099    |\n",
      "|    policy_loss        | 0.0684   |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=346000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 346000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 69199    |\n",
      "|    policy_loss        | -0.455   |\n",
      "|    value_loss         | 0.0896   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -539     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 69200    |\n",
      "|    time_elapsed    | 31595    |\n",
      "|    total_timesteps | 346000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 69300    |\n",
      "|    time_elapsed       | 31607    |\n",
      "|    total_timesteps    | 346500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 69299    |\n",
      "|    policy_loss        | -0.179   |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -536      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 69400     |\n",
      "|    time_elapsed       | 31628     |\n",
      "|    total_timesteps    | 347000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.7      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 69399     |\n",
      "|    policy_loss        | 0.791     |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -536      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 69500     |\n",
      "|    time_elapsed       | 31638     |\n",
      "|    total_timesteps    | 347500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.25     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 69499     |\n",
      "|    policy_loss        | -0.594    |\n",
      "|    value_loss         | 0.0889    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=348000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 348000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.29    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 69599    |\n",
      "|    policy_loss        | -0.0456  |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -535     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 69600    |\n",
      "|    time_elapsed    | 31788    |\n",
      "|    total_timesteps | 348000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -535      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 69700     |\n",
      "|    time_elapsed       | 31799     |\n",
      "|    total_timesteps    | 348500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.51     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 69699     |\n",
      "|    policy_loss        | -16.8     |\n",
      "|    value_loss         | 12.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 69800    |\n",
      "|    time_elapsed       | 31818    |\n",
      "|    total_timesteps    | 349000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.78    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 69799    |\n",
      "|    policy_loss        | -15.2    |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 69900    |\n",
      "|    time_elapsed       | 31831    |\n",
      "|    total_timesteps    | 349500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 69899    |\n",
      "|    policy_loss        | 0.0261   |\n",
      "|    value_loss         | 0.0953   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-497.60 +/- 393.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -498     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 350000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.53    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 69999    |\n",
      "|    policy_loss        | 0.415    |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -539     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 70000    |\n",
      "|    time_elapsed    | 31974    |\n",
      "|    total_timesteps | 350000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 70100    |\n",
      "|    time_elapsed       | 31984    |\n",
      "|    total_timesteps    | 350500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.73    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70099    |\n",
      "|    policy_loss        | -0.326   |\n",
      "|    value_loss         | 0.0899   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -540     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 70200    |\n",
      "|    time_elapsed       | 32000    |\n",
      "|    total_timesteps    | 351000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.79    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70199    |\n",
      "|    policy_loss        | -0.219   |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -540     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 70300    |\n",
      "|    time_elapsed       | 32012    |\n",
      "|    total_timesteps    | 351500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.38    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70299    |\n",
      "|    policy_loss        | -0.0913  |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=352000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 352000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70399    |\n",
      "|    policy_loss        | -0.0915  |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -542     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 70400    |\n",
      "|    time_elapsed    | 32156    |\n",
      "|    total_timesteps | 352000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -542     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 70500    |\n",
      "|    time_elapsed       | 32167    |\n",
      "|    total_timesteps    | 352500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.56    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70499    |\n",
      "|    policy_loss        | -0.182   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -542     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 70600    |\n",
      "|    time_elapsed       | 32184    |\n",
      "|    total_timesteps    | 353000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70599    |\n",
      "|    policy_loss        | -0.287   |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -542     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 70700    |\n",
      "|    time_elapsed       | 32193    |\n",
      "|    total_timesteps    | 353500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.79    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70699    |\n",
      "|    policy_loss        | -0.00441 |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=354000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 354000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70799    |\n",
      "|    policy_loss        | -0.0152  |\n",
      "|    value_loss         | 0.0897   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -538     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 70800    |\n",
      "|    time_elapsed    | 32336    |\n",
      "|    total_timesteps | 354000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -538     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 70900    |\n",
      "|    time_elapsed       | 32347    |\n",
      "|    total_timesteps    | 354500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70899    |\n",
      "|    policy_loss        | -0.0556  |\n",
      "|    value_loss         | 0.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -535     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 71000    |\n",
      "|    time_elapsed       | 32369    |\n",
      "|    total_timesteps    | 355000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.67    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70999    |\n",
      "|    policy_loss        | -0.083   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -535     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 71100    |\n",
      "|    time_elapsed       | 32380    |\n",
      "|    total_timesteps    | 355500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 71099    |\n",
      "|    policy_loss        | 0.109    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=356000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 356000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.67    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 71199    |\n",
      "|    policy_loss        | -6.52    |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -535     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 71200    |\n",
      "|    time_elapsed    | 32525    |\n",
      "|    total_timesteps | 356000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -535     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 71300    |\n",
      "|    time_elapsed       | 32537    |\n",
      "|    total_timesteps    | 356500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.977   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 71299    |\n",
      "|    policy_loss        | 0.15     |\n",
      "|    value_loss         | 0.0908   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -535     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 71400    |\n",
      "|    time_elapsed       | 32554    |\n",
      "|    total_timesteps    | 357000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.662   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 71399    |\n",
      "|    policy_loss        | 0.203    |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -535      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 71500     |\n",
      "|    time_elapsed       | 32566     |\n",
      "|    total_timesteps    | 357500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.05     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 71499     |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=358000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -301      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 358000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.17     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 71599     |\n",
      "|    policy_loss        | -4.93     |\n",
      "|    value_loss         | 12.5      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -539     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 71600    |\n",
      "|    time_elapsed    | 32711    |\n",
      "|    total_timesteps | 358000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 71700    |\n",
      "|    time_elapsed       | 32721    |\n",
      "|    total_timesteps    | 358500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.434   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 71699    |\n",
      "|    policy_loss        | 0.000386 |\n",
      "|    value_loss         | 0.0907   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 71800    |\n",
      "|    time_elapsed       | 32737    |\n",
      "|    total_timesteps    | 359000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.588   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 71799    |\n",
      "|    policy_loss        | -0.00133 |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 71900    |\n",
      "|    time_elapsed       | 32747    |\n",
      "|    total_timesteps    | 359500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.7     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 71899    |\n",
      "|    policy_loss        | 0.323    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 360000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 71999    |\n",
      "|    policy_loss        | -0.406   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -539     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 72000    |\n",
      "|    time_elapsed    | 32890    |\n",
      "|    total_timesteps | 360000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 72100    |\n",
      "|    time_elapsed       | 32900    |\n",
      "|    total_timesteps    | 360500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 72099    |\n",
      "|    policy_loss        | -7.16    |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -544     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 72200    |\n",
      "|    time_elapsed       | 32918    |\n",
      "|    total_timesteps    | 361000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.46    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 72199    |\n",
      "|    policy_loss        | 0.152    |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -544     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 72300    |\n",
      "|    time_elapsed       | 32931    |\n",
      "|    total_timesteps    | 361500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.55    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 72299    |\n",
      "|    policy_loss        | -11.9    |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=362000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 362000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 72399    |\n",
      "|    policy_loss        | 0.238    |\n",
      "|    value_loss         | 0.0951   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -545     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 72400    |\n",
      "|    time_elapsed    | 33082    |\n",
      "|    total_timesteps | 362000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -545      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 72500     |\n",
      "|    time_elapsed       | 33093     |\n",
      "|    total_timesteps    | 362500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.13     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 72499     |\n",
      "|    policy_loss        | 0.178     |\n",
      "|    value_loss         | 0.0894    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -540      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 72600     |\n",
      "|    time_elapsed       | 33113     |\n",
      "|    total_timesteps    | 363000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.96     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 72599     |\n",
      "|    policy_loss        | -17.1     |\n",
      "|    value_loss         | 12.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -540     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 72700    |\n",
      "|    time_elapsed       | 33122    |\n",
      "|    total_timesteps    | 363500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 72699    |\n",
      "|    policy_loss        | 0.0593   |\n",
      "|    value_loss         | 0.0915   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=364000, episode_reward=-535.20 +/- 359.47\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -535     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 364000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 72799    |\n",
      "|    policy_loss        | -6.39    |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -539     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 72800    |\n",
      "|    time_elapsed    | 33266    |\n",
      "|    total_timesteps | 364000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -539     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 72900    |\n",
      "|    time_elapsed       | 33278    |\n",
      "|    total_timesteps    | 364500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.39    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 72899    |\n",
      "|    policy_loss        | 0.134    |\n",
      "|    value_loss         | 0.0974   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -540     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 73000    |\n",
      "|    time_elapsed       | 33299    |\n",
      "|    total_timesteps    | 365000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.33    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 72999    |\n",
      "|    policy_loss        | -15.1    |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -540     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 73100    |\n",
      "|    time_elapsed       | 33309    |\n",
      "|    total_timesteps    | 365500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 73099    |\n",
      "|    policy_loss        | 0.47     |\n",
      "|    value_loss         | 0.124    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=366000, episode_reward=-301.60 +/- 3.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -302     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 366000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.995   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 73199    |\n",
      "|    policy_loss        | 0.0258   |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -537     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 73200    |\n",
      "|    time_elapsed    | 33454    |\n",
      "|    total_timesteps | 366000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -537     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 73300    |\n",
      "|    time_elapsed       | 33465    |\n",
      "|    total_timesteps    | 366500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.77    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 73299    |\n",
      "|    policy_loss        | 0.432    |\n",
      "|    value_loss         | 0.141    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -536     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 73400    |\n",
      "|    time_elapsed       | 33493    |\n",
      "|    total_timesteps    | 367000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 73399    |\n",
      "|    policy_loss        | 1.34     |\n",
      "|    value_loss         | 0.128    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -536     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 73500    |\n",
      "|    time_elapsed       | 33510    |\n",
      "|    total_timesteps    | 367500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.72    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 73499    |\n",
      "|    policy_loss        | 0.969    |\n",
      "|    value_loss         | 0.121    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=368000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 368000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.98    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 73599    |\n",
      "|    policy_loss        | -15.9    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -535     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 73600    |\n",
      "|    time_elapsed    | 33659    |\n",
      "|    total_timesteps | 368000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -535     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 73700    |\n",
      "|    time_elapsed       | 33668    |\n",
      "|    total_timesteps    | 368500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.91    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 73699    |\n",
      "|    policy_loss        | 0.584    |\n",
      "|    value_loss         | 0.0973   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -535      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 73800     |\n",
      "|    time_elapsed       | 33685     |\n",
      "|    total_timesteps    | 369000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.65     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 73799     |\n",
      "|    policy_loss        | -0.000876 |\n",
      "|    value_loss         | 0.0909    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -535     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 73900    |\n",
      "|    time_elapsed       | 33694    |\n",
      "|    total_timesteps    | 369500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.22    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 73899    |\n",
      "|    policy_loss        | 0.177    |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=-498.40 +/- 394.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -498      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 370000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.61     |\n",
      "|    explained_variance | -4.41e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 73999     |\n",
      "|    policy_loss        | -0.0705   |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -534     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 74000    |\n",
      "|    time_elapsed    | 33837    |\n",
      "|    total_timesteps | 370000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -534      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 74100     |\n",
      "|    time_elapsed       | 33846     |\n",
      "|    total_timesteps    | 370500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.51     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 74099     |\n",
      "|    policy_loss        | -12.9     |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -532     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 74200    |\n",
      "|    time_elapsed       | 33866    |\n",
      "|    total_timesteps    | 371000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.81    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 74199    |\n",
      "|    policy_loss        | -0.258   |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -532     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 74300    |\n",
      "|    time_elapsed       | 33875    |\n",
      "|    total_timesteps    | 371500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.46    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 74299    |\n",
      "|    policy_loss        | -0.183   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=372000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 372000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 74399    |\n",
      "|    policy_loss        | -0.187   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -529     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 74400    |\n",
      "|    time_elapsed    | 34020    |\n",
      "|    total_timesteps | 372000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -529     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 74500    |\n",
      "|    time_elapsed       | 34031    |\n",
      "|    total_timesteps    | 372500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.57    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 74499    |\n",
      "|    policy_loss        | 0.171    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -527     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 74600    |\n",
      "|    time_elapsed       | 34051    |\n",
      "|    total_timesteps    | 373000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.58    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 74599    |\n",
      "|    policy_loss        | -11.2    |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -527     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 74700    |\n",
      "|    time_elapsed       | 34062    |\n",
      "|    total_timesteps    | 373500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 74699    |\n",
      "|    policy_loss        | 0.0051   |\n",
      "|    value_loss         | 0.0923   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=374000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 374000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 74799    |\n",
      "|    policy_loss        | 0.157    |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -525     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 74800    |\n",
      "|    time_elapsed    | 34204    |\n",
      "|    total_timesteps | 374000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -525      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 74900     |\n",
      "|    time_elapsed       | 34217     |\n",
      "|    total_timesteps    | 374500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.61     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 74899     |\n",
      "|    policy_loss        | -6.41     |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -525      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 75000     |\n",
      "|    time_elapsed       | 34236     |\n",
      "|    total_timesteps    | 375000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.02     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 74999     |\n",
      "|    policy_loss        | 0.0701    |\n",
      "|    value_loss         | 0.0908    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -525      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 75100     |\n",
      "|    time_elapsed       | 34245     |\n",
      "|    total_timesteps    | 375500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.13     |\n",
      "|    explained_variance | -9.54e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75099     |\n",
      "|    policy_loss        | 0.158     |\n",
      "|    value_loss         | 0.0883    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=376000, episode_reward=-484.80 +/- 365.61\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -485     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 376000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.52    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 75199    |\n",
      "|    policy_loss        | -0.198   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -522     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 75200    |\n",
      "|    time_elapsed    | 34386    |\n",
      "|    total_timesteps | 376000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -522     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 75300    |\n",
      "|    time_elapsed       | 34396    |\n",
      "|    total_timesteps    | 376500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2       |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 75299    |\n",
      "|    policy_loss        | -0.326   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -522     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 75400    |\n",
      "|    time_elapsed       | 34414    |\n",
      "|    total_timesteps    | 377000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 75399    |\n",
      "|    policy_loss        | 0.034    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -522     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 75500    |\n",
      "|    time_elapsed       | 34425    |\n",
      "|    total_timesteps    | 377500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.33    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 75499    |\n",
      "|    policy_loss        | -8.34    |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=378000, episode_reward=-311.20 +/- 22.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -311     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 378000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.42    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 75599    |\n",
      "|    policy_loss        | 0.627    |\n",
      "|    value_loss         | 0.096    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -524     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 75600    |\n",
      "|    time_elapsed    | 34579    |\n",
      "|    total_timesteps | 378000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -524      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 75700     |\n",
      "|    time_elapsed       | 34592     |\n",
      "|    total_timesteps    | 378500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.81     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75699     |\n",
      "|    policy_loss        | -4.94     |\n",
      "|    value_loss         | 12.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -524     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 75800    |\n",
      "|    time_elapsed       | 34609    |\n",
      "|    total_timesteps    | 379000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.23    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 75799    |\n",
      "|    policy_loss        | 0.0135   |\n",
      "|    value_loss         | 0.0967   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -524     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 75900    |\n",
      "|    time_elapsed       | 34622    |\n",
      "|    total_timesteps    | 379500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.66    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 75899    |\n",
      "|    policy_loss        | 0.131    |\n",
      "|    value_loss         | 0.097    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=-304.80 +/- 9.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -305      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 380000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.46     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75999     |\n",
      "|    policy_loss        | 0.0173    |\n",
      "|    value_loss         | 0.0905    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -525     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 76000    |\n",
      "|    time_elapsed    | 34768    |\n",
      "|    total_timesteps | 380000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -525     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 76100    |\n",
      "|    time_elapsed       | 34782    |\n",
      "|    total_timesteps    | 380500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 76099    |\n",
      "|    policy_loss        | -0.0793  |\n",
      "|    value_loss         | 0.0894   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -525     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 76200    |\n",
      "|    time_elapsed       | 34799    |\n",
      "|    total_timesteps    | 381000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 76199    |\n",
      "|    policy_loss        | 0.215    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -525     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 76300    |\n",
      "|    time_elapsed       | 34810    |\n",
      "|    total_timesteps    | 381500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 76299    |\n",
      "|    policy_loss        | 0.378    |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=382000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -301      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 382000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.16     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 76399     |\n",
      "|    policy_loss        | -0.017    |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -523     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 76400    |\n",
      "|    time_elapsed    | 34955    |\n",
      "|    total_timesteps | 382000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -523     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 76500    |\n",
      "|    time_elapsed       | 34968    |\n",
      "|    total_timesteps    | 382500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.54    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 76499    |\n",
      "|    policy_loss        | -0.509   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -518     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 76600    |\n",
      "|    time_elapsed       | 34986    |\n",
      "|    total_timesteps    | 383000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 76599    |\n",
      "|    policy_loss        | 0.164    |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -518     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 76700    |\n",
      "|    time_elapsed       | 34998    |\n",
      "|    total_timesteps    | 383500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.37    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 76699    |\n",
      "|    policy_loss        | 0.0576   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=384000, episode_reward=-460.80 +/- 321.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -461     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 384000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.2     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 76799    |\n",
      "|    policy_loss        | 0.138    |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -514     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 76800    |\n",
      "|    time_elapsed    | 35152    |\n",
      "|    total_timesteps | 384000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -514     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 76900    |\n",
      "|    time_elapsed       | 35163    |\n",
      "|    total_timesteps    | 384500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.64    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 76899    |\n",
      "|    policy_loss        | 0.0272   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 77000    |\n",
      "|    time_elapsed       | 35183    |\n",
      "|    total_timesteps    | 385000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.5     |\n",
      "|    explained_variance | 2.68e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 76999    |\n",
      "|    policy_loss        | -11.6    |\n",
      "|    value_loss         | 13.2     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 77100    |\n",
      "|    time_elapsed       | 35196    |\n",
      "|    total_timesteps    | 385500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 77099    |\n",
      "|    policy_loss        | 0.128    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=386000, episode_reward=-563.20 +/- 365.15\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -563      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 386000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.79     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77199     |\n",
      "|    policy_loss        | 0.0345    |\n",
      "|    value_loss         | 0.0885    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -513     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 77200    |\n",
      "|    time_elapsed    | 35340    |\n",
      "|    total_timesteps | 386000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 77300    |\n",
      "|    time_elapsed       | 35349    |\n",
      "|    total_timesteps    | 386500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.17    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 77299    |\n",
      "|    policy_loss        | -0.271   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -512     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 77400    |\n",
      "|    time_elapsed       | 35367    |\n",
      "|    total_timesteps    | 387000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.71    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 77399    |\n",
      "|    policy_loss        | -0.154   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -512      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 77500     |\n",
      "|    time_elapsed       | 35376     |\n",
      "|    total_timesteps    | 387500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77499     |\n",
      "|    policy_loss        | 0.137     |\n",
      "|    value_loss         | 0.0885    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=388000, episode_reward=-327.20 +/- 50.43\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -327     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 388000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 77599    |\n",
      "|    policy_loss        | -0.0808  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -511     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 77600    |\n",
      "|    time_elapsed    | 35525    |\n",
      "|    total_timesteps | 388000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -511      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 77700     |\n",
      "|    time_elapsed       | 35535     |\n",
      "|    total_timesteps    | 388500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.47     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77699     |\n",
      "|    policy_loss        | 0.04      |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -511     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 77800    |\n",
      "|    time_elapsed       | 35551    |\n",
      "|    total_timesteps    | 389000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 77799    |\n",
      "|    policy_loss        | 0.0583   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -511     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 77900    |\n",
      "|    time_elapsed       | 35562    |\n",
      "|    total_timesteps    | 389500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.11    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 77899    |\n",
      "|    policy_loss        | -0.0319  |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=-496.00 +/- 390.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -496      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 390000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.46     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77999     |\n",
      "|    policy_loss        | -0.077    |\n",
      "|    value_loss         | 0.0888    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -506     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 78000    |\n",
      "|    time_elapsed    | 35714    |\n",
      "|    total_timesteps | 390000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -506      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 78100     |\n",
      "|    time_elapsed       | 35723     |\n",
      "|    total_timesteps    | 390500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.99     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78099     |\n",
      "|    policy_loss        | 0.156     |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 78200    |\n",
      "|    time_elapsed       | 35740    |\n",
      "|    total_timesteps    | 391000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 78199    |\n",
      "|    policy_loss        | -0.337   |\n",
      "|    value_loss         | 0.0994   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 78300    |\n",
      "|    time_elapsed       | 35749    |\n",
      "|    total_timesteps    | 391500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 78299    |\n",
      "|    policy_loss        | 0.0321   |\n",
      "|    value_loss         | 0.0908   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=392000, episode_reward=-303.20 +/- 6.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -303      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 392000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.934    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78399     |\n",
      "|    policy_loss        | -0.243    |\n",
      "|    value_loss         | 0.0883    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -505     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 78400    |\n",
      "|    time_elapsed    | 35896    |\n",
      "|    total_timesteps | 392000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -505     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 78500    |\n",
      "|    time_elapsed       | 35906    |\n",
      "|    total_timesteps    | 392500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.59    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 78499    |\n",
      "|    policy_loss        | -9.52    |\n",
      "|    value_loss         | 13.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -500      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 78600     |\n",
      "|    time_elapsed       | 35924     |\n",
      "|    total_timesteps    | 393000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.97     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78599     |\n",
      "|    policy_loss        | -0.317    |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -500     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 78700    |\n",
      "|    time_elapsed       | 35933    |\n",
      "|    total_timesteps    | 393500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 78699    |\n",
      "|    policy_loss        | 0.357    |\n",
      "|    value_loss         | 0.0928   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=394000, episode_reward=-320.20 +/- 53.53\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -320     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 394000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.952   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 78799    |\n",
      "|    policy_loss        | -0.0689  |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -500     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 78800    |\n",
      "|    time_elapsed    | 36075    |\n",
      "|    total_timesteps | 394000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -500     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 78900    |\n",
      "|    time_elapsed       | 36084    |\n",
      "|    total_timesteps    | 394500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.695   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 78899    |\n",
      "|    policy_loss        | -0.00692 |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -501     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 79000    |\n",
      "|    time_elapsed       | 36101    |\n",
      "|    total_timesteps    | 395000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.78    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 78999    |\n",
      "|    policy_loss        | -0.286   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -501     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 79100    |\n",
      "|    time_elapsed       | 36111    |\n",
      "|    total_timesteps    | 395500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 79099    |\n",
      "|    policy_loss        | 0.0995   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=396000, episode_reward=-302.40 +/- 3.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -302     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 396000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.757   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 79199    |\n",
      "|    policy_loss        | -0.15    |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -500     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 79200    |\n",
      "|    time_elapsed    | 36254    |\n",
      "|    total_timesteps | 396000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -500     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 79300    |\n",
      "|    time_elapsed       | 36265    |\n",
      "|    total_timesteps    | 396500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.71    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 79299    |\n",
      "|    policy_loss        | 0.00456  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -500     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 79400    |\n",
      "|    time_elapsed       | 36284    |\n",
      "|    total_timesteps    | 397000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.44    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 79399    |\n",
      "|    policy_loss        | -5.65    |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -500     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 79500    |\n",
      "|    time_elapsed       | 36294    |\n",
      "|    total_timesteps    | 397500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 79499    |\n",
      "|    policy_loss        | -0.0162  |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=398000, episode_reward=-352.80 +/- 91.89\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -353     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 398000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.926   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 79599    |\n",
      "|    policy_loss        | -0.0153  |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -498     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 79600    |\n",
      "|    time_elapsed    | 36459    |\n",
      "|    total_timesteps | 398000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -498     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 79700    |\n",
      "|    time_elapsed       | 36471    |\n",
      "|    total_timesteps    | 398500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 79699    |\n",
      "|    policy_loss        | -0.32    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -496     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 79800    |\n",
      "|    time_elapsed       | 36491    |\n",
      "|    total_timesteps    | 399000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.869   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 79799    |\n",
      "|    policy_loss        | -0.102   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -496     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 79900    |\n",
      "|    time_elapsed       | 36501    |\n",
      "|    total_timesteps    | 399500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 79899    |\n",
      "|    policy_loss        | -7.65    |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=-588.20 +/- 393.05\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -588     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 400000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.971   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 79999    |\n",
      "|    policy_loss        | 0.148    |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -495     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 80000    |\n",
      "|    time_elapsed    | 36676    |\n",
      "|    total_timesteps | 400000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -495     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 80100    |\n",
      "|    time_elapsed       | 36685    |\n",
      "|    total_timesteps    | 400500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.833   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 80099    |\n",
      "|    policy_loss        | 0.0139   |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -492     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 80200    |\n",
      "|    time_elapsed       | 36701    |\n",
      "|    total_timesteps    | 401000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.853   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 80199    |\n",
      "|    policy_loss        | -3.56    |\n",
      "|    value_loss         | 13.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -492     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 80300    |\n",
      "|    time_elapsed       | 36711    |\n",
      "|    total_timesteps    | 401500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 80299    |\n",
      "|    policy_loss        | -0.412   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=402000, episode_reward=-418.60 +/- 161.58\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -419      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 402000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.6      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80399     |\n",
      "|    policy_loss        | 0.282     |\n",
      "|    value_loss         | 0.0954    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -493     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 80400    |\n",
      "|    time_elapsed    | 36862    |\n",
      "|    total_timesteps | 402000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -493     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 80500    |\n",
      "|    time_elapsed       | 36871    |\n",
      "|    total_timesteps    | 402500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 80499    |\n",
      "|    policy_loss        | 0.505    |\n",
      "|    value_loss         | 0.1      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -495      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 80600     |\n",
      "|    time_elapsed       | 36888     |\n",
      "|    total_timesteps    | 403000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.11     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80599     |\n",
      "|    policy_loss        | 0.14      |\n",
      "|    value_loss         | 0.0938    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -495     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 80700    |\n",
      "|    time_elapsed       | 36897    |\n",
      "|    total_timesteps    | 403500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.823   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 80699    |\n",
      "|    policy_loss        | 5.7e-05  |\n",
      "|    value_loss         | 0.0897   |\n",
      "------------------------------------\n",
      "<DisconnectMessageData>\n",
      "    <name>player_1</name>\n",
      "    <errortypeCode>TIMEOUT</errortypeCode>\n",
      "</DisconnectMessageData>\n",
      "\n",
      "Eval num_timesteps=404000, episode_reward=-423.80 +/- 245.60\n",
      "Episode length: 949.80 +/- 100.40\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 950       |\n",
      "|    mean_reward        | -424      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 404000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.16     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80799     |\n",
      "|    policy_loss        | 0.0825    |\n",
      "|    value_loss         | 0.0885    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -490     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 80800    |\n",
      "|    time_elapsed    | 37045    |\n",
      "|    total_timesteps | 404000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -490     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 80900    |\n",
      "|    time_elapsed       | 37055    |\n",
      "|    total_timesteps    | 404500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.722   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 80899    |\n",
      "|    policy_loss        | -0.379   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -487      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 81000     |\n",
      "|    time_elapsed       | 37071     |\n",
      "|    total_timesteps    | 405000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.32     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80999     |\n",
      "|    policy_loss        | -0.00762  |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -487     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 81100    |\n",
      "|    time_elapsed       | 37084    |\n",
      "|    total_timesteps    | 405500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 81099    |\n",
      "|    policy_loss        | -0.359   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=406000, episode_reward=-805.60 +/- 434.59\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -806     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 406000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 81199    |\n",
      "|    policy_loss        | -0.0379  |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -486     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 81200    |\n",
      "|    time_elapsed    | 37229    |\n",
      "|    total_timesteps | 406000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -486     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 81300    |\n",
      "|    time_elapsed       | 37240    |\n",
      "|    total_timesteps    | 406500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.55    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 81299    |\n",
      "|    policy_loss        | 0.112    |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -485     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 81400    |\n",
      "|    time_elapsed       | 37261    |\n",
      "|    total_timesteps    | 407000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.876   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 81399    |\n",
      "|    policy_loss        | -0.105   |\n",
      "|    value_loss         | 0.0896   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -485     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 81500    |\n",
      "|    time_elapsed       | 37273    |\n",
      "|    total_timesteps    | 407500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.47    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 81499    |\n",
      "|    policy_loss        | -8.95    |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "<DisconnectMessageData>\n",
      "    <name>player_1</name>\n",
      "    <errortypeCode>TIMEOUT</errortypeCode>\n",
      "</DisconnectMessageData>\n",
      "\n",
      "Eval num_timesteps=408000, episode_reward=-467.60 +/- 420.39\n",
      "Episode length: 897.80 +/- 204.40\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 898      |\n",
      "|    mean_reward        | -468     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 408000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 81599    |\n",
      "|    policy_loss        | 0.116    |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -485     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 81600    |\n",
      "|    time_elapsed    | 37422    |\n",
      "|    total_timesteps | 408000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -485     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 81700    |\n",
      "|    time_elapsed       | 37434    |\n",
      "|    total_timesteps    | 408500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 81699    |\n",
      "|    policy_loss        | -0.0606  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -481     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 81800    |\n",
      "|    time_elapsed       | 37455    |\n",
      "|    total_timesteps    | 409000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 81799    |\n",
      "|    policy_loss        | -0.574   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -481      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 81900     |\n",
      "|    time_elapsed       | 37465     |\n",
      "|    total_timesteps    | 409500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.1      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 81899     |\n",
      "|    policy_loss        | -7.78     |\n",
      "|    value_loss         | 13.3      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=-486.40 +/- 372.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -486     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 410000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.9     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 81999    |\n",
      "|    policy_loss        | -3.96    |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -481     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 82000    |\n",
      "|    time_elapsed    | 37615    |\n",
      "|    total_timesteps | 410000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -481      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 82100     |\n",
      "|    time_elapsed       | 37626     |\n",
      "|    total_timesteps    | 410500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.5      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 82099     |\n",
      "|    policy_loss        | -18.1     |\n",
      "|    value_loss         | 12.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -484     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 82200    |\n",
      "|    time_elapsed       | 37643    |\n",
      "|    total_timesteps    | 411000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.67    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 82199    |\n",
      "|    policy_loss        | 0.482    |\n",
      "|    value_loss         | 0.118    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -484      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 82300     |\n",
      "|    time_elapsed       | 37654     |\n",
      "|    total_timesteps    | 411500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.78     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 82299     |\n",
      "|    policy_loss        | 0.147     |\n",
      "|    value_loss         | 0.105     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=412000, episode_reward=-475.20 +/- 346.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -475     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 412000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.98    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 82399    |\n",
      "|    policy_loss        | 0.438    |\n",
      "|    value_loss         | 0.0936   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -482     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 82400    |\n",
      "|    time_elapsed    | 37803    |\n",
      "|    total_timesteps | 412000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -482      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 82500     |\n",
      "|    time_elapsed       | 37817     |\n",
      "|    total_timesteps    | 412500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.01     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 82499     |\n",
      "|    policy_loss        | -11.8     |\n",
      "|    value_loss         | 12.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -484     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 82600    |\n",
      "|    time_elapsed       | 37835    |\n",
      "|    total_timesteps    | 413000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.46    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 82599    |\n",
      "|    policy_loss        | -11.9    |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -484     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 82700    |\n",
      "|    time_elapsed       | 37847    |\n",
      "|    total_timesteps    | 413500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.17    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 82699    |\n",
      "|    policy_loss        | -13.6    |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=414000, episode_reward=-452.80 +/- 241.31\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -453     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 414000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.74    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 82799    |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    value_loss         | 0.15     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -489     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 82800    |\n",
      "|    time_elapsed    | 37991    |\n",
      "|    total_timesteps | 414000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -489     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 82900    |\n",
      "|    time_elapsed       | 38001    |\n",
      "|    total_timesteps    | 414500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.61    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 82899    |\n",
      "|    policy_loss        | 0.168    |\n",
      "|    value_loss         | 0.119    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -487     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 83000    |\n",
      "|    time_elapsed       | 38019    |\n",
      "|    total_timesteps    | 415000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.24    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 82999    |\n",
      "|    policy_loss        | 0.0906   |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -487     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 83100    |\n",
      "|    time_elapsed       | 38031    |\n",
      "|    total_timesteps    | 415500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.8     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 83099    |\n",
      "|    policy_loss        | -12.5    |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=416000, episode_reward=-522.40 +/- 383.75\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -522      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 416000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.05     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 83199     |\n",
      "|    policy_loss        | 1.17      |\n",
      "|    value_loss         | 0.125     |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -485     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 83200    |\n",
      "|    time_elapsed    | 38178    |\n",
      "|    total_timesteps | 416000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -485     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 83300    |\n",
      "|    time_elapsed       | 38192    |\n",
      "|    total_timesteps    | 416500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.93    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 83299    |\n",
      "|    policy_loss        | 0.83     |\n",
      "|    value_loss         | 0.142    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -486     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 83400    |\n",
      "|    time_elapsed       | 38210    |\n",
      "|    total_timesteps    | 417000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 83399    |\n",
      "|    policy_loss        | 0.0749   |\n",
      "|    value_loss         | 0.115    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -486      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 83500     |\n",
      "|    time_elapsed       | 38220     |\n",
      "|    total_timesteps    | 417500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.56     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 83499     |\n",
      "|    policy_loss        | 0.257     |\n",
      "|    value_loss         | 0.102     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=418000, episode_reward=-422.40 +/- 244.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -422     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 418000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.69    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 83599    |\n",
      "|    policy_loss        | 0.0299   |\n",
      "|    value_loss         | 0.0983   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -487     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 83600    |\n",
      "|    time_elapsed    | 38376    |\n",
      "|    total_timesteps | 418000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -487     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 83700    |\n",
      "|    time_elapsed       | 38387    |\n",
      "|    total_timesteps    | 418500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.57    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 83699    |\n",
      "|    policy_loss        | 0.12     |\n",
      "|    value_loss         | 0.093    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -488     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 83800    |\n",
      "|    time_elapsed       | 38405    |\n",
      "|    total_timesteps    | 419000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 83799    |\n",
      "|    policy_loss        | -0.129   |\n",
      "|    value_loss         | 0.0959   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -488     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 83900    |\n",
      "|    time_elapsed       | 38416    |\n",
      "|    total_timesteps    | 419500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 83899    |\n",
      "|    policy_loss        | -12.6    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=-548.00 +/- 339.82\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -548     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 420000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 83999    |\n",
      "|    policy_loss        | 0.23     |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -484     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 84000    |\n",
      "|    time_elapsed    | 38559    |\n",
      "|    total_timesteps | 420000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -484     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 84100    |\n",
      "|    time_elapsed       | 38569    |\n",
      "|    total_timesteps    | 420500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.63    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 84099    |\n",
      "|    policy_loss        | -0.00892 |\n",
      "|    value_loss         | 0.0925   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -477     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 84200    |\n",
      "|    time_elapsed       | 38595    |\n",
      "|    total_timesteps    | 421000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.781   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 84199    |\n",
      "|    policy_loss        | 0.000938 |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -477      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 84300     |\n",
      "|    time_elapsed       | 38606     |\n",
      "|    total_timesteps    | 421500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.96     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 84299     |\n",
      "|    policy_loss        | 0.19      |\n",
      "|    value_loss         | 0.0886    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=422000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -301      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 422000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.55     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 84399     |\n",
      "|    policy_loss        | -3.2      |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -478     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 84400    |\n",
      "|    time_elapsed    | 38754    |\n",
      "|    total_timesteps | 422000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -478     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 84500    |\n",
      "|    time_elapsed       | 38764    |\n",
      "|    total_timesteps    | 422500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.48    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 84499    |\n",
      "|    policy_loss        | -0.00319 |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -470     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 84600    |\n",
      "|    time_elapsed       | 38780    |\n",
      "|    total_timesteps    | 423000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.01    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 84599    |\n",
      "|    policy_loss        | -0.19    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -470     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 84700    |\n",
      "|    time_elapsed       | 38790    |\n",
      "|    total_timesteps    | 423500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.67    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 84699    |\n",
      "|    policy_loss        | -3.27    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=424000, episode_reward=-376.80 +/- 149.63\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -377     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 424000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.24    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 84799    |\n",
      "|    policy_loss        | -21      |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -475     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 84800    |\n",
      "|    time_elapsed    | 38934    |\n",
      "|    total_timesteps | 424000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -475      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 84900     |\n",
      "|    time_elapsed       | 38951     |\n",
      "|    total_timesteps    | 424500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.46     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 84899     |\n",
      "|    policy_loss        | 0.369     |\n",
      "|    value_loss         | 0.116     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -478     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 85000    |\n",
      "|    time_elapsed       | 38970    |\n",
      "|    total_timesteps    | 425000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.99    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 84999    |\n",
      "|    policy_loss        | 0.249    |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -478     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 85100    |\n",
      "|    time_elapsed       | 38982    |\n",
      "|    total_timesteps    | 425500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.646   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 85099    |\n",
      "|    policy_loss        | -0.0325  |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=426000, episode_reward=-498.40 +/- 184.53\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -498     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 426000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.364   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 85199    |\n",
      "|    policy_loss        | 0.36     |\n",
      "|    value_loss         | 0.0914   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -478     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 85200    |\n",
      "|    time_elapsed    | 39138    |\n",
      "|    total_timesteps | 426000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -478     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 85300    |\n",
      "|    time_elapsed       | 39149    |\n",
      "|    total_timesteps    | 426500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 85299    |\n",
      "|    policy_loss        | 0.344    |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -476     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 85400    |\n",
      "|    time_elapsed       | 39167    |\n",
      "|    total_timesteps    | 427000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 85399    |\n",
      "|    policy_loss        | -18.2    |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -476     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 85500    |\n",
      "|    time_elapsed       | 39182    |\n",
      "|    total_timesteps    | 427500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.43    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 85499    |\n",
      "|    policy_loss        | 0.0469   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=428000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 428000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 85599    |\n",
      "|    policy_loss        | -0.181   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -474     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 85600    |\n",
      "|    time_elapsed    | 39330    |\n",
      "|    total_timesteps | 428000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -474     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 85700    |\n",
      "|    time_elapsed       | 39340    |\n",
      "|    total_timesteps    | 428500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.67    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 85699    |\n",
      "|    policy_loss        | 0.0542   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -477     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 85800    |\n",
      "|    time_elapsed       | 39357    |\n",
      "|    total_timesteps    | 429000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.91    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 85799    |\n",
      "|    policy_loss        | 0.678    |\n",
      "|    value_loss         | 0.0961   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -477     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 85900    |\n",
      "|    time_elapsed       | 39370    |\n",
      "|    total_timesteps    | 429500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.45    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 85899    |\n",
      "|    policy_loss        | 0.0448   |\n",
      "|    value_loss         | 0.0958   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=-600.00 +/- 374.39\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -600     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 430000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.26    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 85999    |\n",
      "|    policy_loss        | -12.1    |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -475     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 86000    |\n",
      "|    time_elapsed    | 39517    |\n",
      "|    total_timesteps | 430000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -475     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 86100    |\n",
      "|    time_elapsed       | 39530    |\n",
      "|    total_timesteps    | 430500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86099    |\n",
      "|    policy_loss        | -6.06    |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -476     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 86200    |\n",
      "|    time_elapsed       | 39551    |\n",
      "|    total_timesteps    | 431000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.9     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86199    |\n",
      "|    policy_loss        | 0.186    |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -476     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 86300    |\n",
      "|    time_elapsed       | 39575    |\n",
      "|    total_timesteps    | 431500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86299    |\n",
      "|    policy_loss        | -19.6    |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=432000, episode_reward=-500.00 +/- 199.92\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -500     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 432000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.35    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86399    |\n",
      "|    policy_loss        | -0.0382  |\n",
      "|    value_loss         | 0.0898   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -478     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 86400    |\n",
      "|    time_elapsed    | 39719    |\n",
      "|    total_timesteps | 432000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -478     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 86500    |\n",
      "|    time_elapsed       | 39731    |\n",
      "|    total_timesteps    | 432500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.38    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86499    |\n",
      "|    policy_loss        | 0.0797   |\n",
      "|    value_loss         | 0.105    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -485     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 86600    |\n",
      "|    time_elapsed       | 39749    |\n",
      "|    total_timesteps    | 433000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86599    |\n",
      "|    policy_loss        | -3.35    |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -485     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 86700    |\n",
      "|    time_elapsed       | 39759    |\n",
      "|    total_timesteps    | 433500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.316   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86699    |\n",
      "|    policy_loss        | -11.4    |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=434000, episode_reward=-367.40 +/- 86.11\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -367     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 434000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.465   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86799    |\n",
      "|    policy_loss        | 0.0052   |\n",
      "|    value_loss         | 0.0961   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -485     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 86800    |\n",
      "|    time_elapsed    | 39922    |\n",
      "|    total_timesteps | 434000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -485     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 86900    |\n",
      "|    time_elapsed       | 39930    |\n",
      "|    total_timesteps    | 434500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.83    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86899    |\n",
      "|    policy_loss        | -0.119   |\n",
      "|    value_loss         | 0.099    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -488     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 87000    |\n",
      "|    time_elapsed       | 39949    |\n",
      "|    total_timesteps    | 435000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.759   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86999    |\n",
      "|    policy_loss        | 0.084    |\n",
      "|    value_loss         | 0.0955   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -488     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 87100    |\n",
      "|    time_elapsed       | 39964    |\n",
      "|    total_timesteps    | 435500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.58    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 87099    |\n",
      "|    policy_loss        | -14.6    |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "<DisconnectMessageData>\n",
      "    <name>player_1</name>\n",
      "    <errortypeCode>TIMEOUT</errortypeCode>\n",
      "</DisconnectMessageData>\n",
      "\n",
      "Eval num_timesteps=436000, episode_reward=-468.80 +/- 236.31\n",
      "Episode length: 921.80 +/- 156.40\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 922      |\n",
      "|    mean_reward        | -469     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 436000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.65    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 87199    |\n",
      "|    policy_loss        | 0.008    |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -487     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 87200    |\n",
      "|    time_elapsed    | 40115    |\n",
      "|    total_timesteps | 436000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -487     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 87300    |\n",
      "|    time_elapsed       | 40125    |\n",
      "|    total_timesteps    | 436500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.24    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 87299    |\n",
      "|    policy_loss        | 0.00242  |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -488     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 87400    |\n",
      "|    time_elapsed       | 40147    |\n",
      "|    total_timesteps    | 437000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 87399    |\n",
      "|    policy_loss        | -0.206   |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -488     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 87500    |\n",
      "|    time_elapsed       | 40156    |\n",
      "|    total_timesteps    | 437500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.761   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 87499    |\n",
      "|    policy_loss        | -0.253   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=438000, episode_reward=-498.40 +/- 392.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -498     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 438000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 87599    |\n",
      "|    policy_loss        | 0.0452   |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -485     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 87600    |\n",
      "|    time_elapsed    | 40305    |\n",
      "|    total_timesteps | 438000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -485     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 87700    |\n",
      "|    time_elapsed       | 40316    |\n",
      "|    total_timesteps    | 438500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 87699    |\n",
      "|    policy_loss        | 0.0391   |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -486     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 87800    |\n",
      "|    time_elapsed       | 40337    |\n",
      "|    total_timesteps    | 439000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.17    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 87799    |\n",
      "|    policy_loss        | -3.53    |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -486     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 87900    |\n",
      "|    time_elapsed       | 40347    |\n",
      "|    total_timesteps    | 439500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 87899    |\n",
      "|    policy_loss        | 0.129    |\n",
      "|    value_loss         | 0.0896   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=-1008.00 +/- 381.21\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -1.01e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 440000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 87999     |\n",
      "|    policy_loss        | -0.0649   |\n",
      "|    value_loss         | 0.0961    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -489     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 88000    |\n",
      "|    time_elapsed    | 40492    |\n",
      "|    total_timesteps | 440000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -489     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 88100    |\n",
      "|    time_elapsed       | 40505    |\n",
      "|    total_timesteps    | 440500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 88099    |\n",
      "|    policy_loss        | 0.124    |\n",
      "|    value_loss         | 0.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -490     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 88200    |\n",
      "|    time_elapsed       | 40522    |\n",
      "|    total_timesteps    | 441000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 88199    |\n",
      "|    policy_loss        | -8.79    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -490     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 88300    |\n",
      "|    time_elapsed       | 40533    |\n",
      "|    total_timesteps    | 441500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 88299    |\n",
      "|    policy_loss        | -16.9    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=442000, episode_reward=-689.60 +/- 477.30\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -690     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 442000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.41    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 88399    |\n",
      "|    policy_loss        | 0.367    |\n",
      "|    value_loss         | 0.112    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -493     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 88400    |\n",
      "|    time_elapsed    | 40688    |\n",
      "|    total_timesteps | 442000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -493     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 88500    |\n",
      "|    time_elapsed       | 40699    |\n",
      "|    total_timesteps    | 442500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.97    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 88499    |\n",
      "|    policy_loss        | 0.00477  |\n",
      "|    value_loss         | 0.0982   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -490     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 88600    |\n",
      "|    time_elapsed       | 40722    |\n",
      "|    total_timesteps    | 443000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 88599    |\n",
      "|    policy_loss        | 0.000569 |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -490     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 88700    |\n",
      "|    time_elapsed       | 40732    |\n",
      "|    total_timesteps    | 443500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.11    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 88699    |\n",
      "|    policy_loss        | 0.0373   |\n",
      "|    value_loss         | 0.0943   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=444000, episode_reward=-447.20 +/- 191.62\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -447     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 444000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.18    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 88799    |\n",
      "|    policy_loss        | 0.0576   |\n",
      "|    value_loss         | 0.0948   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -493     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 88800    |\n",
      "|    time_elapsed    | 40910    |\n",
      "|    total_timesteps | 444000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -493     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 88900    |\n",
      "|    time_elapsed       | 40921    |\n",
      "|    total_timesteps    | 444500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.888   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 88899    |\n",
      "|    policy_loss        | 0.00955  |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -493     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 89000    |\n",
      "|    time_elapsed       | 40938    |\n",
      "|    total_timesteps    | 445000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.16    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 88999    |\n",
      "|    policy_loss        | 0.0671   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -493     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 89100    |\n",
      "|    time_elapsed       | 40950    |\n",
      "|    total_timesteps    | 445500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.18    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 89099    |\n",
      "|    policy_loss        | -0.237   |\n",
      "|    value_loss         | 0.0971   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=446000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -300      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 446000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.59     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 89199     |\n",
      "|    policy_loss        | -16.7     |\n",
      "|    value_loss         | 12.6      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -497     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 89200    |\n",
      "|    time_elapsed    | 41103    |\n",
      "|    total_timesteps | 446000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -497     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 89300    |\n",
      "|    time_elapsed       | 41112    |\n",
      "|    total_timesteps    | 446500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.383   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 89299    |\n",
      "|    policy_loss        | -0.37    |\n",
      "|    value_loss         | 0.115    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -502     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 89400    |\n",
      "|    time_elapsed       | 41129    |\n",
      "|    total_timesteps    | 447000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 89399    |\n",
      "|    policy_loss        | -4.65    |\n",
      "|    value_loss         | 11.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -502     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 89500    |\n",
      "|    time_elapsed       | 41139    |\n",
      "|    total_timesteps    | 447500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.74    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 89499    |\n",
      "|    policy_loss        | -13.4    |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=448000, episode_reward=-1248.80 +/- 43.48\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -1.25e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 448000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.59     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 89599     |\n",
      "|    policy_loss        | 0.59      |\n",
      "|    value_loss         | 0.192     |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -506     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 89600    |\n",
      "|    time_elapsed    | 41284    |\n",
      "|    total_timesteps | 448000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -506      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 89700     |\n",
      "|    time_elapsed       | 41293     |\n",
      "|    total_timesteps    | 448500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.244    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 89699     |\n",
      "|    policy_loss        | 0.00707   |\n",
      "|    value_loss         | 0.148     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -502     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 89800    |\n",
      "|    time_elapsed       | 41309    |\n",
      "|    total_timesteps    | 449000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.297   |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 89799    |\n",
      "|    policy_loss        | 0.00609  |\n",
      "|    value_loss         | 0.118    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -502     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 89900    |\n",
      "|    time_elapsed       | 41319    |\n",
      "|    total_timesteps    | 449500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 89899    |\n",
      "|    policy_loss        | -6.16    |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=-717.60 +/- 463.05\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -718     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 450000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.588   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 89999    |\n",
      "|    policy_loss        | -0.163   |\n",
      "|    value_loss         | 0.0917   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -501     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 90000    |\n",
      "|    time_elapsed    | 41462    |\n",
      "|    total_timesteps | 450000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -501     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 90100    |\n",
      "|    time_elapsed       | 41475    |\n",
      "|    total_timesteps    | 450500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.39    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 90099    |\n",
      "|    policy_loss        | 0.556    |\n",
      "|    value_loss         | 0.0947   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -504     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 90200    |\n",
      "|    time_elapsed       | 41495    |\n",
      "|    total_timesteps    | 451000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.62    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 90199    |\n",
      "|    policy_loss        | -13.5    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -504     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 90300    |\n",
      "|    time_elapsed       | 41505    |\n",
      "|    total_timesteps    | 451500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.53    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 90299    |\n",
      "|    policy_loss        | -17.4    |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=452000, episode_reward=-500.80 +/- 397.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -501      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 452000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.44     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90399     |\n",
      "|    policy_loss        | 0.304     |\n",
      "|    value_loss         | 0.101     |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -505     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 90400    |\n",
      "|    time_elapsed    | 41651    |\n",
      "|    total_timesteps | 452000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -505     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 90500    |\n",
      "|    time_elapsed       | 41661    |\n",
      "|    total_timesteps    | 452500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.55    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 90499    |\n",
      "|    policy_loss        | -0.578   |\n",
      "|    value_loss         | 0.0916   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -507      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 90600     |\n",
      "|    time_elapsed       | 41678     |\n",
      "|    total_timesteps    | 453000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.88     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90599     |\n",
      "|    policy_loss        | -7.75     |\n",
      "|    value_loss         | 12.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -507     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 90700    |\n",
      "|    time_elapsed       | 41689    |\n",
      "|    total_timesteps    | 453500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 90699    |\n",
      "|    policy_loss        | -4.42    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=454000, episode_reward=-500.00 +/- 396.01\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -500      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 454000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.24     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90799     |\n",
      "|    policy_loss        | 0.0542    |\n",
      "|    value_loss         | 0.141     |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -514     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 90800    |\n",
      "|    time_elapsed    | 41844    |\n",
      "|    total_timesteps | 454000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -514      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 90900     |\n",
      "|    time_elapsed       | 41856     |\n",
      "|    total_timesteps    | 454500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.28     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90899     |\n",
      "|    policy_loss        | 0.0952    |\n",
      "|    value_loss         | 0.133     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -513      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 91000     |\n",
      "|    time_elapsed       | 41875     |\n",
      "|    total_timesteps    | 455000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.952    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90999     |\n",
      "|    policy_loss        | 0.468     |\n",
      "|    value_loss         | 0.109     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 91100    |\n",
      "|    time_elapsed       | 41888    |\n",
      "|    total_timesteps    | 455500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.731   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 91099    |\n",
      "|    policy_loss        | -1.95    |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=456000, episode_reward=-524.00 +/- 387.19\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -524     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 456000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 91199    |\n",
      "|    policy_loss        | -6.69    |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -513     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 91200    |\n",
      "|    time_elapsed    | 42034    |\n",
      "|    total_timesteps | 456000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 91300    |\n",
      "|    time_elapsed       | 42044    |\n",
      "|    total_timesteps    | 456500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.05    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 91299    |\n",
      "|    policy_loss        | -15.1    |\n",
      "|    value_loss         | 11.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -518     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 91400    |\n",
      "|    time_elapsed       | 42065    |\n",
      "|    total_timesteps    | 457000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.6     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 91399    |\n",
      "|    policy_loss        | 0.168    |\n",
      "|    value_loss         | 0.141    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -518     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 91500    |\n",
      "|    time_elapsed       | 42073    |\n",
      "|    total_timesteps    | 457500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.135   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 91499    |\n",
      "|    policy_loss        | 0.00197  |\n",
      "|    value_loss         | 0.111    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=458000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 458000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 91599    |\n",
      "|    policy_loss        | 0.038    |\n",
      "|    value_loss         | 0.095    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -513     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 91600    |\n",
      "|    time_elapsed    | 42229    |\n",
      "|    total_timesteps | 458000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 91700    |\n",
      "|    time_elapsed       | 42240    |\n",
      "|    total_timesteps    | 458500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.758   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 91699    |\n",
      "|    policy_loss        | -0.267   |\n",
      "|    value_loss         | 0.091    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -516     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 91800    |\n",
      "|    time_elapsed       | 42258    |\n",
      "|    total_timesteps    | 459000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.63    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 91799    |\n",
      "|    policy_loss        | 0.116    |\n",
      "|    value_loss         | 0.0937   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -516     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 91900    |\n",
      "|    time_elapsed       | 42271    |\n",
      "|    total_timesteps    | 459500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 91899    |\n",
      "|    policy_loss        | -5.07    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=-691.20 +/- 477.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -691     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 460000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.228   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 91999    |\n",
      "|    policy_loss        | 0.00171  |\n",
      "|    value_loss         | 0.0966   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -519     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 92000    |\n",
      "|    time_elapsed    | 42415    |\n",
      "|    total_timesteps | 460000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -519     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 92100    |\n",
      "|    time_elapsed       | 42427    |\n",
      "|    total_timesteps    | 460500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.86    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 92099    |\n",
      "|    policy_loss        | -0.288   |\n",
      "|    value_loss         | 0.0925   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -515     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 92200    |\n",
      "|    time_elapsed       | 42444    |\n",
      "|    total_timesteps    | 461000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.09    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 92199    |\n",
      "|    policy_loss        | 4.86e-05 |\n",
      "|    value_loss         | 0.09     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -515      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 92300     |\n",
      "|    time_elapsed       | 42453     |\n",
      "|    total_timesteps    | 461500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.1      |\n",
      "|    explained_variance | 1.61e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92299     |\n",
      "|    policy_loss        | -0.000245 |\n",
      "|    value_loss         | 0.0883    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=462000, episode_reward=-496.00 +/- 392.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -496      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 462000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.113    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92399     |\n",
      "|    policy_loss        | -0.000626 |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -513     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 92400    |\n",
      "|    time_elapsed    | 42595    |\n",
      "|    total_timesteps | 462000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -513      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 92500     |\n",
      "|    time_elapsed       | 42607     |\n",
      "|    total_timesteps    | 462500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.112    |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92499     |\n",
      "|    policy_loss        | -0.000719 |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -511     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 92600    |\n",
      "|    time_elapsed       | 42624    |\n",
      "|    total_timesteps    | 463000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.77    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 92599    |\n",
      "|    policy_loss        | -0.154   |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -511     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 92700    |\n",
      "|    time_elapsed       | 42634    |\n",
      "|    total_timesteps    | 463500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.514   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 92699    |\n",
      "|    policy_loss        | -0.00247 |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=464000, episode_reward=-305.60 +/- 5.99\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -306     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 464000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.18    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 92799    |\n",
      "|    policy_loss        | -20.5    |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -512     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 92800    |\n",
      "|    time_elapsed    | 42778    |\n",
      "|    total_timesteps | 464000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -512      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 92900     |\n",
      "|    time_elapsed       | 42788     |\n",
      "|    total_timesteps    | 464500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.209    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92899     |\n",
      "|    policy_loss        | -0.000242 |\n",
      "|    value_loss         | 0.089     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -508      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 93000     |\n",
      "|    time_elapsed       | 42804     |\n",
      "|    total_timesteps    | 465000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.127    |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92999     |\n",
      "|    policy_loss        | -0.000605 |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 93100    |\n",
      "|    time_elapsed       | 42816    |\n",
      "|    total_timesteps    | 465500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.545   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 93099    |\n",
      "|    policy_loss        | -0.354   |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=466000, episode_reward=-495.20 +/- 390.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -495      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 466000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.64     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 93199     |\n",
      "|    policy_loss        | 1.19      |\n",
      "|    value_loss         | 0.154     |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -513     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 93200    |\n",
      "|    time_elapsed    | 42962    |\n",
      "|    total_timesteps | 466000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 93300    |\n",
      "|    time_elapsed       | 42974    |\n",
      "|    total_timesteps    | 466500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.519   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 93299    |\n",
      "|    policy_loss        | 0.441    |\n",
      "|    value_loss         | 0.139    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -511      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 93400     |\n",
      "|    time_elapsed       | 42992     |\n",
      "|    total_timesteps    | 467000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.07     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 93399     |\n",
      "|    policy_loss        | 0.721     |\n",
      "|    value_loss         | 0.117     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -511     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 93500    |\n",
      "|    time_elapsed       | 43004    |\n",
      "|    total_timesteps    | 467500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.4     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 93499    |\n",
      "|    policy_loss        | -0.0157  |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=468000, episode_reward=-324.00 +/- 48.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -324     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 468000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3       |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 93599    |\n",
      "|    policy_loss        | -16.4    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -513     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 93600    |\n",
      "|    time_elapsed    | 43157    |\n",
      "|    total_timesteps | 468000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 93700    |\n",
      "|    time_elapsed       | 43167    |\n",
      "|    total_timesteps    | 468500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.583   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 93699    |\n",
      "|    policy_loss        | 0.283    |\n",
      "|    value_loss         | 0.0931   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 93800    |\n",
      "|    time_elapsed       | 43187    |\n",
      "|    total_timesteps    | 469000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.79    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 93799    |\n",
      "|    policy_loss        | -0.299   |\n",
      "|    value_loss         | 0.0919   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 93900    |\n",
      "|    time_elapsed       | 43198    |\n",
      "|    total_timesteps    | 469500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 93899    |\n",
      "|    policy_loss        | 0.0019   |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 470000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.592   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 93999    |\n",
      "|    policy_loss        | 0.00336  |\n",
      "|    value_loss         | 0.0929   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -515     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 94000    |\n",
      "|    time_elapsed    | 43360    |\n",
      "|    total_timesteps | 470000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -515      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 94100     |\n",
      "|    time_elapsed       | 43371     |\n",
      "|    total_timesteps    | 470500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.494    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 94099     |\n",
      "|    policy_loss        | -0.000116 |\n",
      "|    value_loss         | 0.0889    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 94200    |\n",
      "|    time_elapsed       | 43389    |\n",
      "|    total_timesteps    | 471000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.535   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 94199    |\n",
      "|    policy_loss        | -0.00544 |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 94300    |\n",
      "|    time_elapsed       | 43401    |\n",
      "|    total_timesteps    | 471500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.18    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 94299    |\n",
      "|    policy_loss        | -0.459   |\n",
      "|    value_loss         | 0.0918   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=472000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 472000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.6     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 94399    |\n",
      "|    policy_loss        | -17.1    |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -518     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 94400    |\n",
      "|    time_elapsed    | 43549    |\n",
      "|    total_timesteps | 472000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -518     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 94500    |\n",
      "|    time_elapsed       | 43559    |\n",
      "|    total_timesteps    | 472500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.185   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 94499    |\n",
      "|    policy_loss        | 0.00214  |\n",
      "|    value_loss         | 0.0981   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -516      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 94600     |\n",
      "|    time_elapsed       | 43575     |\n",
      "|    total_timesteps    | 473000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.11     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 94599     |\n",
      "|    policy_loss        | -9.17e-05 |\n",
      "|    value_loss         | 0.0898    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -516     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 94700    |\n",
      "|    time_elapsed       | 43584    |\n",
      "|    total_timesteps    | 473500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.394   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 94699    |\n",
      "|    policy_loss        | -0.00253 |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=474000, episode_reward=-522.40 +/- 387.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -522     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 474000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 94799    |\n",
      "|    policy_loss        | -0.142   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -514     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 94800    |\n",
      "|    time_elapsed    | 43741    |\n",
      "|    total_timesteps | 474000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -514     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 94900    |\n",
      "|    time_elapsed       | 43757    |\n",
      "|    total_timesteps    | 474500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 94899    |\n",
      "|    policy_loss        | -0.127   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -514     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 95000    |\n",
      "|    time_elapsed       | 43774    |\n",
      "|    total_timesteps    | 475000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.62    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 94999    |\n",
      "|    policy_loss        | -12.2    |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -514      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 95100     |\n",
      "|    time_elapsed       | 43783     |\n",
      "|    total_timesteps    | 475500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.32     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 95099     |\n",
      "|    policy_loss        | -0.00101  |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=476000, episode_reward=-696.80 +/- 484.35\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -697     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 476000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.63    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 95199    |\n",
      "|    policy_loss        | -13.3    |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -516     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 95200    |\n",
      "|    time_elapsed    | 43925    |\n",
      "|    total_timesteps | 476000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -516     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 95300    |\n",
      "|    time_elapsed       | 43936    |\n",
      "|    total_timesteps    | 476500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 95299    |\n",
      "|    policy_loss        | -4.31    |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -515     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 95400    |\n",
      "|    time_elapsed       | 43960    |\n",
      "|    total_timesteps    | 477000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 95399    |\n",
      "|    policy_loss        | 0.0955   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -515     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 95500    |\n",
      "|    time_elapsed       | 43969    |\n",
      "|    total_timesteps    | 477500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.29    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 95499    |\n",
      "|    policy_loss        | -0.382   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=478000, episode_reward=-304.00 +/- 8.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -304      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 478000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.31     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 95599     |\n",
      "|    policy_loss        | 0.338     |\n",
      "|    value_loss         | 0.0893    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -513     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 95600    |\n",
      "|    time_elapsed    | 44116    |\n",
      "|    total_timesteps | 478000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 95700    |\n",
      "|    time_elapsed       | 44127    |\n",
      "|    total_timesteps    | 478500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.819   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 95699    |\n",
      "|    policy_loss        | -0.0864  |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -511     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 95800    |\n",
      "|    time_elapsed       | 44146    |\n",
      "|    total_timesteps    | 479000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.748   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 95799    |\n",
      "|    policy_loss        | -0.00452 |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -511      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 95900     |\n",
      "|    time_elapsed       | 44157     |\n",
      "|    total_timesteps    | 479500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.84     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 95899     |\n",
      "|    policy_loss        | 19        |\n",
      "|    value_loss         | 740       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=-301.60 +/- 3.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -302     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 480000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.65    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 95999    |\n",
      "|    policy_loss        | -0.101   |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -510     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 96000    |\n",
      "|    time_elapsed    | 44303    |\n",
      "|    total_timesteps | 480000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -510      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 96100     |\n",
      "|    time_elapsed       | 44313     |\n",
      "|    total_timesteps    | 480500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.1      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96099     |\n",
      "|    policy_loss        | -0.0648   |\n",
      "|    value_loss         | 0.089     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -510     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 96200    |\n",
      "|    time_elapsed       | 44329    |\n",
      "|    total_timesteps    | 481000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.97    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 96199    |\n",
      "|    policy_loss        | -0.574   |\n",
      "|    value_loss         | 0.0897   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -510      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 96300     |\n",
      "|    time_elapsed       | 44339     |\n",
      "|    total_timesteps    | 481500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.94     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96299     |\n",
      "|    policy_loss        | -0.0674   |\n",
      "|    value_loss         | 0.0899    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=482000, episode_reward=-497.60 +/- 395.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -498     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 482000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.73    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 96399    |\n",
      "|    policy_loss        | -0.0442  |\n",
      "|    value_loss         | 0.0904   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -509     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 96400    |\n",
      "|    time_elapsed    | 44482    |\n",
      "|    total_timesteps | 482000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 96500    |\n",
      "|    time_elapsed       | 44491    |\n",
      "|    total_timesteps    | 482500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.98    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 96499    |\n",
      "|    policy_loss        | -0.154   |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 96600    |\n",
      "|    time_elapsed       | 44508    |\n",
      "|    total_timesteps    | 483000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.96    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 96599    |\n",
      "|    policy_loss        | -0.0695  |\n",
      "|    value_loss         | 0.0903   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 96700    |\n",
      "|    time_elapsed       | 44518    |\n",
      "|    total_timesteps    | 483500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 96699    |\n",
      "|    policy_loss        | 0.0353   |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=484000, episode_reward=-494.40 +/- 386.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -494     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 484000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.81    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 96799    |\n",
      "|    policy_loss        | 0.0123   |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -509     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 96800    |\n",
      "|    time_elapsed    | 44660    |\n",
      "|    total_timesteps | 484000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -509      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 96900     |\n",
      "|    time_elapsed       | 44670     |\n",
      "|    total_timesteps    | 484500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.521    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96899     |\n",
      "|    policy_loss        | 0.183     |\n",
      "|    value_loss         | 0.0887    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 97000    |\n",
      "|    time_elapsed       | 44688    |\n",
      "|    total_timesteps    | 485000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.396   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 96999    |\n",
      "|    policy_loss        | -0.00595 |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 97100    |\n",
      "|    time_elapsed       | 44697    |\n",
      "|    total_timesteps    | 485500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 97099    |\n",
      "|    policy_loss        | -0.281   |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=486000, episode_reward=-499.20 +/- 386.47\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -499     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 486000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.16    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 97199    |\n",
      "|    policy_loss        | 0.106    |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -508     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 97200    |\n",
      "|    time_elapsed    | 44841    |\n",
      "|    total_timesteps | 486000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -508      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 97300     |\n",
      "|    time_elapsed       | 44851     |\n",
      "|    total_timesteps    | 486500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.74     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 97299     |\n",
      "|    policy_loss        | 0.131     |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 97400    |\n",
      "|    time_elapsed       | 44868    |\n",
      "|    total_timesteps    | 487000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.83    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 97399    |\n",
      "|    policy_loss        | -0.133   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -508      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 97500     |\n",
      "|    time_elapsed       | 44878     |\n",
      "|    total_timesteps    | 487500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.925    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 97499     |\n",
      "|    policy_loss        | -0.0142   |\n",
      "|    value_loss         | 0.0883    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=488000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 488000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 97599    |\n",
      "|    policy_loss        | 0.0371   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -508     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 97600    |\n",
      "|    time_elapsed    | 45020    |\n",
      "|    total_timesteps | 488000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 97700    |\n",
      "|    time_elapsed       | 45032    |\n",
      "|    total_timesteps    | 488500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.667   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 97699    |\n",
      "|    policy_loss        | -0.0038  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -507     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 97800    |\n",
      "|    time_elapsed       | 45050    |\n",
      "|    total_timesteps    | 489000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.863   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 97799    |\n",
      "|    policy_loss        | -0.0149  |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -507     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 97900    |\n",
      "|    time_elapsed       | 45061    |\n",
      "|    total_timesteps    | 489500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.34    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 97899    |\n",
      "|    policy_loss        | -0.0645  |\n",
      "|    value_loss         | 0.089    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -300      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 490000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.28     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 97999     |\n",
      "|    policy_loss        | -0.22     |\n",
      "|    value_loss         | 0.0898    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -507     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 98000    |\n",
      "|    time_elapsed    | 45203    |\n",
      "|    total_timesteps | 490000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -507      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 98100     |\n",
      "|    time_elapsed       | 45213     |\n",
      "|    total_timesteps    | 490500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.27     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 98099     |\n",
      "|    policy_loss        | 0.0131    |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -504     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 98200    |\n",
      "|    time_elapsed       | 45230    |\n",
      "|    total_timesteps    | 491000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.23    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 98199    |\n",
      "|    policy_loss        | -0.251   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -504     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 98300    |\n",
      "|    time_elapsed       | 45240    |\n",
      "|    total_timesteps    | 491500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.868   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 98299    |\n",
      "|    policy_loss        | -0.00455 |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=492000, episode_reward=-302.40 +/- 3.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -302     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 492000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.438   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 98399    |\n",
      "|    policy_loss        | -0.00466 |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -504     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 98400    |\n",
      "|    time_elapsed    | 45383    |\n",
      "|    total_timesteps | 492000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -504     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 98500    |\n",
      "|    time_elapsed       | 45394    |\n",
      "|    total_timesteps    | 492500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 98499    |\n",
      "|    policy_loss        | -6.39    |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -511     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 98600    |\n",
      "|    time_elapsed       | 45410    |\n",
      "|    total_timesteps    | 493000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 98599    |\n",
      "|    policy_loss        | -6.98    |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -511     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 98700    |\n",
      "|    time_elapsed       | 45419    |\n",
      "|    total_timesteps    | 493500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 98699    |\n",
      "|    policy_loss        | 0.201    |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=494000, episode_reward=-488.80 +/- 375.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -489     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 494000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.87    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 98799    |\n",
      "|    policy_loss        | 0.0307   |\n",
      "|    value_loss         | 0.091    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -508     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 98800    |\n",
      "|    time_elapsed    | 45562    |\n",
      "|    total_timesteps | 494000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 98900    |\n",
      "|    time_elapsed       | 45572    |\n",
      "|    total_timesteps    | 494500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 98899    |\n",
      "|    policy_loss        | -0.541   |\n",
      "|    value_loss         | 0.0915   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 99000    |\n",
      "|    time_elapsed       | 45591    |\n",
      "|    total_timesteps    | 495000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.16    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 98999    |\n",
      "|    policy_loss        | 0.0152   |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 99100    |\n",
      "|    time_elapsed       | 45602    |\n",
      "|    total_timesteps    | 495500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.651   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99099    |\n",
      "|    policy_loss        | 0.218    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=496000, episode_reward=-301.60 +/- 3.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -302     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 496000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.755   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99199    |\n",
      "|    policy_loss        | -0.00943 |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -509     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 99200    |\n",
      "|    time_elapsed    | 45750    |\n",
      "|    total_timesteps | 496000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -509      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 99300     |\n",
      "|    time_elapsed       | 45761     |\n",
      "|    total_timesteps    | 496500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.66     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99299     |\n",
      "|    policy_loss        | -0.0201   |\n",
      "|    value_loss         | 0.0889    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 99400    |\n",
      "|    time_elapsed       | 45777    |\n",
      "|    total_timesteps    | 497000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.781   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99399    |\n",
      "|    policy_loss        | 0.1      |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 99500    |\n",
      "|    time_elapsed       | 45786    |\n",
      "|    total_timesteps    | 497500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.652   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99499    |\n",
      "|    policy_loss        | -4.67    |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=498000, episode_reward=-350.40 +/- 60.11\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -350     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 498000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.707   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99599    |\n",
      "|    policy_loss        | 0.0341   |\n",
      "|    value_loss         | 0.14     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -515     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 99600    |\n",
      "|    time_elapsed    | 45932    |\n",
      "|    total_timesteps | 498000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -515     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 99700    |\n",
      "|    time_elapsed       | 45943    |\n",
      "|    total_timesteps    | 498500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.36    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99699    |\n",
      "|    policy_loss        | 0.00735  |\n",
      "|    value_loss         | 0.113    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -514     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 99800    |\n",
      "|    time_elapsed       | 45960    |\n",
      "|    total_timesteps    | 499000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.297   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99799    |\n",
      "|    policy_loss        | 0.00248  |\n",
      "|    value_loss         | 0.0962   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -514      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 99900     |\n",
      "|    time_elapsed       | 45969     |\n",
      "|    total_timesteps    | 499500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.247    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99899     |\n",
      "|    policy_loss        | 0.000307  |\n",
      "|    value_loss         | 0.0904    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=-295.40 +/- 13.32\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -295      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 500000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.176    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99999     |\n",
      "|    policy_loss        | -0.000602 |\n",
      "|    value_loss         | 0.0883    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -515     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 100000   |\n",
      "|    time_elapsed    | 46117    |\n",
      "|    total_timesteps | 500000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -515     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 100100   |\n",
      "|    time_elapsed       | 46126    |\n",
      "|    total_timesteps    | 500500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.216   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 100099   |\n",
      "|    policy_loss        | -0.00149 |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -515     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 100200   |\n",
      "|    time_elapsed       | 46143    |\n",
      "|    total_timesteps    | 501000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.192   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 100199   |\n",
      "|    policy_loss        | -0.00169 |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -515      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 100300    |\n",
      "|    time_elapsed       | 46152     |\n",
      "|    total_timesteps    | 501500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.305    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 100299    |\n",
      "|    policy_loss        | 0.166     |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=502000, episode_reward=-523.20 +/- 387.39\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -523     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 502000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.318   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 100399   |\n",
      "|    policy_loss        | -0.00316 |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -511     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 100400   |\n",
      "|    time_elapsed    | 46299    |\n",
      "|    total_timesteps | 502000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -511      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 100500    |\n",
      "|    time_elapsed       | 46309     |\n",
      "|    total_timesteps    | 502500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.209    |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 100499    |\n",
      "|    policy_loss        | -0.000885 |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -509      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 100600    |\n",
      "|    time_elapsed       | 46325     |\n",
      "|    total_timesteps    | 503000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.138    |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 100599    |\n",
      "|    policy_loss        | -0.000829 |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -509     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 100700   |\n",
      "|    time_elapsed       | 46334    |\n",
      "|    total_timesteps    | 503500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.139   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 100699   |\n",
      "|    policy_loss        | 0.000133 |\n",
      "|    value_loss         | 0.0903   |\n",
      "------------------------------------\n",
      "<DisconnectMessageData>\n",
      "    <name>player_1</name>\n",
      "    <errortypeCode>TIMEOUT</errortypeCode>\n",
      "</DisconnectMessageData>\n",
      "\n",
      "Eval num_timesteps=504000, episode_reward=-359.60 +/- 93.04\n",
      "Episode length: 965.00 +/- 70.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 965      |\n",
      "|    mean_reward        | -360     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 504000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.779   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 100799   |\n",
      "|    policy_loss        | -1.71    |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -513     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 100800   |\n",
      "|    time_elapsed    | 46502    |\n",
      "|    total_timesteps | 504000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 100900   |\n",
      "|    time_elapsed       | 46512    |\n",
      "|    total_timesteps    | 504500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.139   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 100899   |\n",
      "|    policy_loss        | 8.94e-05 |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 101000   |\n",
      "|    time_elapsed       | 46530    |\n",
      "|    total_timesteps    | 505000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.812   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 100999   |\n",
      "|    policy_loss        | -2.47    |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -513      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 101100    |\n",
      "|    time_elapsed       | 46540     |\n",
      "|    total_timesteps    | 505500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.121    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 101099    |\n",
      "|    policy_loss        | -0.000714 |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=506000, episode_reward=-688.00 +/- 465.62\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -688      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 506000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.195    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 101199    |\n",
      "|    policy_loss        | -0.00134  |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -513     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 101200   |\n",
      "|    time_elapsed    | 46684    |\n",
      "|    total_timesteps | 506000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 101300   |\n",
      "|    time_elapsed       | 46694    |\n",
      "|    total_timesteps    | 506500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.195   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 101299   |\n",
      "|    policy_loss        | -0.00141 |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 101400   |\n",
      "|    time_elapsed       | 46710    |\n",
      "|    total_timesteps    | 507000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.179   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 101399   |\n",
      "|    policy_loss        | -0.00143 |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -513     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 101500   |\n",
      "|    time_elapsed       | 46722    |\n",
      "|    total_timesteps    | 507500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.789   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 101499   |\n",
      "|    policy_loss        | -0.00188 |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=508000, episode_reward=-419.40 +/- 181.15\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -419     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 508000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.327   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 101599   |\n",
      "|    policy_loss        | 0.00148  |\n",
      "|    value_loss         | 0.0929   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -514     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 101600   |\n",
      "|    time_elapsed    | 46880    |\n",
      "|    total_timesteps | 508000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -514      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 101700    |\n",
      "|    time_elapsed       | 46890     |\n",
      "|    total_timesteps    | 508500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.423    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 101699    |\n",
      "|    policy_loss        | 0.0204    |\n",
      "|    value_loss         | 0.0887    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -514      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 101800    |\n",
      "|    time_elapsed       | 46907     |\n",
      "|    total_timesteps    | 509000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.327    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 101799    |\n",
      "|    policy_loss        | 0.158     |\n",
      "|    value_loss         | 0.0882    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -514     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 101900   |\n",
      "|    time_elapsed       | 46919    |\n",
      "|    total_timesteps    | 509500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.33    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 101899   |\n",
      "|    policy_loss        | 0.0156   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=-349.60 +/- 59.15\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -350      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 510000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.54     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 101999    |\n",
      "|    policy_loss        | -0.0522   |\n",
      "|    value_loss         | 0.0883    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -511     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 102000   |\n",
      "|    time_elapsed    | 47067    |\n",
      "|    total_timesteps | 510000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -511     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 102100   |\n",
      "|    time_elapsed       | 47076    |\n",
      "|    total_timesteps    | 510500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.533   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 102099   |\n",
      "|    policy_loss        | -0.124   |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -505     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 102200   |\n",
      "|    time_elapsed       | 47092    |\n",
      "|    total_timesteps    | 511000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.62    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 102199   |\n",
      "|    policy_loss        | -9.46    |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -505      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 102300    |\n",
      "|    time_elapsed       | 47102     |\n",
      "|    total_timesteps    | 511500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.997    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102299    |\n",
      "|    policy_loss        | -0.0776   |\n",
      "|    value_loss         | 0.0883    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=512000, episode_reward=-500.80 +/- 395.63\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -501     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 512000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.856   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 102399   |\n",
      "|    policy_loss        | -0.757   |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -508     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 102400   |\n",
      "|    time_elapsed    | 47257    |\n",
      "|    total_timesteps | 512000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 102500   |\n",
      "|    time_elapsed       | 47266    |\n",
      "|    total_timesteps    | 512500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.4     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 102499   |\n",
      "|    policy_loss        | -0.0273  |\n",
      "|    value_loss         | 0.0988   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -506      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 102600    |\n",
      "|    time_elapsed       | 47282     |\n",
      "|    total_timesteps    | 513000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.94     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102599    |\n",
      "|    policy_loss        | 0.00647   |\n",
      "|    value_loss         | 0.0941    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -506     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 102700   |\n",
      "|    time_elapsed       | 47295    |\n",
      "|    total_timesteps    | 513500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.9     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 102699   |\n",
      "|    policy_loss        | 0.163    |\n",
      "|    value_loss         | 0.0939   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=514000, episode_reward=-345.80 +/- 107.77\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -346     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 514000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 102799   |\n",
      "|    policy_loss        | -0.00687 |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -504     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 102800   |\n",
      "|    time_elapsed    | 47455    |\n",
      "|    total_timesteps | 514000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -504     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 102900   |\n",
      "|    time_elapsed       | 47473    |\n",
      "|    total_timesteps    | 514500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.19    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 102899   |\n",
      "|    policy_loss        | -0.0365  |\n",
      "|    value_loss         | 0.0957   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -504      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 103000    |\n",
      "|    time_elapsed       | 47494     |\n",
      "|    total_timesteps    | 515000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.71     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102999    |\n",
      "|    policy_loss        | 0.166     |\n",
      "|    value_loss         | 0.0906    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -504     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 103100   |\n",
      "|    time_elapsed       | 47503    |\n",
      "|    total_timesteps    | 515500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.26    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 103099   |\n",
      "|    policy_loss        | -7.7     |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=516000, episode_reward=-500.80 +/- 393.62\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -501     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 516000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.46    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 103199   |\n",
      "|    policy_loss        | -5.03    |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -510     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 103200   |\n",
      "|    time_elapsed    | 47653    |\n",
      "|    total_timesteps | 516000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -510     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 103300   |\n",
      "|    time_elapsed       | 47662    |\n",
      "|    total_timesteps    | 516500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.828   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 103299   |\n",
      "|    policy_loss        | 0.144    |\n",
      "|    value_loss         | 0.156    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 103400   |\n",
      "|    time_elapsed       | 47679    |\n",
      "|    total_timesteps    | 517000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 103399   |\n",
      "|    policy_loss        | 0.0457   |\n",
      "|    value_loss         | 0.125    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -508      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 103500    |\n",
      "|    time_elapsed       | 47688     |\n",
      "|    total_timesteps    | 517500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.04     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 103499    |\n",
      "|    policy_loss        | 0.00656   |\n",
      "|    value_loss         | 0.109     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=518000, episode_reward=-648.80 +/- 434.33\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -649     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 518000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 103599   |\n",
      "|    policy_loss        | -8.91    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -508     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 103600   |\n",
      "|    time_elapsed    | 47831    |\n",
      "|    total_timesteps | 518000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 103700   |\n",
      "|    time_elapsed       | 47840    |\n",
      "|    total_timesteps    | 518500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 103699   |\n",
      "|    policy_loss        | -2.11    |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -507     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 103800   |\n",
      "|    time_elapsed       | 47858    |\n",
      "|    total_timesteps    | 519000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.7     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 103799   |\n",
      "|    policy_loss        | -0.0361  |\n",
      "|    value_loss         | 0.093    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -507     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 103900   |\n",
      "|    time_elapsed       | 47869    |\n",
      "|    total_timesteps    | 519500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.55    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 103899   |\n",
      "|    policy_loss        | 0.106    |\n",
      "|    value_loss         | 0.0895   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=-302.40 +/- 4.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -302     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 520000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 103999   |\n",
      "|    policy_loss        | 0.041    |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -503     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 104000   |\n",
      "|    time_elapsed    | 48018    |\n",
      "|    total_timesteps | 520000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -503     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 104100   |\n",
      "|    time_elapsed       | 48032    |\n",
      "|    total_timesteps    | 520500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 104099   |\n",
      "|    policy_loss        | -6.6     |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -507     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 104200   |\n",
      "|    time_elapsed       | 48048    |\n",
      "|    total_timesteps    | 521000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.768   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 104199   |\n",
      "|    policy_loss        | 0.0196   |\n",
      "|    value_loss         | 0.0979   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -507     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 104300   |\n",
      "|    time_elapsed       | 48057    |\n",
      "|    total_timesteps    | 521500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.57    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 104299   |\n",
      "|    policy_loss        | -13.5    |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=522000, episode_reward=-353.60 +/- 57.94\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -354     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 522000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.51    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 104399   |\n",
      "|    policy_loss        | -7.57    |\n",
      "|    value_loss         | 11.8     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -512     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 104400   |\n",
      "|    time_elapsed    | 48200    |\n",
      "|    total_timesteps | 522000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -512     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 104500   |\n",
      "|    time_elapsed       | 48209    |\n",
      "|    total_timesteps    | 522500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 104499   |\n",
      "|    policy_loss        | 0.198    |\n",
      "|    value_loss         | 0.112    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -512     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 104600   |\n",
      "|    time_elapsed       | 48227    |\n",
      "|    total_timesteps    | 523000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.656   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 104599   |\n",
      "|    policy_loss        | 0.0157   |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -512     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 104700   |\n",
      "|    time_elapsed       | 48238    |\n",
      "|    total_timesteps    | 523500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 104699   |\n",
      "|    policy_loss        | -6.12    |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=524000, episode_reward=-522.40 +/- 378.41\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -522     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 524000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.2     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 104799   |\n",
      "|    policy_loss        | 0.55     |\n",
      "|    value_loss         | 0.141    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -511     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 104800   |\n",
      "|    time_elapsed    | 48385    |\n",
      "|    total_timesteps | 524000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -511      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 104900    |\n",
      "|    time_elapsed       | 48396     |\n",
      "|    total_timesteps    | 524500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.84     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 104899    |\n",
      "|    policy_loss        | 0.305     |\n",
      "|    value_loss         | 0.114     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 105000   |\n",
      "|    time_elapsed       | 48416    |\n",
      "|    total_timesteps    | 525000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.2     |\n",
      "|    explained_variance | 2.53e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 104999   |\n",
      "|    policy_loss        | 0.324    |\n",
      "|    value_loss         | 0.0997   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 105100   |\n",
      "|    time_elapsed       | 48426    |\n",
      "|    total_timesteps    | 525500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.865   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 105099   |\n",
      "|    policy_loss        | 0.228    |\n",
      "|    value_loss         | 0.0922   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=526000, episode_reward=-324.80 +/- 49.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -325     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 526000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.59    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 105199   |\n",
      "|    policy_loss        | 0.0355   |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -509     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 105200   |\n",
      "|    time_elapsed    | 48576    |\n",
      "|    total_timesteps | 526000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -509      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 105300    |\n",
      "|    time_elapsed       | 48587     |\n",
      "|    total_timesteps    | 526500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.87     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105299    |\n",
      "|    policy_loss        | -10.1     |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -508      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 105400    |\n",
      "|    time_elapsed       | 48606     |\n",
      "|    total_timesteps    | 527000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.19     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105399    |\n",
      "|    policy_loss        | -12.7     |\n",
      "|    value_loss         | 13.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 105500   |\n",
      "|    time_elapsed       | 48616    |\n",
      "|    total_timesteps    | 527500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 105499   |\n",
      "|    policy_loss        | -0.0598  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "<DisconnectMessageData>\n",
      "    <name>player_1</name>\n",
      "    <errortypeCode>TIMEOUT</errortypeCode>\n",
      "</DisconnectMessageData>\n",
      "\n",
      "Eval num_timesteps=528000, episode_reward=-289.00 +/- 22.00\n",
      "Episode length: 996.20 +/- 7.60\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 996      |\n",
      "|    mean_reward        | -289     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 528000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 105599   |\n",
      "|    policy_loss        | -0.38    |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -508     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 105600   |\n",
      "|    time_elapsed    | 48768    |\n",
      "|    total_timesteps | 528000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -508     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 105700   |\n",
      "|    time_elapsed       | 48778    |\n",
      "|    total_timesteps    | 528500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 105699   |\n",
      "|    policy_loss        | -0.0647  |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -505     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 105800   |\n",
      "|    time_elapsed       | 48795    |\n",
      "|    total_timesteps    | 529000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 105799   |\n",
      "|    policy_loss        | 0.0015   |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -505      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 105900    |\n",
      "|    time_elapsed       | 48806     |\n",
      "|    total_timesteps    | 529500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.54     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105899    |\n",
      "|    policy_loss        | -0.525    |\n",
      "|    value_loss         | 0.0894    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=-297.00 +/- 10.16\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -297     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 530000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 105999   |\n",
      "|    policy_loss        | -0.167   |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -502     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 106000   |\n",
      "|    time_elapsed    | 48950    |\n",
      "|    total_timesteps | 530000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -502     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 106100   |\n",
      "|    time_elapsed       | 48960    |\n",
      "|    total_timesteps    | 530500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2       |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 106099   |\n",
      "|    policy_loss        | -0.115   |\n",
      "|    value_loss         | 0.0903   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -502     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 106200   |\n",
      "|    time_elapsed       | 48976    |\n",
      "|    total_timesteps    | 531000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 106199   |\n",
      "|    policy_loss        | -0.264   |\n",
      "|    value_loss         | 0.0906   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -502     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 106300   |\n",
      "|    time_elapsed       | 48985    |\n",
      "|    total_timesteps    | 531500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.78    |\n",
      "|    explained_variance | 2.21e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 106299   |\n",
      "|    policy_loss        | -0.384   |\n",
      "|    value_loss         | 0.0907   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=532000, episode_reward=-499.20 +/- 396.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -499     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 532000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.64    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 106399   |\n",
      "|    policy_loss        | -0.136   |\n",
      "|    value_loss         | 0.0895   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -500     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 106400   |\n",
      "|    time_elapsed    | 49129    |\n",
      "|    total_timesteps | 532000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -500     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 106500   |\n",
      "|    time_elapsed       | 49138    |\n",
      "|    total_timesteps    | 532500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 106499   |\n",
      "|    policy_loss        | 0.0153   |\n",
      "|    value_loss         | 0.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -493     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 106600   |\n",
      "|    time_elapsed       | 49155    |\n",
      "|    total_timesteps    | 533000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 106599   |\n",
      "|    policy_loss        | -0.176   |\n",
      "|    value_loss         | 0.0904   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -493     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 106700   |\n",
      "|    time_elapsed       | 49165    |\n",
      "|    total_timesteps    | 533500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.44    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 106699   |\n",
      "|    policy_loss        | 0.14     |\n",
      "|    value_loss         | 0.0906   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=534000, episode_reward=-593.60 +/- 387.81\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -594      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 534000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.53     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 106799    |\n",
      "|    policy_loss        | -0.324    |\n",
      "|    value_loss         | 0.0911    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -493     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 106800   |\n",
      "|    time_elapsed    | 49315    |\n",
      "|    total_timesteps | 534000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -493     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 106900   |\n",
      "|    time_elapsed       | 49326    |\n",
      "|    total_timesteps    | 534500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.33    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 106899   |\n",
      "|    policy_loss        | -0.0552  |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -492     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 107000   |\n",
      "|    time_elapsed       | 49342    |\n",
      "|    total_timesteps    | 535000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.932   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 106999   |\n",
      "|    policy_loss        | -0.00812 |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -492     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 107100   |\n",
      "|    time_elapsed       | 49351    |\n",
      "|    total_timesteps    | 535500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.391   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 107099   |\n",
      "|    policy_loss        | -0.00446 |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "<DisconnectMessageData>\n",
      "    <name>player_1</name>\n",
      "    <errortypeCode>TIMEOUT</errortypeCode>\n",
      "</DisconnectMessageData>\n",
      "\n",
      "Eval num_timesteps=536000, episode_reward=-252.20 +/- 83.06\n",
      "Episode length: 870.60 +/- 258.80\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 871      |\n",
      "|    mean_reward        | -252     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 536000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.579   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 107199   |\n",
      "|    policy_loss        | 0.0339   |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -492     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 107200   |\n",
      "|    time_elapsed    | 49493    |\n",
      "|    total_timesteps | 536000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -492      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 107300    |\n",
      "|    time_elapsed       | 49502     |\n",
      "|    total_timesteps    | 536500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.779    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 107299    |\n",
      "|    policy_loss        | 0.129     |\n",
      "|    value_loss         | 0.089     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -491     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 107400   |\n",
      "|    time_elapsed       | 49518    |\n",
      "|    total_timesteps    | 537000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.698   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 107399   |\n",
      "|    policy_loss        | -0.0142  |\n",
      "|    value_loss         | 0.0894   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -491     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 107500   |\n",
      "|    time_elapsed       | 49527    |\n",
      "|    total_timesteps    | 537500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 107499   |\n",
      "|    policy_loss        | 0.116    |\n",
      "|    value_loss         | 0.0894   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=538000, episode_reward=-301.60 +/- 1.96\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -302      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 538000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.17     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 107599    |\n",
      "|    policy_loss        | -0.0342   |\n",
      "|    value_loss         | 0.0902    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -490     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 107600   |\n",
      "|    time_elapsed    | 49669    |\n",
      "|    total_timesteps | 538000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -490     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 107700   |\n",
      "|    time_elapsed       | 49678    |\n",
      "|    total_timesteps    | 538500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.92    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 107699   |\n",
      "|    policy_loss        | -0.115   |\n",
      "|    value_loss         | 0.0903   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -491     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 107800   |\n",
      "|    time_elapsed       | 49695    |\n",
      "|    total_timesteps    | 539000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.659   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 107799   |\n",
      "|    policy_loss        | -0.00607 |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -491     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 107900   |\n",
      "|    time_elapsed       | 49704    |\n",
      "|    total_timesteps    | 539500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.14    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 107899   |\n",
      "|    policy_loss        | -0.0163  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=-303.20 +/- 4.66\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -303     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 540000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 107999   |\n",
      "|    policy_loss        | -0.302   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -488     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 108000   |\n",
      "|    time_elapsed    | 49848    |\n",
      "|    total_timesteps | 540000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -488     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 108100   |\n",
      "|    time_elapsed       | 49859    |\n",
      "|    total_timesteps    | 540500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.891   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 108099   |\n",
      "|    policy_loss        | -0.837   |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -491     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 108200   |\n",
      "|    time_elapsed       | 49877    |\n",
      "|    total_timesteps    | 541000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 108199   |\n",
      "|    policy_loss        | -4.25    |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -491     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 108300   |\n",
      "|    time_elapsed       | 49886    |\n",
      "|    total_timesteps    | 541500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.762   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 108299   |\n",
      "|    policy_loss        | 0.191    |\n",
      "|    value_loss         | 0.0995   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=542000, episode_reward=-692.00 +/- 478.48\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -692     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 542000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.925   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 108399   |\n",
      "|    policy_loss        | 0.133    |\n",
      "|    value_loss         | 0.0907   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -487     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 108400   |\n",
      "|    time_elapsed    | 50029    |\n",
      "|    total_timesteps | 542000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -487     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 108500   |\n",
      "|    time_elapsed       | 50039    |\n",
      "|    total_timesteps    | 542500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.24    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 108499   |\n",
      "|    policy_loss        | -0.0701  |\n",
      "|    value_loss         | 0.0914   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -489     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 108600   |\n",
      "|    time_elapsed       | 50055    |\n",
      "|    total_timesteps    | 543000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 108599   |\n",
      "|    policy_loss        | 0.0277   |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -489      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 108700    |\n",
      "|    time_elapsed       | 50065     |\n",
      "|    total_timesteps    | 543500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.88     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 108699    |\n",
      "|    policy_loss        | -3.5      |\n",
      "|    value_loss         | 12.7      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=544000, episode_reward=-300.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -300     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 544000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.716   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 108799   |\n",
      "|    policy_loss        | -1.95    |\n",
      "|    value_loss         | 11.6     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -493     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 108800   |\n",
      "|    time_elapsed    | 50207    |\n",
      "|    total_timesteps | 544000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -493     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 108900   |\n",
      "|    time_elapsed       | 50216    |\n",
      "|    total_timesteps    | 544500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.501   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 108899   |\n",
      "|    policy_loss        | 0.0173   |\n",
      "|    value_loss         | 0.121    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -493     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 109000   |\n",
      "|    time_elapsed       | 50232    |\n",
      "|    total_timesteps    | 545000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.947   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 108999   |\n",
      "|    policy_loss        | 0.251    |\n",
      "|    value_loss         | 0.0999   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -493      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 109100    |\n",
      "|    time_elapsed       | 50241     |\n",
      "|    total_timesteps    | 545500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.4      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 109099    |\n",
      "|    policy_loss        | 0.0345    |\n",
      "|    value_loss         | 0.0914    |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=546000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 546000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 109199   |\n",
      "|    policy_loss        | -0.133   |\n",
      "|    value_loss         | 0.0885   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -489     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 109200   |\n",
      "|    time_elapsed    | 50383    |\n",
      "|    total_timesteps | 546000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -489      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 109300    |\n",
      "|    time_elapsed       | 50391     |\n",
      "|    total_timesteps    | 546500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.881    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 109299    |\n",
      "|    policy_loss        | 0.0519    |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -482      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 109400    |\n",
      "|    time_elapsed       | 50408     |\n",
      "|    total_timesteps    | 547000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1        |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 109399    |\n",
      "|    policy_loss        | -0.0641   |\n",
      "|    value_loss         | 0.0884    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -482     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 109500   |\n",
      "|    time_elapsed       | 50418    |\n",
      "|    total_timesteps    | 547500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.76    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 109499   |\n",
      "|    policy_loss        | -0.0419  |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=548000, episode_reward=-306.40 +/- 8.24\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -306     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 548000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 109599   |\n",
      "|    policy_loss        | -7.93    |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -480     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 109600   |\n",
      "|    time_elapsed    | 50562    |\n",
      "|    total_timesteps | 548000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -480     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 109700   |\n",
      "|    time_elapsed       | 50571    |\n",
      "|    total_timesteps    | 548500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.996   |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 109699   |\n",
      "|    policy_loss        | -0.179   |\n",
      "|    value_loss         | 0.0895   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -482     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 109800   |\n",
      "|    time_elapsed       | 50588    |\n",
      "|    total_timesteps    | 549000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 109799   |\n",
      "|    policy_loss        | -0.0744  |\n",
      "|    value_loss         | 0.0898   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -482     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 109900   |\n",
      "|    time_elapsed       | 50597    |\n",
      "|    total_timesteps    | 549500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.627   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 109899   |\n",
      "|    policy_loss        | 0.013    |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=-300.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -301     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 550000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.629   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 109999   |\n",
      "|    policy_loss        | 0.0057   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -482     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 110000   |\n",
      "|    time_elapsed    | 50739    |\n",
      "|    total_timesteps | 550000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -482     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 110100   |\n",
      "|    time_elapsed       | 50748    |\n",
      "|    total_timesteps    | 550500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.51    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 110099   |\n",
      "|    policy_loss        | -0.0784  |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -478     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 110200   |\n",
      "|    time_elapsed       | 50764    |\n",
      "|    total_timesteps    | 551000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 110199   |\n",
      "|    policy_loss        | -0.361   |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -478     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 110300   |\n",
      "|    time_elapsed       | 50775    |\n",
      "|    total_timesteps    | 551500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 110299   |\n",
      "|    policy_loss        | -4.67    |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=552000, episode_reward=-305.60 +/- 11.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -306     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 552000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 110399   |\n",
      "|    policy_loss        | 0.0751   |\n",
      "|    value_loss         | 0.0963   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -480     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 110400   |\n",
      "|    time_elapsed    | 50919    |\n",
      "|    total_timesteps | 552000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -480     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 110500   |\n",
      "|    time_elapsed       | 50927    |\n",
      "|    total_timesteps    | 552500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.832   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 110499   |\n",
      "|    policy_loss        | -0.0723  |\n",
      "|    value_loss         | 0.0899   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -478     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 110600   |\n",
      "|    time_elapsed       | 50944    |\n",
      "|    total_timesteps    | 553000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.999   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 110599   |\n",
      "|    policy_loss        | -0.249   |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -478     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 110700   |\n",
      "|    time_elapsed       | 50953    |\n",
      "|    total_timesteps    | 553500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.888   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 110699   |\n",
      "|    policy_loss        | -0.0645  |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=554000, episode_reward=-495.20 +/- 390.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -495      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 554000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.63     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 110799    |\n",
      "|    policy_loss        | -0.11     |\n",
      "|    value_loss         | 0.0885    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -473     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 110800   |\n",
      "|    time_elapsed    | 51096    |\n",
      "|    total_timesteps | 554000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -473     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 110900   |\n",
      "|    time_elapsed       | 51107    |\n",
      "|    total_timesteps    | 554500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.72    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 110899   |\n",
      "|    policy_loss        | 0.00975  |\n",
      "|    value_loss         | 0.0958   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -477      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 111000    |\n",
      "|    time_elapsed       | 51127     |\n",
      "|    total_timesteps    | 555000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.88     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 110999    |\n",
      "|    policy_loss        | -6.62     |\n",
      "|    value_loss         | 12.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -477     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 111100   |\n",
      "|    time_elapsed       | 51136    |\n",
      "|    total_timesteps    | 555500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.341   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 111099   |\n",
      "|    policy_loss        | 0.00128  |\n",
      "|    value_loss         | 0.0916   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=556000, episode_reward=-302.40 +/- 4.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -302     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 556000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.3     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 111199   |\n",
      "|    policy_loss        | -0.00116 |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -473     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 111200   |\n",
      "|    time_elapsed    | 51278    |\n",
      "|    total_timesteps | 556000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -473      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 111300    |\n",
      "|    time_elapsed       | 51287     |\n",
      "|    total_timesteps    | 556500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.377    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 111299    |\n",
      "|    policy_loss        | -0.00316  |\n",
      "|    value_loss         | 0.0881    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -469     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 111400   |\n",
      "|    time_elapsed       | 51305    |\n",
      "|    total_timesteps    | 557000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.712   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 111399   |\n",
      "|    policy_loss        | -0.091   |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -469     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 111500   |\n",
      "|    time_elapsed       | 51313    |\n",
      "|    total_timesteps    | 557500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.907   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 111499   |\n",
      "|    policy_loss        | 0.0413   |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "<DisconnectMessageData>\n",
      "    <name>player_1</name>\n",
      "    <errortypeCode>TIMEOUT</errortypeCode>\n",
      "</DisconnectMessageData>\n",
      "\n",
      "Eval num_timesteps=558000, episode_reward=-275.40 +/- 51.22\n",
      "Episode length: 938.60 +/- 122.80\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 939      |\n",
      "|    mean_reward        | -275     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 558000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.434   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 111599   |\n",
      "|    policy_loss        | -0.00469 |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -470     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 111600   |\n",
      "|    time_elapsed    | 51460    |\n",
      "|    total_timesteps | 558000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -470     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 111700   |\n",
      "|    time_elapsed       | 51469    |\n",
      "|    total_timesteps    | 558500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.47    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 111699   |\n",
      "|    policy_loss        | -12.9    |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -471      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 111800    |\n",
      "|    time_elapsed       | 51486     |\n",
      "|    total_timesteps    | 559000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.234    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 111799    |\n",
      "|    policy_loss        | -5.23e-05 |\n",
      "|    value_loss         | 0.0896    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -471     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 111900   |\n",
      "|    time_elapsed       | 51495    |\n",
      "|    total_timesteps    | 559500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.354   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 111899   |\n",
      "|    policy_loss        | -0.00223 |\n",
      "|    value_loss         | 0.0882   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=-301.60 +/- 3.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -302     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 560000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.57    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 111999   |\n",
      "|    policy_loss        | -6.83    |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -469     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 112000   |\n",
      "|    time_elapsed    | 51638    |\n",
      "|    total_timesteps | 560000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -469     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 112100   |\n",
      "|    time_elapsed       | 51647    |\n",
      "|    total_timesteps    | 560500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.608   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 112099   |\n",
      "|    policy_loss        | 0.211    |\n",
      "|    value_loss         | 0.0967   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -471     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 112200   |\n",
      "|    time_elapsed       | 51665    |\n",
      "|    total_timesteps    | 561000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.51    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 112199   |\n",
      "|    policy_loss        | -0.00139 |\n",
      "|    value_loss         | 0.0924   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -471     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 112300   |\n",
      "|    time_elapsed       | 51675    |\n",
      "|    total_timesteps    | 561500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.916   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 112299   |\n",
      "|    policy_loss        | 0.482    |\n",
      "|    value_loss         | 0.0902   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=562000, episode_reward=-304.00 +/- 6.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1e+03     |\n",
      "|    mean_reward        | -304      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 562000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.3      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 112399    |\n",
      "|    policy_loss        | -15.2     |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -473     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 112400   |\n",
      "|    time_elapsed    | 51817    |\n",
      "|    total_timesteps | 562000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -473     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 112500   |\n",
      "|    time_elapsed       | 51828    |\n",
      "|    total_timesteps    | 562500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.58    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 112499   |\n",
      "|    policy_loss        | -7.73    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -480     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 112600   |\n",
      "|    time_elapsed       | 51845    |\n",
      "|    total_timesteps    | 563000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 112599   |\n",
      "|    policy_loss        | -2.16    |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1e+03     |\n",
      "|    ep_rew_mean        | -480      |\n",
      "| time/                 |           |\n",
      "|    fps                | 10        |\n",
      "|    iterations         | 112700    |\n",
      "|    time_elapsed       | 51856     |\n",
      "|    total_timesteps    | 563500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.03     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 112699    |\n",
      "|    policy_loss        | -0.14     |\n",
      "|    value_loss         | 0.14      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=564000, episode_reward=-375.20 +/- 148.41\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -375     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 564000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.49    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 112799   |\n",
      "|    policy_loss        | 0.556    |\n",
      "|    value_loss         | 0.143    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -479     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 112800   |\n",
      "|    time_elapsed    | 52023    |\n",
      "|    total_timesteps | 564000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -479     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 112900   |\n",
      "|    time_elapsed       | 52033    |\n",
      "|    total_timesteps    | 564500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.741   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 112899   |\n",
      "|    policy_loss        | -0.119   |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -479     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 113000   |\n",
      "|    time_elapsed       | 52052    |\n",
      "|    total_timesteps    | 565000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 112999   |\n",
      "|    policy_loss        | 0.0789   |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -479     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 113100   |\n",
      "|    time_elapsed       | 52061    |\n",
      "|    total_timesteps    | 565500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.183   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 113099   |\n",
      "|    policy_loss        | 0.000458 |\n",
      "|    value_loss         | 0.0914   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=566000, episode_reward=-397.60 +/- 193.21\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -398     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 566000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.487   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 113199   |\n",
      "|    policy_loss        | 0.154    |\n",
      "|    value_loss         | 0.0884   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -471     |\n",
      "| time/              |          |\n",
      "|    fps             | 10       |\n",
      "|    iterations      | 113200   |\n",
      "|    time_elapsed    | 52211    |\n",
      "|    total_timesteps | 566000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -471     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 113300   |\n",
      "|    time_elapsed       | 52224    |\n",
      "|    total_timesteps    | 566500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.84    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 113299   |\n",
      "|    policy_loss        | 0.0737   |\n",
      "|    value_loss         | 0.0937   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -475     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 113400   |\n",
      "|    time_elapsed       | 52242    |\n",
      "|    total_timesteps    | 567000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.64    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 113399   |\n",
      "|    policy_loss        | -4.92    |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1e+03    |\n",
      "|    ep_rew_mean        | -475     |\n",
      "| time/                 |          |\n",
      "|    fps                | 10       |\n",
      "|    iterations         | 113500   |\n",
      "|    time_elapsed       | 52254    |\n",
      "|    total_timesteps    | 567500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1       |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 113499   |\n",
      "|    policy_loss        | 0.0168   |\n",
      "|    value_loss         | 0.104    |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#for step in range(int(steps/5000)):\n",
    "model.learn(total_timesteps=steps, callback=[checkpoint_callback, eval_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_path = \"Training/Saved Models/A2C_\"+str(steps)+\"_Mazenet_Model_v3\"\n",
    "model.save(a2c_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b5d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea27787",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(\"./saved_models/rl_model__49152_steps.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef7a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = menv.reset()\n",
    "done = False  \n",
    "total_reward   = 0\n",
    "while not done:\n",
    "    #print(menv.action_space.sample())\n",
    "    obs, reward, done, trunc, info =  menv.step(menv.action_space.sample())\n",
    "    total_reward  += reward\n",
    "print('Total Reward for episode {} is {}'.format(episode, total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecff7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env = MazeEnv()\n",
    "# It will check your custom environment and output additional warnings if needed\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ec36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces import Box\n",
    "b = Box(low=0, high=1, shape=(7, 7), dtype=int).sample()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b912ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((7, 7), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3ca121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
