{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e78dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AStA\\anaconda3\\envs\\gym\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\AStA\\anaconda3\\envs\\gym\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\AStA\\anaconda3\\envs\\gym\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\AStA\\anaconda3\\envs\\gym\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Boiler plate stuff to start the module\n",
    "import jpype\n",
    "import jpype.imports\n",
    "from jpype.types import *\n",
    "import sys \n",
    "import numpy as np\n",
    "import traceback\n",
    "import random\n",
    "import Client\n",
    "import copy\n",
    "import threading\n",
    "import queue\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f4292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Java modules\n",
    "from de.fhac.mazenet.server.generated import AwaitMoveMessageData\n",
    "from de.fhac.mazenet.server.generated import Errortype\n",
    "from de.fhac.mazenet.server.generated import MazeCom\n",
    "from de.fhac.mazenet.server.generated import MazeComMessagetype\n",
    "#from de.fhac.mazenet.server.generated import MoveMessageData\n",
    "from de.fhac.mazenet.server.generated import BoardData\n",
    "\n",
    "from de.fhac.mazenet.server.networking import MazeComMessageFactory\n",
    "\n",
    "from de.fhac.mazenet.server.game import Board\n",
    "#from de.fhac.mazenet.server.game import Position\n",
    "#from de.fhac.mazenet.server.game import Card\n",
    "#from mazeCom import AwaitMoveMessageData, Errortype, MazeCom, MazeComMessagetype, MoveMessageData, BoardData\n",
    "#from Boardpy import Board\n",
    "from MoveMessageDatapy import MoveMessageData\n",
    "from Positionpy import Position\n",
    "from Cardpy import Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afca3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"127.0.0.1\"\n",
    "PORT = 9888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb73702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c20ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mss import mss\n",
    "import pydirectinput\n",
    "import cv2\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca6b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_range = np.arange(1,6,2)\n",
    "potentialShiftMoves =  []\n",
    "potentialShiftMovesPos =  []\n",
    "for i in ls_range:\n",
    "    potentialShiftMoves.append((0, i))\n",
    "    potentialShiftMoves.append((6, i))\n",
    "    potentialShiftMoves.append((i, 0))\n",
    "    potentialShiftMoves.append((i, 6))\n",
    "    potentialShiftMovesPos.append(Position(row=0, col=i))\n",
    "    potentialShiftMovesPos.append(Position(row=6, col=i))\n",
    "    potentialShiftMovesPos.append(Position(row=i, col=0))\n",
    "    potentialShiftMovesPos.append(Position(row=i, col=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce59d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "from pettingzoo import AECEnv, ParallelEnv\n",
    "from pettingzoo.utils import agent_selector, parallel_to_aec, wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b421f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent_Client:\n",
    "    def __init__(self, name, client=None):\n",
    "        self.name = name\n",
    "        self.client = client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de6add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MARL_Env_Parallel(ParallelEnv):\n",
    "    metadata = {\"render_modes\": [\"human\"], \"name\": \"rps_v2\"}\n",
    "\n",
    "    def __init__(self, render_mode=None, num_players=4):\n",
    "        #self.manager = Client.Client(\"manager\", HOST, PORT, True)\n",
    "        #self.manager.login_manager()\n",
    "        \n",
    "        self.num_players = num_players\n",
    "        self.possible_agents = [Agent_Client(name=\"player_\" + str(r)) for r in range(self.num_players)]\n",
    "        self.agent_name_mapping = dict(\n",
    "            zip(self.possible_agents, list(range(len(self.possible_agents))))\n",
    "        )\n",
    "\n",
    "        # Gym spaces are defined and documented here: https://gym.openai.com/docs/#spaces\n",
    "        self._action_spaces = {agent: MultiDiscrete([12, 4, 7, 7], dtype=np.int8) for agent in self.possible_agents}\n",
    "        self._observation_spaces = {\n",
    "            agent: Tuple((Box(low=0, high=6, shape=(1,2), dtype=np.uint8),\n",
    "                           Box(low=0, high=6, shape=(1,2), dtype=np.uint8)\n",
    "                           ))  for agent in self.possible_agents\n",
    "        }\n",
    "        self.render_mode = render_mode\n",
    "        self.player_pos = {}\n",
    "        self.next_treasure_pos = {}\n",
    "        self.is_done = False\n",
    "        #self.manager = Client.Client(\"manager\", HOST, PORT, True)\n",
    "        #self.manager.login_manager()\n",
    "\n",
    "    # this cache ensures that same space object is returned for the same agent\n",
    "    # allows action space seeding to work as expected\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def observation_space(self, agent):\n",
    "        # gymnasium spaces are defined and documented here: https://gymnasium.farama.org/api/spaces/\n",
    "        return Tuple((Box(low=0, high=6, shape=(1,2), dtype=np.uint8),\n",
    "                           Box(low=0, high=6, shape=(1,2), dtype=np.uint8)\n",
    "                           ))\n",
    "    \n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def action_space(self, agent):\n",
    "        return MultiDiscrete([12, 4, 7, 7], dtype=np.int8)\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        Renders the environment. In human mode, it can print to terminal, open\n",
    "        up a graphical window, or open up some other display that a human can see and understand.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close should release any graphical displays, subprocesses, network connections\n",
    "        or any other environment data which should not be kept around after the\n",
    "        user is no longer using the environment.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def moeglicheOrientierungen(self, rot, card):\n",
    "        card_ = Card(c=card)\n",
    "        openings = card_.getOpenings()\n",
    "        print(\"card.getShape:\", type(card.getShape()))\n",
    "        if(card.getShape() == Card.CardShape.I):\n",
    "            openings.setBottom(not openings.isBottom())\n",
    "            openings.setLeft(not openings.isLeft())\n",
    "            openings.setRight(not openings.isRight())\n",
    "            openings.setTop(not openings.isTop())\n",
    "            return  Card(c=card_)\n",
    "        else:\n",
    "            if(rot == 0):\n",
    "                return Card(None, card.getShape(), Card.Orientation.D0, card.getTreasure())\n",
    "            if(rot == 1):\n",
    "                return Card(None, card.getShape(), Card.Orientation.D90, card.getTreasure())\n",
    "            if(rot == 2):\n",
    "                return Card(None, card.getShape(), Card.Orientation.D180, card.getTreasure())\n",
    "            if(rot == 3):\n",
    "                return Card(None, card.getShape(), Card.Orientation.D270, card.getTreasure())\n",
    "        return Card(None, card.getShape(), Card.Orientation.D0, card.getTreasure())\n",
    "    \n",
    "    def Move(self, awaitMove, action, agent):\n",
    "        reward = 0\n",
    "        boardData = awaitMove.getBoard()\n",
    "        treasure = awaitMove.getTreasureToFindNext()\n",
    "        board = Board(boardData)\n",
    "        playerPosition = board.findPlayer(agent.client.getId())\n",
    "        psm = potentialShiftMoves[action[0]]\n",
    "        position = Position(row=psm[0], col=psm[1])\n",
    "        \n",
    "        potentialMove = MoveMessageData()\n",
    "        psmp = copy.copy(potentialShiftMovesPos)\n",
    "        if(position == board.getForbidden()):\n",
    "            #print(\"forbidden shift position, random shift position used, reward decreased\")\n",
    "            reward -= 10\n",
    "            try:\n",
    "                psmp.remove(position)\n",
    "            except Exception:\n",
    "                print(\"element not in list, skipping\")\n",
    "            potentialMove.setShiftPosition(psmp[0])\n",
    "        else:\n",
    "            potentialMove.setShiftPosition(position)\n",
    "        \n",
    "        treasurePositionData = board.findTreasure(treasure)\n",
    "        \n",
    "        orientedShiftCard = self.moeglicheOrientierungen(action[1], board.getShiftCard())\n",
    "        \n",
    "        potentialMove.setShiftCard(orientedShiftCard)\n",
    "        potentialMove.setNewPinPos(playerPosition)\n",
    "\n",
    "        boardNext = board.fakeShift(potentialMove)\n",
    "        treasurePositionData = boardNext.findTreasure(treasure)\n",
    "        \n",
    "        new_player_pos = boardNext.findPlayer(agent.client.getId())\n",
    "        reachablePositions = boardNext.getAllReachablePositions(new_player_pos)\n",
    "        rp = np.array(reachablePositions)\n",
    "        chosen_pos_obj = Position(row=action[2], col=action[3])\n",
    "        chosen_pos_arr = np.array(action[2], action[3])\n",
    "        if(treasurePositionData == None):\n",
    "            #print(\"no treasure? skipping\")\n",
    "            potentialMove.setNewPinPos(new_player_pos)\n",
    "            self.next_treasure_pos[agent] = treasurePositionData\n",
    "            self.player_pos[agent] = new_player_pos\n",
    "            return potentialMove, reward\n",
    "\n",
    "        if(chosen_pos_obj not in rp):\n",
    "            #print(\"cannot reach position, reward decreased\")\n",
    "            potentialMove.setNewPinPos(new_player_pos)\n",
    "            self.next_treasure_pos[agent] = treasurePositionData\n",
    "            self.player_pos[agent] = new_player_pos\n",
    "            return potentialMove, reward - 10\n",
    "        else:\n",
    "            #print(\"treasure position data:\", treasurePositionData)\n",
    "            treasurePosition = Position(treasurePositionData)\n",
    "            #print(\"treasure pos:\", treasurePosition)\n",
    "\n",
    "            if(chosen_pos_obj == treasurePosition):\n",
    "                #print(\"straight to the treasure, reward increased!\")\n",
    "                potentialMove.setNewPinPos(treasurePosition)\n",
    "                self.next_treasure_pos[agent] = treasurePositionData\n",
    "                self.player_pos[agent] = treasurePosition\n",
    "                return potentialMove, reward + 20\n",
    "            else:\n",
    "                #print(\"reachable position, but no treasure\")\n",
    "                potentialMove.setNewPinPos(chosen_pos_obj)\n",
    "                self.next_treasure_pos[agent] = treasurePositionData\n",
    "                self.player_pos[agent] = chosen_pos_obj\n",
    "                return potentialMove, reward - 5\n",
    "\n",
    "        #print(\"Object not reachable: random move :/\")\n",
    "        potentialMove.setNewPinPos(reachablePositions[0])\n",
    "        self.next_treasure_pos[agent] = treasurePositionData\n",
    "        self.player_pos[agent] = reachablePositions[0]\n",
    "        return potentialMove, reward - 10\n",
    "    \n",
    "    def awaitMove(self, receivedMazeCom, action, agent):\n",
    "        awaitMove = receivedMazeCom.getAwaitMoveMessage()\n",
    "        move, reward = self.Move(awaitMove, action, agent)\n",
    "        mazeComToSend = MazeCom()\n",
    "        mazeComToSend.setId(agent.client.getId())\n",
    "        mazeComToSend.setMessagetype(MazeComMessagetype.MOVE)\n",
    "        mazeComToSend.setMoveMessage(move)\n",
    "        agent.client.out.write(mazeComToSend)\n",
    "        return reward          \n",
    "    \n",
    "    def run_agent(self, agent, action, return_val):\n",
    "        reward = 0\n",
    "        #print(f\"agents:\", agent)\n",
    "        #print(f\"actions:\", action)\n",
    "        try:\n",
    "            print(\"starrt rer\")\n",
    "            receivedMazeCom = agent.client.in_.readMazeCom()\n",
    "            print(\"end ererer\")\n",
    "            if(receivedMazeCom.getMessagetype() == MazeComMessagetype.LOGINREPLY):\n",
    "                newid = receivedMazeCom.getLoginReplyMessage().getNewID()\n",
    "                agent.client.setId(newid)\n",
    "            elif(receivedMazeCom.getMessagetype() == MazeComMessagetype.ACCEPT):\n",
    "                print(receivedMazeCom.getAcceptMessage().getErrortypeCode())\n",
    "                reward += 2\n",
    "            elif (receivedMazeCom.getMessagetype() == MazeComMessagetype.DISCONNECT):\n",
    "                print(receivedMazeCom.getDisconnectMessage().getErrortypeCode())\n",
    "                reward -= 10\n",
    "            elif(receivedMazeCom.getMessagetype() == MazeComMessagetype.AWAITMOVE):\n",
    "                print(action)\n",
    "                reward += self.awaitMove(receivedMazeCom, action, agent)\n",
    "            elif(receivedMazeCom.getMessagetype() == MazeComMessagetype.MOVEINFO):\n",
    "                #print(\"in MoveInfo\")\n",
    "                x = 0\n",
    "            elif(receivedMazeCom.getMessagetype() == MazeComMessagetype.WIN):\n",
    "                print(\"You have won\")\n",
    "                self.is_done = True\n",
    "                reward += 100\n",
    "            else:\n",
    "                print(\"Unknown message type: \" + receivedMazeCom.getMessagetype())\n",
    "        except Exception as e:\n",
    "            print(\"exception time\")\n",
    "            print(traceback.format_exc())\n",
    "            if str(type(e)) == \"<java class 'java.net.SocketException'>\":\n",
    "                print(\"socket error, disconnected\")\n",
    "                sys.exit(1)\n",
    "            elif str(type(e)) == \"<java class 'java.io.EOFException'>\":\n",
    "                print(\"end reached, disconnecting\")\n",
    "                sys.exit(1)\n",
    "                \n",
    "        observations = (self.player_pos[agent], self.next_treasure_pos[agent])\n",
    "        if self.is_done:\n",
    "            terminations = True\n",
    "        else:\n",
    "            terminations = False\n",
    "        truncations = False\n",
    "        infos = {}\n",
    "        return_val[0] = observations\n",
    "        return_val[1] = reward\n",
    "        return_val[2] = terminations\n",
    "        return_val[3] = truncations\n",
    "        return_val[4] = infos\n",
    "    \n",
    "    def reset(self, seed=None, return_info=False, options=None):\n",
    "        \"\"\"\n",
    "        Reset needs to initialize the `agents` attribute and must set up the\n",
    "        environment so that render(), and step() can be called without issues.\n",
    "        Here it initializes the `num_moves` variable which counts the number of\n",
    "        hands that are played.\n",
    "        Returns the observations for each agent\n",
    "        \"\"\"\n",
    "        pydirectinput.click(x=1050, y=135)\n",
    "        # start\n",
    "        pydirectinput.click(x=950, y=135)\n",
    "        #print(\"t1\")\n",
    "        #self.manager.stop_game(self.num_players)\n",
    "        #self.manager.start_game(self.num_players)\n",
    "        #print(\"t2\")\n",
    "        #time.sleep(1)\n",
    "        #for agent in self.possible_agents:\n",
    "        #    agent.client = Client.Client(agent.name, HOST, PORT, True)\n",
    "        #\"\"\"\n",
    "        for agent in self.possible_agents:\n",
    "            while True:\n",
    "                agent.client = Client.Client(agent.name, HOST, PORT, True)\n",
    "                try:\n",
    "                    login = MazeComMessageFactory.createLoginMessage(agent.name)\n",
    "                    agent.client.out.write(login)\n",
    "                    receivedMazeCom = agent.client.in_.readMazeCom()\n",
    "                    if(receivedMazeCom.getMessagetype() == MazeComMessagetype.LOGINREPLY):\n",
    "                        newid = receivedMazeCom.getLoginReplyMessage().getNewID()\n",
    "                        print(\"newid:\", newid)\n",
    "                        agent.client.setId(newid)\n",
    "                        break\n",
    "                    else:\n",
    "                        print(receivedMazeCom.getAcceptMessage().getErrortypeCode())\n",
    "                except:\n",
    "                    print(\"failed login :)\")\n",
    "        \n",
    "        #self.possible_agents = [Client.Client(\"player_\" + str(r), HOST, PORT, True) for r in range(self.num_players+1)]\n",
    "        #self.possible_agents = self.possible_agents[1:]\n",
    "        \n",
    "        self.is_done = False\n",
    "        for i in self.possible_agents:\n",
    "            print(\"id:\", i.client.id_)\n",
    "        #print(\"agents:\", self.agents)\n",
    "        self.possible_agents = sorted(self.possible_agents, key=operator.attrgetter('client.id_'))\n",
    "        for i in self.possible_agents:\n",
    "            print(\"id:\", i.client.id_)\n",
    "        #\"\"\"\n",
    "        self.agents = self.possible_agents[:]\n",
    "        observations = {agent: None for agent in self.agents}\n",
    "        print(\"reset done\")\n",
    "        if not return_info:\n",
    "            return observations\n",
    "        else:\n",
    "            infos = {agent: {} for agent in self.agents}\n",
    "            return observations, infos\n",
    "\n",
    "    def step(self, actions):\n",
    "        \"\"\"\n",
    "        step(action) takes in an action for each agent and should return the\n",
    "        - observations\n",
    "        - rewards\n",
    "        - terminations\n",
    "        - truncations\n",
    "        - infos\n",
    "        dicts where each dict looks like {agent_1: item_1, agent_2: item_2}\n",
    "        \"\"\"\n",
    "        # If a user passes in actions with no agents, then just return empty observations, etc.\n",
    "        if not actions:\n",
    "            self.agents = []\n",
    "            return {}, {}, {}, {}, {}\n",
    "        \n",
    "        i = 0\n",
    "        return_val= [[None]*5]*self.num_players\n",
    "        for agent in self.agents:\n",
    "            try:\n",
    "                self.run_agent(agent, actions[agent], return_val[i])\n",
    "                i += 1\n",
    "            except:\n",
    "                print(traceback.format_exc())\n",
    "                print(\"dang\")\n",
    "        \n",
    "        observations, rewards, terminations, truncations, infos = {}, {}, {}, {}, {}\n",
    "        \n",
    "        for t in range(self.num_players):\n",
    "            observations[self.agents[t]] = return_val[t][0]\n",
    "            rewards[self.agents[t]] = return_val[t][1]\n",
    "            terminations[self.agents[t]] = return_val[t][2]\n",
    "            truncations[self.agents[t]] = return_val[t][3]\n",
    "            infos[self.agents[t]] = return_val[t][4]\n",
    "        print(\"we're done\")\n",
    "        # rewards for all agents are placed in the rewards dictionary to be returned\n",
    "        return observations, rewards, terminations, truncations, infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d62fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.test import api_test\n",
    "from pettingzoo.test import parallel_api_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ce61d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Card.CardShape.I.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab0a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad1082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did it?\n",
      "newid: 4\n",
      "newid: 2\n",
      "newid: 3\n",
      "newid: 1\n",
      "id: 4\n",
      "id: 2\n",
      "id: 3\n",
      "id: 1\n",
      "id: 1\n",
      "id: 2\n",
      "id: 3\n",
      "id: 4\n",
      "reset done\n",
      "tigt\n",
      "starrt rer\n",
      "end ererer\n",
      "[4 2 0 4]\n",
      "card.getShape: <java class 'de.fhac.mazenet.server.game.Card.CardShape'>\n",
      "exception time\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AStA\\AppData\\Local\\Temp\\ipykernel_8120\\118066941.py\", line 180, in run_agent\n",
      "    reward += self.awaitMove(receivedMazeCom, action, agent)\n",
      "  File \"C:\\Users\\AStA\\AppData\\Local\\Temp\\ipykernel_8120\\118066941.py\", line 153, in awaitMove\n",
      "    move, reward = self.Move(awaitMove, action, agent)\n",
      "  File \"C:\\Users\\AStA\\AppData\\Local\\Temp\\ipykernel_8120\\118066941.py\", line 101, in Move\n",
      "    orientedShiftCard = self.moeglicheOrientierungen(action[1], board.getShiftCard())\n",
      "  File \"C:\\Users\\AStA\\AppData\\Local\\Temp\\ipykernel_8120\\118066941.py\", line 60, in moeglicheOrientierungen\n",
      "    if(card.getShape() == Card.CardShape.I):\n",
      "SystemError: Fail in conversion\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AStA\\AppData\\Local\\Temp\\ipykernel_8120\\118066941.py\", line 288, in step\n",
      "    self.run_agent(agent, actions[agent], return_val[i])\n",
      "  File \"C:\\Users\\AStA\\AppData\\Local\\Temp\\ipykernel_8120\\118066941.py\", line 200, in run_agent\n",
      "    observations = (self.player_pos[agent], self.next_treasure_pos[agent])\n",
      "KeyError: <__main__.Agent_Client object at 0x00000232AC7D7F70>\n",
      "\n",
      "dang\n",
      "starrt rer\n"
     ]
    }
   ],
   "source": [
    "parallel_env = MARL_Env_Parallel()\n",
    "print(\"did it?\")\n",
    "observations = parallel_env.reset()\n",
    "print(\"tigt\")\n",
    "for step in range(1000):\n",
    "    actions = {agent: parallel_env.action_space(agent).sample() for agent in parallel_env.agents}  # this is where you would insert your policy\n",
    "    observations, rewards, terminations, truncations, infos = parallel_env.step(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763810e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "import supersuit as ss\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e695f47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = MARL_Env_Parallel(4)\n",
    "#env_steps = 1000  # 2 * env.width * env.height  # Code uses 1.5 to calculate max_steps\n",
    "#rollout_fragment_length = 50\n",
    "env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "env = ss.concat_vec_envs_v1(env, 1, num_cpus=1, base_class='stable_baselines3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dccdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\"MlpPolicy\", env, tensorboard_log=\"./logs\", verbose=3, #gamma=0.95, \n",
    "    #n_steps=rollout_fragment_length, ent_coef=0.01, \n",
    "    #learning_rate=5e-5, vf_coef=1, max_grad_norm=0.9, gae_lambda=1.0, n_epochs=30, clip_range=0.3,\n",
    "    #batch_size=150, seed=seed)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db323181",
   "metadata": {},
   "outputs": [],
   "source": [
    "asy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0718cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(args):\n",
    "    env = MARL_Env_Parallel(4)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29334606",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"marl_env_para\"\n",
    "\n",
    "register_env(env_name, lambda config: ParallelPettingZooEnv(env_creator(config)))\n",
    "\n",
    "test_env = ParallelPettingZooEnv(env_creator({}))\n",
    "obs_space = test_env.observation_space\n",
    "act_space = test_env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_policy(i):\n",
    "    config = {\n",
    "        \"gamma\": 0.99,\n",
    "    }\n",
    "    return (None, obs_space, act_space, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e628cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "policies = {\"policy_0\": gen_policy(0)}\n",
    "policy_ids = list(policies.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0382910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.run(\n",
    "    \"PPO\",\n",
    "    name=\"PPO\",\n",
    "    stop={\"timesteps_total\": 5000000},\n",
    "    checkpoint_freq=10,\n",
    "    local_dir=\"~/ray_results/\"+env_name,\n",
    "    config={\n",
    "        # Environment specific\n",
    "        \"env\": env_name,\n",
    "        # https://github.com/ray-project/ray/issues/10761\n",
    "        \"no_done_at_end\": True,\n",
    "        # \"soft_horizon\" : True,\n",
    "        \"num_gpus\": 0,\n",
    "        \"num_workers\": 4,\n",
    "        \"num_envs_per_worker\": 1,\n",
    "        \"compress_observations\": False,\n",
    "        \"batch_mode\": 'truncate_episodes',\n",
    "        \"clip_rewards\": False,\n",
    "        \"vf_clip_param\": 500.0,\n",
    "        \"entropy_coeff\": 0.01,\n",
    "        # effective batch_size: train_batch_size * num_agents_in_each_environment [5, 10]\n",
    "        # see https://github.com/ray-project/ray/issues/4628\n",
    "        \"train_batch_size\": 1000,  # 5000\n",
    "        \"rollout_fragment_length\": 50,  # 100\n",
    "        \"sgd_minibatch_size\": 100,  # 500\n",
    "        \"vf_share_layers\": False\n",
    "        },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f48fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=100000)\n",
    "model.save(f\"policy_ppo_{train_timesteps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab7ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MARL_Env_Parallel(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Training/Logs'\n",
    "# model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
